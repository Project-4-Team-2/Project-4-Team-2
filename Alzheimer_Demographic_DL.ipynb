{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "from matplotlib import style\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import regularizers\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PatientID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>EducationLevel</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoking</th>\n",
       "      <th>AlcoholConsumption</th>\n",
       "      <th>PhysicalActivity</th>\n",
       "      <th>DietQuality</th>\n",
       "      <th>...</th>\n",
       "      <th>MemoryComplaints</th>\n",
       "      <th>BehavioralProblems</th>\n",
       "      <th>ADL</th>\n",
       "      <th>Confusion</th>\n",
       "      <th>Disorientation</th>\n",
       "      <th>PersonalityChanges</th>\n",
       "      <th>DifficultyCompletingTasks</th>\n",
       "      <th>Forgetfulness</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>DoctorInCharge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4751</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>22.927749</td>\n",
       "      <td>0</td>\n",
       "      <td>13.297218</td>\n",
       "      <td>6.327112</td>\n",
       "      <td>1.347214</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.725883</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>XXXConfid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4752</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.827681</td>\n",
       "      <td>0</td>\n",
       "      <td>4.542524</td>\n",
       "      <td>7.619885</td>\n",
       "      <td>0.518767</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.592424</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>XXXConfid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4753</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>17.795882</td>\n",
       "      <td>0</td>\n",
       "      <td>19.555085</td>\n",
       "      <td>7.844988</td>\n",
       "      <td>1.826335</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.119548</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>XXXConfid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4754</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>33.800817</td>\n",
       "      <td>1</td>\n",
       "      <td>12.209266</td>\n",
       "      <td>8.428001</td>\n",
       "      <td>7.435604</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.481226</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>XXXConfid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4755</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20.716974</td>\n",
       "      <td>0</td>\n",
       "      <td>18.454356</td>\n",
       "      <td>6.310461</td>\n",
       "      <td>0.795498</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.014691</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>XXXConfid</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PatientID  Age  Gender  Ethnicity  EducationLevel        BMI  Smoking  \\\n",
       "0       4751   73       0          0               2  22.927749        0   \n",
       "1       4752   89       0          0               0  26.827681        0   \n",
       "2       4753   73       0          3               1  17.795882        0   \n",
       "3       4754   74       1          0               1  33.800817        1   \n",
       "4       4755   89       0          0               0  20.716974        0   \n",
       "\n",
       "   AlcoholConsumption  PhysicalActivity  DietQuality  ...  MemoryComplaints  \\\n",
       "0           13.297218          6.327112     1.347214  ...                 0   \n",
       "1            4.542524          7.619885     0.518767  ...                 0   \n",
       "2           19.555085          7.844988     1.826335  ...                 0   \n",
       "3           12.209266          8.428001     7.435604  ...                 0   \n",
       "4           18.454356          6.310461     0.795498  ...                 0   \n",
       "\n",
       "   BehavioralProblems       ADL  Confusion  Disorientation  \\\n",
       "0                   0  1.725883          0               0   \n",
       "1                   0  2.592424          0               0   \n",
       "2                   0  7.119548          0               1   \n",
       "3                   1  6.481226          0               0   \n",
       "4                   0  0.014691          0               0   \n",
       "\n",
       "   PersonalityChanges  DifficultyCompletingTasks  Forgetfulness  Diagnosis  \\\n",
       "0                   0                          1              0          0   \n",
       "1                   0                          0              1          0   \n",
       "2                   0                          1              0          0   \n",
       "3                   0                          0              0          0   \n",
       "4                   1                          1              0          0   \n",
       "\n",
       "   DoctorInCharge  \n",
       "0       XXXConfid  \n",
       "1       XXXConfid  \n",
       "2       XXXConfid  \n",
       "3       XXXConfid  \n",
       "4       XXXConfid  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame for the healthcare-dataset-stroke-data.csv. \n",
    "file_path = Path(\"alzheimers_disease_data.csv\")\n",
    "alzheimer_df = pd.read_csv(file_path)\n",
    "alzheimer_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Data cleaning and preparation process \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of total rows: 2149\n",
      "Number of total columns: 35\n"
     ]
    }
   ],
   "source": [
    "# determine the number of rows and columns.\n",
    "alzheimer_df_rc, alzheimer_df_cc = alzheimer_df.shape\n",
    "print('Number of total rows:', alzheimer_df_rc)\n",
    "print('Number of total columns:', alzheimer_df_cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PatientID', 'Age', 'Gender', 'Ethnicity', 'EducationLevel', 'BMI',\n",
       "       'Smoking', 'AlcoholConsumption', 'PhysicalActivity', 'DietQuality',\n",
       "       'SleepQuality', 'FamilyHistoryAlzheimers', 'CardiovascularDisease',\n",
       "       'Diabetes', 'Depression', 'HeadInjury', 'Hypertension', 'SystolicBP',\n",
       "       'DiastolicBP', 'CholesterolTotal', 'CholesterolLDL', 'CholesterolHDL',\n",
       "       'CholesterolTriglycerides', 'MMSE', 'FunctionalAssessment',\n",
       "       'MemoryComplaints', 'BehavioralProblems', 'ADL', 'Confusion',\n",
       "       'Disorientation', 'PersonalityChanges', 'DifficultyCompletingTasks',\n",
       "       'Forgetfulness', 'Diagnosis', 'DoctorInCharge'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check all columns inside of the DataFrame\n",
    "alzheimer_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate Rows: 0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show duplicates\n",
    "duplicate = alzheimer_df[alzheimer_df.duplicated()]\n",
    "print(\"Duplicate Rows:\", len(duplicate), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PatientID                    0\n",
       "Age                          0\n",
       "Gender                       0\n",
       "Ethnicity                    0\n",
       "EducationLevel               0\n",
       "BMI                          0\n",
       "Smoking                      0\n",
       "AlcoholConsumption           0\n",
       "PhysicalActivity             0\n",
       "DietQuality                  0\n",
       "SleepQuality                 0\n",
       "FamilyHistoryAlzheimers      0\n",
       "CardiovascularDisease        0\n",
       "Diabetes                     0\n",
       "Depression                   0\n",
       "HeadInjury                   0\n",
       "Hypertension                 0\n",
       "SystolicBP                   0\n",
       "DiastolicBP                  0\n",
       "CholesterolTotal             0\n",
       "CholesterolLDL               0\n",
       "CholesterolHDL               0\n",
       "CholesterolTriglycerides     0\n",
       "MMSE                         0\n",
       "FunctionalAssessment         0\n",
       "MemoryComplaints             0\n",
       "BehavioralProblems           0\n",
       "ADL                          0\n",
       "Confusion                    0\n",
       "Disorientation               0\n",
       "PersonalityChanges           0\n",
       "DifficultyCompletingTasks    0\n",
       "Forgetfulness                0\n",
       "Diagnosis                    0\n",
       "DoctorInCharge               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values\n",
    "alzheimer_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all rows with missing information \n",
    "alzheimer_df = alzheimer_df.dropna(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PatientID 2149\n",
      "Age 31\n",
      "Gender 2\n",
      "Ethnicity 4\n",
      "EducationLevel 4\n",
      "BMI 2149\n",
      "Smoking 2\n",
      "AlcoholConsumption 2149\n",
      "PhysicalActivity 2149\n",
      "DietQuality 2149\n",
      "SleepQuality 2149\n",
      "FamilyHistoryAlzheimers 2\n",
      "CardiovascularDisease 2\n",
      "Diabetes 2\n",
      "Depression 2\n",
      "HeadInjury 2\n",
      "Hypertension 2\n",
      "SystolicBP 90\n",
      "DiastolicBP 60\n",
      "CholesterolTotal 2149\n",
      "CholesterolLDL 2149\n",
      "CholesterolHDL 2149\n",
      "CholesterolTriglycerides 2149\n",
      "MMSE 2149\n",
      "FunctionalAssessment 2149\n",
      "MemoryComplaints 2\n",
      "BehavioralProblems 2\n",
      "ADL 2149\n",
      "Confusion 2\n",
      "Disorientation 2\n",
      "PersonalityChanges 2\n",
      "DifficultyCompletingTasks 2\n",
      "Forgetfulness 2\n",
      "Diagnosis 2\n",
      "DoctorInCharge 1\n"
     ]
    }
   ],
   "source": [
    "# print out columns and number of unique values\n",
    "for col in alzheimer_df.columns:\n",
    "    print(col, alzheimer_df[col].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Exploratory Data Analysis (EDA)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Diagnosis\n",
       "0    1389\n",
       "1     760\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the stroke outcome value counts\n",
    "alzheimer_counts = alzheimer_df['Diagnosis'].value_counts()\n",
    "alzheimer_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>EducationLevel</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>MemoryComplaints</th>\n",
       "      <th>BehavioralProblems</th>\n",
       "      <th>MMSE</th>\n",
       "      <th>FunctionalAssessment</th>\n",
       "      <th>ADL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21.463532</td>\n",
       "      <td>6.518877</td>\n",
       "      <td>1.725883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20.613267</td>\n",
       "      <td>7.118696</td>\n",
       "      <td>2.592424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.356249</td>\n",
       "      <td>5.895077</td>\n",
       "      <td>7.119548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13.991127</td>\n",
       "      <td>8.965106</td>\n",
       "      <td>6.481226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.517609</td>\n",
       "      <td>6.045039</td>\n",
       "      <td>0.014691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2144</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.201190</td>\n",
       "      <td>0.238667</td>\n",
       "      <td>4.492838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2145</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.458060</td>\n",
       "      <td>8.687480</td>\n",
       "      <td>9.204952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2146</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17.011003</td>\n",
       "      <td>1.972137</td>\n",
       "      <td>5.036334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2147</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.030491</td>\n",
       "      <td>5.173891</td>\n",
       "      <td>3.785399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2148</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11.114777</td>\n",
       "      <td>6.307543</td>\n",
       "      <td>8.327563</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2149 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Ethnicity  Gender  Age  EducationLevel  Diagnosis  MemoryComplaints  \\\n",
       "0             0       0   73               2          0                 0   \n",
       "1             0       0   89               0          0                 0   \n",
       "2             3       0   73               1          0                 0   \n",
       "3             0       1   74               1          0                 0   \n",
       "4             0       0   89               0          0                 0   \n",
       "...         ...     ...  ...             ...        ...               ...   \n",
       "2144          0       0   61               1          1                 0   \n",
       "2145          0       0   75               2          1                 0   \n",
       "2146          0       0   77               1          1                 0   \n",
       "2147          3       1   78               1          1                 0   \n",
       "2148          0       0   72               2          0                 0   \n",
       "\n",
       "      BehavioralProblems       MMSE  FunctionalAssessment       ADL  \n",
       "0                      0  21.463532              6.518877  1.725883  \n",
       "1                      0  20.613267              7.118696  2.592424  \n",
       "2                      0   7.356249              5.895077  7.119548  \n",
       "3                      1  13.991127              8.965106  6.481226  \n",
       "4                      0  13.517609              6.045039  0.014691  \n",
       "...                  ...        ...                   ...       ...  \n",
       "2144                   0   1.201190              0.238667  4.492838  \n",
       "2145                   1   6.458060              8.687480  9.204952  \n",
       "2146                   0  17.011003              1.972137  5.036334  \n",
       "2147                   0   4.030491              5.173891  3.785399  \n",
       "2148                   1  11.114777              6.307543  8.327563  \n",
       "\n",
       "[2149 rows x 10 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keep part of columns for abalysis\n",
    "alzheimer_cleanML_df = alzheimer_df[['Ethnicity', 'Gender', 'Age', 'EducationLevel', 'Diagnosis', 'MemoryComplaints','BehavioralProblems', 'MMSE', 'FunctionalAssessment','ADL']]\n",
    "alzheimer_cleanML_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Age: The age of the patients ranges from 60 to 90 years.\n",
    "**Gender: Gender of the patients, where 0 represents Male and 1 represents Female.\n",
    "**Ethnicity: The ethnicity of the patients, coded as follows:\n",
    "0: Caucasian\n",
    "1: African American\n",
    "2: Asian\n",
    "3: Other\n",
    "**EducationLevel: The education level of the patients, coded as follows:\n",
    "0: None\n",
    "1: High School\n",
    "2: Bachelor's\n",
    "3: Higher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>MemoryComplaints</th>\n",
       "      <th>BehavioralProblems</th>\n",
       "      <th>MMSE</th>\n",
       "      <th>FunctionalAssessment</th>\n",
       "      <th>ADL</th>\n",
       "      <th>Caucasian</th>\n",
       "      <th>African American</th>\n",
       "      <th>Asian</th>\n",
       "      <th>Other</th>\n",
       "      <th>None</th>\n",
       "      <th>High School</th>\n",
       "      <th>Bachelor's</th>\n",
       "      <th>Higher</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21.463532</td>\n",
       "      <td>6.518877</td>\n",
       "      <td>1.725883</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20.613267</td>\n",
       "      <td>7.118696</td>\n",
       "      <td>2.592424</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.356249</td>\n",
       "      <td>5.895077</td>\n",
       "      <td>7.119548</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13.991127</td>\n",
       "      <td>8.965106</td>\n",
       "      <td>6.481226</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.517609</td>\n",
       "      <td>6.045039</td>\n",
       "      <td>0.014691</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2144</th>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.201190</td>\n",
       "      <td>0.238667</td>\n",
       "      <td>4.492838</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2145</th>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.458060</td>\n",
       "      <td>8.687480</td>\n",
       "      <td>9.204952</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2146</th>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17.011003</td>\n",
       "      <td>1.972137</td>\n",
       "      <td>5.036334</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2147</th>\n",
       "      <td>1</td>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.030491</td>\n",
       "      <td>5.173891</td>\n",
       "      <td>3.785399</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2148</th>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11.114777</td>\n",
       "      <td>6.307543</td>\n",
       "      <td>8.327563</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2149 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Gender  Age  Diagnosis  MemoryComplaints  BehavioralProblems       MMSE  \\\n",
       "0          0   73          0                 0                   0  21.463532   \n",
       "1          0   89          0                 0                   0  20.613267   \n",
       "2          0   73          0                 0                   0   7.356249   \n",
       "3          1   74          0                 0                   1  13.991127   \n",
       "4          0   89          0                 0                   0  13.517609   \n",
       "...      ...  ...        ...               ...                 ...        ...   \n",
       "2144       0   61          1                 0                   0   1.201190   \n",
       "2145       0   75          1                 0                   1   6.458060   \n",
       "2146       0   77          1                 0                   0  17.011003   \n",
       "2147       1   78          1                 0                   0   4.030491   \n",
       "2148       0   72          0                 0                   1  11.114777   \n",
       "\n",
       "      FunctionalAssessment       ADL  Caucasian  African American  Asian  \\\n",
       "0                 6.518877  1.725883          1                 0      0   \n",
       "1                 7.118696  2.592424          1                 0      0   \n",
       "2                 5.895077  7.119548          0                 0      0   \n",
       "3                 8.965106  6.481226          1                 0      0   \n",
       "4                 6.045039  0.014691          1                 0      0   \n",
       "...                    ...       ...        ...               ...    ...   \n",
       "2144              0.238667  4.492838          1                 0      0   \n",
       "2145              8.687480  9.204952          1                 0      0   \n",
       "2146              1.972137  5.036334          1                 0      0   \n",
       "2147              5.173891  3.785399          0                 0      0   \n",
       "2148              6.307543  8.327563          1                 0      0   \n",
       "\n",
       "      Other  None  High School  Bachelor's  Higher  \n",
       "0         0     0            0           1       0  \n",
       "1         0     1            0           0       0  \n",
       "2         1     0            1           0       0  \n",
       "3         0     0            1           0       0  \n",
       "4         0     1            0           0       0  \n",
       "...     ...   ...          ...         ...     ...  \n",
       "2144      0     0            1           0       0  \n",
       "2145      0     0            0           1       0  \n",
       "2146      0     0            1           0       0  \n",
       "2147      1     0            1           0       0  \n",
       "2148      0     0            0           1       0  \n",
       "\n",
       "[2149 rows x 16 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create new columns for each ethnicity and education level to obtain binary values\n",
    "alzheimer_cleanML_df['Caucasian'] = (alzheimer_cleanML_df['Ethnicity'] == 0).astype(int)\n",
    "alzheimer_cleanML_df['African American'] = (alzheimer_cleanML_df['Ethnicity'] == 1).astype(int)\n",
    "alzheimer_cleanML_df['Asian'] = (alzheimer_cleanML_df['Ethnicity'] == 2).astype(int)\n",
    "alzheimer_cleanML_df['Other'] = (alzheimer_cleanML_df['Ethnicity'] == 3).astype(int)\n",
    "\n",
    "alzheimer_cleanML_df['None'] = (alzheimer_cleanML_df['EducationLevel'] == 0).astype(int)\n",
    "alzheimer_cleanML_df['High School'] = (alzheimer_cleanML_df['EducationLevel'] == 1).astype(int)\n",
    "alzheimer_cleanML_df['Bachelor\\'s'] = (alzheimer_cleanML_df['EducationLevel'] == 2).astype(int)\n",
    "alzheimer_cleanML_df['Higher'] = (alzheimer_cleanML_df['EducationLevel'] == 3).astype(int)\n",
    "\n",
    "# Drop the original Ethnicity and EducationLevel columns\n",
    "alzheimer_cleanML_df = alzheimer_cleanML_df.drop('Ethnicity', axis=1)\n",
    "alzheimer_cleanML_df = alzheimer_cleanML_df.drop('EducationLevel', axis=1)\n",
    "\n",
    "# Display the first few rows of the reshaped dataframe\n",
    "alzheimer_cleanML_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data:\n",
    "X = alzheimer_cleanML_df.drop('Diagnosis', axis=1)  \n",
    "y = alzheimer_cleanML_df['Diagnosis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "# Review number of features\n",
    "print(len(X_train_scaled[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dense(16, activation='relu'),\n",
    "    keras.layers.Dense(8, activation='sigmoid'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">136</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m528\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m136\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m9\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,777</span> (14.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,777\u001b[0m (14.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,777</span> (14.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,777\u001b[0m (14.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check the structure of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6407 - loss: 0.6682 - val_accuracy: 0.6192 - val_loss: 0.6207\n",
      "Epoch 2/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6491 - loss: 0.5733 - val_accuracy: 0.6744 - val_loss: 0.5388\n",
      "Epoch 3/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7751 - loss: 0.4943 - val_accuracy: 0.7674 - val_loss: 0.4833\n",
      "Epoch 4/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8410 - loss: 0.4310 - val_accuracy: 0.8169 - val_loss: 0.4574\n",
      "Epoch 5/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8517 - loss: 0.4059 - val_accuracy: 0.8256 - val_loss: 0.4404\n",
      "Epoch 6/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8342 - loss: 0.3987 - val_accuracy: 0.8198 - val_loss: 0.4417\n",
      "Epoch 7/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8598 - loss: 0.3808 - val_accuracy: 0.8169 - val_loss: 0.4305\n",
      "Epoch 8/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8525 - loss: 0.3879 - val_accuracy: 0.8256 - val_loss: 0.4200\n",
      "Epoch 9/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8660 - loss: 0.3602 - val_accuracy: 0.8256 - val_loss: 0.4144\n",
      "Epoch 10/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8819 - loss: 0.3369 - val_accuracy: 0.8140 - val_loss: 0.4242\n",
      "Epoch 11/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8884 - loss: 0.3254 - val_accuracy: 0.8256 - val_loss: 0.4070\n",
      "Epoch 12/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8690 - loss: 0.3325 - val_accuracy: 0.8256 - val_loss: 0.4129\n",
      "Epoch 13/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8822 - loss: 0.3272 - val_accuracy: 0.8256 - val_loss: 0.4172\n",
      "Epoch 14/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8933 - loss: 0.3193 - val_accuracy: 0.8372 - val_loss: 0.3968\n",
      "Epoch 15/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9009 - loss: 0.2981 - val_accuracy: 0.8343 - val_loss: 0.3896\n",
      "Epoch 16/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8949 - loss: 0.3116 - val_accuracy: 0.8372 - val_loss: 0.3923\n",
      "Epoch 17/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9026 - loss: 0.2866 - val_accuracy: 0.8517 - val_loss: 0.3890\n",
      "Epoch 18/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9077 - loss: 0.2894 - val_accuracy: 0.8459 - val_loss: 0.3883\n",
      "Epoch 19/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9195 - loss: 0.2633 - val_accuracy: 0.8517 - val_loss: 0.3820\n",
      "Epoch 20/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9208 - loss: 0.2702 - val_accuracy: 0.8488 - val_loss: 0.3782\n",
      "Epoch 21/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9158 - loss: 0.2646 - val_accuracy: 0.8576 - val_loss: 0.3748\n",
      "Epoch 22/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9323 - loss: 0.2303 - val_accuracy: 0.8459 - val_loss: 0.3838\n",
      "Epoch 23/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9327 - loss: 0.2303 - val_accuracy: 0.8605 - val_loss: 0.3747\n",
      "Epoch 24/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9361 - loss: 0.2371 - val_accuracy: 0.8488 - val_loss: 0.3875\n",
      "Epoch 25/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9347 - loss: 0.2481 - val_accuracy: 0.8517 - val_loss: 0.3956\n",
      "Epoch 26/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9301 - loss: 0.2282 - val_accuracy: 0.8488 - val_loss: 0.4002\n",
      "Epoch 27/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9297 - loss: 0.2369 - val_accuracy: 0.8634 - val_loss: 0.3816\n",
      "Epoch 28/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9290 - loss: 0.2415 - val_accuracy: 0.8488 - val_loss: 0.3769\n",
      "Epoch 29/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9349 - loss: 0.2281 - val_accuracy: 0.8517 - val_loss: 0.3921\n",
      "Epoch 30/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9432 - loss: 0.2050 - val_accuracy: 0.8634 - val_loss: 0.3780\n",
      "Epoch 31/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9348 - loss: 0.2188 - val_accuracy: 0.8517 - val_loss: 0.3768\n",
      "Epoch 32/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9378 - loss: 0.2217 - val_accuracy: 0.8517 - val_loss: 0.3825\n",
      "Epoch 33/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9541 - loss: 0.1939 - val_accuracy: 0.8547 - val_loss: 0.3944\n",
      "Epoch 34/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9562 - loss: 0.1760 - val_accuracy: 0.8576 - val_loss: 0.3743\n",
      "Epoch 35/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9530 - loss: 0.1856 - val_accuracy: 0.8663 - val_loss: 0.3890\n",
      "Epoch 36/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9421 - loss: 0.2023 - val_accuracy: 0.8488 - val_loss: 0.4072\n",
      "Epoch 37/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9459 - loss: 0.1939 - val_accuracy: 0.8547 - val_loss: 0.4128\n",
      "Epoch 38/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9374 - loss: 0.2120 - val_accuracy: 0.8663 - val_loss: 0.3771\n",
      "Epoch 39/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9528 - loss: 0.1835 - val_accuracy: 0.8605 - val_loss: 0.3844\n",
      "Epoch 40/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9477 - loss: 0.2037 - val_accuracy: 0.8517 - val_loss: 0.4011\n",
      "Epoch 41/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9483 - loss: 0.1958 - val_accuracy: 0.8634 - val_loss: 0.3838\n",
      "Epoch 42/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9400 - loss: 0.2032 - val_accuracy: 0.8605 - val_loss: 0.3896\n",
      "Epoch 43/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9654 - loss: 0.1520 - val_accuracy: 0.8605 - val_loss: 0.3933\n",
      "Epoch 44/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9566 - loss: 0.1757 - val_accuracy: 0.8517 - val_loss: 0.4100\n",
      "Epoch 45/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9526 - loss: 0.1916 - val_accuracy: 0.8430 - val_loss: 0.3904\n",
      "Epoch 46/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9637 - loss: 0.1681 - val_accuracy: 0.8576 - val_loss: 0.3898\n",
      "Epoch 47/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9617 - loss: 0.1648 - val_accuracy: 0.8576 - val_loss: 0.3969\n",
      "Epoch 48/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9590 - loss: 0.1761 - val_accuracy: 0.8517 - val_loss: 0.4041\n",
      "Epoch 49/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9645 - loss: 0.1450 - val_accuracy: 0.8488 - val_loss: 0.4100\n",
      "Epoch 50/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9645 - loss: 0.1441 - val_accuracy: 0.8488 - val_loss: 0.4125\n",
      "Epoch 51/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9684 - loss: 0.1382 - val_accuracy: 0.8547 - val_loss: 0.4125\n",
      "Epoch 52/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9516 - loss: 0.1857 - val_accuracy: 0.8430 - val_loss: 0.4253\n",
      "Epoch 53/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9632 - loss: 0.1402 - val_accuracy: 0.8459 - val_loss: 0.4170\n",
      "Epoch 54/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9619 - loss: 0.1674 - val_accuracy: 0.8517 - val_loss: 0.4196\n",
      "Epoch 55/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9698 - loss: 0.1387 - val_accuracy: 0.8547 - val_loss: 0.4015\n",
      "Epoch 56/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9588 - loss: 0.1547 - val_accuracy: 0.8547 - val_loss: 0.4099\n",
      "Epoch 57/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9614 - loss: 0.1388 - val_accuracy: 0.8517 - val_loss: 0.4141\n",
      "Epoch 58/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9530 - loss: 0.1648 - val_accuracy: 0.8576 - val_loss: 0.4351\n",
      "Epoch 59/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9672 - loss: 0.1422 - val_accuracy: 0.8430 - val_loss: 0.4317\n",
      "Epoch 60/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9660 - loss: 0.1411 - val_accuracy: 0.8459 - val_loss: 0.4391\n",
      "Epoch 61/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9600 - loss: 0.1586 - val_accuracy: 0.8605 - val_loss: 0.4168\n",
      "Epoch 62/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9684 - loss: 0.1301 - val_accuracy: 0.8517 - val_loss: 0.4280\n",
      "Epoch 63/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9700 - loss: 0.1315 - val_accuracy: 0.8517 - val_loss: 0.4420\n",
      "Epoch 64/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9729 - loss: 0.1227 - val_accuracy: 0.8517 - val_loss: 0.4386\n",
      "Epoch 65/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9763 - loss: 0.1166 - val_accuracy: 0.8488 - val_loss: 0.4522\n",
      "Epoch 66/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9795 - loss: 0.1071 - val_accuracy: 0.8517 - val_loss: 0.4352\n",
      "Epoch 67/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9659 - loss: 0.1434 - val_accuracy: 0.8488 - val_loss: 0.4388\n",
      "Epoch 68/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9685 - loss: 0.1374 - val_accuracy: 0.8459 - val_loss: 0.4457\n",
      "Epoch 69/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9743 - loss: 0.1126 - val_accuracy: 0.8517 - val_loss: 0.4529\n",
      "Epoch 70/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9726 - loss: 0.1245 - val_accuracy: 0.8488 - val_loss: 0.4875\n",
      "Epoch 71/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9600 - loss: 0.1491 - val_accuracy: 0.8459 - val_loss: 0.4524\n",
      "Epoch 72/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9665 - loss: 0.1369 - val_accuracy: 0.8459 - val_loss: 0.4848\n",
      "Epoch 73/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9720 - loss: 0.1187 - val_accuracy: 0.8401 - val_loss: 0.4820\n",
      "Epoch 74/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9681 - loss: 0.1225 - val_accuracy: 0.8547 - val_loss: 0.4715\n",
      "Epoch 75/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9728 - loss: 0.1069 - val_accuracy: 0.8401 - val_loss: 0.4734\n",
      "Epoch 76/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9657 - loss: 0.1234 - val_accuracy: 0.8372 - val_loss: 0.5120\n",
      "Epoch 77/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9617 - loss: 0.1518 - val_accuracy: 0.8488 - val_loss: 0.5133\n",
      "Epoch 78/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9647 - loss: 0.1171 - val_accuracy: 0.8430 - val_loss: 0.4922\n",
      "Epoch 79/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9695 - loss: 0.1327 - val_accuracy: 0.8488 - val_loss: 0.4977\n",
      "Epoch 80/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9730 - loss: 0.1128 - val_accuracy: 0.8576 - val_loss: 0.4763\n",
      "Epoch 81/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9628 - loss: 0.1110 - val_accuracy: 0.8372 - val_loss: 0.5055\n",
      "Epoch 82/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9670 - loss: 0.1124 - val_accuracy: 0.8430 - val_loss: 0.5245\n",
      "Epoch 83/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9783 - loss: 0.0970 - val_accuracy: 0.8430 - val_loss: 0.5134\n",
      "Epoch 84/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9762 - loss: 0.0982 - val_accuracy: 0.8372 - val_loss: 0.4972\n",
      "Epoch 85/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9659 - loss: 0.1196 - val_accuracy: 0.8459 - val_loss: 0.5050\n",
      "Epoch 86/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9767 - loss: 0.0958 - val_accuracy: 0.8517 - val_loss: 0.5095\n",
      "Epoch 87/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9712 - loss: 0.1090 - val_accuracy: 0.8372 - val_loss: 0.5286\n",
      "Epoch 88/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9718 - loss: 0.1106 - val_accuracy: 0.8459 - val_loss: 0.5081\n",
      "Epoch 89/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9825 - loss: 0.0785 - val_accuracy: 0.8430 - val_loss: 0.5376\n",
      "Epoch 90/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9718 - loss: 0.1007 - val_accuracy: 0.8372 - val_loss: 0.5181\n",
      "Epoch 91/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9570 - loss: 0.1147 - val_accuracy: 0.8314 - val_loss: 0.5729\n",
      "Epoch 92/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9736 - loss: 0.1046 - val_accuracy: 0.8401 - val_loss: 0.5410\n",
      "Epoch 93/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9804 - loss: 0.0842 - val_accuracy: 0.8459 - val_loss: 0.5451\n",
      "Epoch 94/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9853 - loss: 0.0719 - val_accuracy: 0.8401 - val_loss: 0.5439\n",
      "Epoch 95/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9730 - loss: 0.1104 - val_accuracy: 0.8430 - val_loss: 0.5164\n",
      "Epoch 96/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9759 - loss: 0.1031 - val_accuracy: 0.8459 - val_loss: 0.5297\n",
      "Epoch 97/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9817 - loss: 0.0833 - val_accuracy: 0.8459 - val_loss: 0.5301\n",
      "Epoch 98/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9865 - loss: 0.0704 - val_accuracy: 0.8430 - val_loss: 0.5546\n",
      "Epoch 99/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9847 - loss: 0.0766 - val_accuracy: 0.8488 - val_loss: 0.5540\n",
      "Epoch 100/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9886 - loss: 0.0525 - val_accuracy: 0.8517 - val_loss: 0.5524\n",
      "Epoch 101/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9860 - loss: 0.0675 - val_accuracy: 0.8517 - val_loss: 0.5514\n",
      "Epoch 102/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9851 - loss: 0.0637 - val_accuracy: 0.8488 - val_loss: 0.5559\n",
      "Epoch 103/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9800 - loss: 0.0803 - val_accuracy: 0.8459 - val_loss: 0.5610\n",
      "Epoch 104/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9850 - loss: 0.0694 - val_accuracy: 0.8517 - val_loss: 0.5638\n",
      "Epoch 105/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9822 - loss: 0.0826 - val_accuracy: 0.8547 - val_loss: 0.5671\n",
      "Epoch 106/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9851 - loss: 0.0636 - val_accuracy: 0.8488 - val_loss: 0.5692\n",
      "Epoch 107/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9822 - loss: 0.0820 - val_accuracy: 0.8488 - val_loss: 0.5706\n",
      "Epoch 108/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9893 - loss: 0.0526 - val_accuracy: 0.8430 - val_loss: 0.5862\n",
      "Epoch 109/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9853 - loss: 0.0676 - val_accuracy: 0.8547 - val_loss: 0.5725\n",
      "Epoch 110/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9844 - loss: 0.0770 - val_accuracy: 0.8488 - val_loss: 0.5814\n",
      "Epoch 111/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9874 - loss: 0.0634 - val_accuracy: 0.8459 - val_loss: 0.5785\n",
      "Epoch 112/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9920 - loss: 0.0460 - val_accuracy: 0.8488 - val_loss: 0.5871\n",
      "Epoch 113/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9822 - loss: 0.0695 - val_accuracy: 0.8459 - val_loss: 0.5881\n",
      "Epoch 114/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9934 - loss: 0.0418 - val_accuracy: 0.8488 - val_loss: 0.5919\n",
      "Epoch 115/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9858 - loss: 0.0650 - val_accuracy: 0.8459 - val_loss: 0.5914\n",
      "Epoch 116/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9877 - loss: 0.0618 - val_accuracy: 0.8430 - val_loss: 0.5903\n",
      "Epoch 117/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9855 - loss: 0.0638 - val_accuracy: 0.8488 - val_loss: 0.5962\n",
      "Epoch 118/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9913 - loss: 0.0505 - val_accuracy: 0.8401 - val_loss: 0.6090\n",
      "Epoch 119/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9848 - loss: 0.0661 - val_accuracy: 0.8401 - val_loss: 0.6120\n",
      "Epoch 120/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9842 - loss: 0.0704 - val_accuracy: 0.8488 - val_loss: 0.6063\n",
      "Epoch 121/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9897 - loss: 0.0464 - val_accuracy: 0.8430 - val_loss: 0.6070\n",
      "Epoch 122/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9913 - loss: 0.0513 - val_accuracy: 0.8430 - val_loss: 0.6174\n",
      "Epoch 123/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9919 - loss: 0.0480 - val_accuracy: 0.8517 - val_loss: 0.6075\n",
      "Epoch 124/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9897 - loss: 0.0517 - val_accuracy: 0.8488 - val_loss: 0.6167\n",
      "Epoch 125/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9857 - loss: 0.0627 - val_accuracy: 0.8401 - val_loss: 0.6252\n",
      "Epoch 126/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9890 - loss: 0.0518 - val_accuracy: 0.8343 - val_loss: 0.6312\n",
      "Epoch 127/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9831 - loss: 0.0734 - val_accuracy: 0.8488 - val_loss: 0.6276\n",
      "Epoch 128/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9919 - loss: 0.0428 - val_accuracy: 0.8430 - val_loss: 0.6262\n",
      "Epoch 129/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9854 - loss: 0.0697 - val_accuracy: 0.8401 - val_loss: 0.6375\n",
      "Epoch 130/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9917 - loss: 0.0452 - val_accuracy: 0.8401 - val_loss: 0.6383\n",
      "Epoch 131/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9892 - loss: 0.0522 - val_accuracy: 0.8372 - val_loss: 0.6545\n",
      "Epoch 132/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9832 - loss: 0.0778 - val_accuracy: 0.8343 - val_loss: 0.6511\n",
      "Epoch 133/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9900 - loss: 0.0477 - val_accuracy: 0.8372 - val_loss: 0.6498\n",
      "Epoch 134/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9947 - loss: 0.0367 - val_accuracy: 0.8430 - val_loss: 0.6552\n",
      "Epoch 135/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9864 - loss: 0.0648 - val_accuracy: 0.8401 - val_loss: 0.6549\n",
      "Epoch 136/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9919 - loss: 0.0454 - val_accuracy: 0.8401 - val_loss: 0.6561\n",
      "Epoch 137/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9855 - loss: 0.0641 - val_accuracy: 0.8459 - val_loss: 0.6569\n",
      "Epoch 138/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9829 - loss: 0.0792 - val_accuracy: 0.8401 - val_loss: 0.6567\n",
      "Epoch 139/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9914 - loss: 0.0392 - val_accuracy: 0.8372 - val_loss: 0.6696\n",
      "Epoch 140/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9914 - loss: 0.0463 - val_accuracy: 0.8401 - val_loss: 0.6639\n",
      "Epoch 141/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9933 - loss: 0.0391 - val_accuracy: 0.8401 - val_loss: 0.6668\n",
      "Epoch 142/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9885 - loss: 0.0520 - val_accuracy: 0.8372 - val_loss: 0.6657\n",
      "Epoch 143/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9863 - loss: 0.0616 - val_accuracy: 0.8430 - val_loss: 0.6676\n",
      "Epoch 144/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9827 - loss: 0.0686 - val_accuracy: 0.8372 - val_loss: 0.6756\n",
      "Epoch 145/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9950 - loss: 0.0339 - val_accuracy: 0.8372 - val_loss: 0.6775\n",
      "Epoch 146/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9881 - loss: 0.0618 - val_accuracy: 0.8343 - val_loss: 0.6726\n",
      "Epoch 147/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9878 - loss: 0.0630 - val_accuracy: 0.8401 - val_loss: 0.6743\n",
      "Epoch 148/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9872 - loss: 0.0595 - val_accuracy: 0.8343 - val_loss: 0.6863\n",
      "Epoch 149/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9862 - loss: 0.0612 - val_accuracy: 0.8430 - val_loss: 0.6763\n",
      "Epoch 150/150\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9911 - loss: 0.0413 - val_accuracy: 0.8401 - val_loss: 0.6842\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_scaled, y_train, epochs=150, batch_size=32, validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8825 - loss: 0.5737 \n",
      "Test accuracy: 0.8790697455406189\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(X_test_scaled, y_test)\n",
    "print(f\"Test accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "filename = 'alzheimer_ML.h5'\n",
    "model.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot accuracy of the model\n",
    "plot_df = pd.DataFrame(history.history, index =  range(1, len(history.history[\"loss\"]) + 1))\n",
    "plot_df.plot(y = \"accuracy\", figsize = (8, 5))\n",
    "plt.title(\"Model Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.grid(True)\n",
    "plt.savefig(\"model_accuracy_opt.png\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inclassfeb2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
