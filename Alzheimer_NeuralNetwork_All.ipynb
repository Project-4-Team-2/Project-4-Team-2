{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "from warnings import simplefilter\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>EducationLevel</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoking</th>\n",
       "      <th>AlcoholConsumption</th>\n",
       "      <th>PhysicalActivity</th>\n",
       "      <th>DietQuality</th>\n",
       "      <th>SleepQuality</th>\n",
       "      <th>...</th>\n",
       "      <th>FunctionalAssessment</th>\n",
       "      <th>MemoryComplaints</th>\n",
       "      <th>BehavioralProblems</th>\n",
       "      <th>ADL</th>\n",
       "      <th>Confusion</th>\n",
       "      <th>Disorientation</th>\n",
       "      <th>PersonalityChanges</th>\n",
       "      <th>DifficultyCompletingTasks</th>\n",
       "      <th>Forgetfulness</th>\n",
       "      <th>Diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>22.927749</td>\n",
       "      <td>0</td>\n",
       "      <td>13.297218</td>\n",
       "      <td>6.327112</td>\n",
       "      <td>1.347214</td>\n",
       "      <td>9.025679</td>\n",
       "      <td>...</td>\n",
       "      <td>6.518877</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.725883</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.827681</td>\n",
       "      <td>0</td>\n",
       "      <td>4.542524</td>\n",
       "      <td>7.619885</td>\n",
       "      <td>0.518767</td>\n",
       "      <td>7.151293</td>\n",
       "      <td>...</td>\n",
       "      <td>7.118696</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.592424</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>17.795882</td>\n",
       "      <td>0</td>\n",
       "      <td>19.555085</td>\n",
       "      <td>7.844988</td>\n",
       "      <td>1.826335</td>\n",
       "      <td>9.673574</td>\n",
       "      <td>...</td>\n",
       "      <td>5.895077</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.119548</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>33.800817</td>\n",
       "      <td>1</td>\n",
       "      <td>12.209266</td>\n",
       "      <td>8.428001</td>\n",
       "      <td>7.435604</td>\n",
       "      <td>8.392554</td>\n",
       "      <td>...</td>\n",
       "      <td>8.965106</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.481226</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20.716974</td>\n",
       "      <td>0</td>\n",
       "      <td>18.454356</td>\n",
       "      <td>6.310461</td>\n",
       "      <td>0.795498</td>\n",
       "      <td>5.597238</td>\n",
       "      <td>...</td>\n",
       "      <td>6.045039</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.014691</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Gender  Ethnicity  EducationLevel        BMI  Smoking  \\\n",
       "0   73       0          0               2  22.927749        0   \n",
       "1   89       0          0               0  26.827681        0   \n",
       "2   73       0          3               1  17.795882        0   \n",
       "3   74       1          0               1  33.800817        1   \n",
       "4   89       0          0               0  20.716974        0   \n",
       "\n",
       "   AlcoholConsumption  PhysicalActivity  DietQuality  SleepQuality  ...  \\\n",
       "0           13.297218          6.327112     1.347214      9.025679  ...   \n",
       "1            4.542524          7.619885     0.518767      7.151293  ...   \n",
       "2           19.555085          7.844988     1.826335      9.673574  ...   \n",
       "3           12.209266          8.428001     7.435604      8.392554  ...   \n",
       "4           18.454356          6.310461     0.795498      5.597238  ...   \n",
       "\n",
       "   FunctionalAssessment  MemoryComplaints  BehavioralProblems       ADL  \\\n",
       "0              6.518877                 0                   0  1.725883   \n",
       "1              7.118696                 0                   0  2.592424   \n",
       "2              5.895077                 0                   0  7.119548   \n",
       "3              8.965106                 0                   1  6.481226   \n",
       "4              6.045039                 0                   0  0.014691   \n",
       "\n",
       "   Confusion  Disorientation  PersonalityChanges  DifficultyCompletingTasks  \\\n",
       "0          0               0                   0                          1   \n",
       "1          0               0                   0                          0   \n",
       "2          0               1                   0                          1   \n",
       "3          0               0                   0                          0   \n",
       "4          0               0                   1                          1   \n",
       "\n",
       "   Forgetfulness  Diagnosis  \n",
       "0              0          0  \n",
       "1              1          0  \n",
       "2              0          0  \n",
       "3              0          0  \n",
       "4              0          0  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(\n",
    "    Path(\"alzheimer_clean.csv\")   \n",
    ")\n",
    "\n",
    "# Review the DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"Diagnosis\"]\n",
    "x = df.drop(columns=\"Diagnosis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the categorical variables using get_dummies\n",
    "X = pd.get_dummies(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split original dataset X and y into a training set + temp set (test_size=0.2 for 20% of data going towards the temp set and 80% for training set)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "# split temp set into validation set + test set (50/50) \n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=1)\n",
    "\n",
    "# goal = train using 80% of original data, tune hyperparameters using the validation set + evaluate model performance on unseen data using test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1719, 32) (215, 32) (215, 32)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_val.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the training data to the standard scaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Transform the training data using the scaler\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "\n",
    "# Transform the testing data using the scaler\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "# Transform the validation data using the scaler\n",
    "X_val_scaled = X_scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doing a Grid Search for n_neighours optimal value using cross-validation in Python with SciKit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best n_neighbors value: 11\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid with the correct parameter name 'n_neighbors'\n",
    "param_grid = {'n_neighbors': [3, 5, 7, 9, 11]}\n",
    "\n",
    "# Create a KNN classifier\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(knn, param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Access the best parameters and print the best n_neighbors value\n",
    "best_n_neighbors = grid_search.best_params_['n_neighbors']\n",
    "print(\"Best n_neighbors value:\", best_n_neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best n_neighbors value: 19\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid with the correct parameter name 'n_neighbors'\n",
    "param_grid = {'n_neighbors': [11, 13, 15, 17, 19]}\n",
    "\n",
    "# Create a KNN classifier\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(knn, param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Access the best parameters and print the best n_neighbors value\n",
    "best_n_neighbors = grid_search.best_params_['n_neighbors']\n",
    "print(\"Best n_neighbors value:\", best_n_neighbors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying the \"rule of thumb for n_neighbours\" = square root of total number of samples in the dataset (1719 for training set = 41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best n_neighbors value: 43\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid with the correct parameter name 'n_neighbors'\n",
    "param_grid = {'n_neighbors': [35, 37, 39, 41, 43]}\n",
    "\n",
    "# Create a KNN classifier\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(knn, param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Access the best parameters and print the best n_neighbors value\n",
    "best_n_neighbors = grid_search.best_params_['n_neighbors']\n",
    "print(\"Best n_neighbors value:\", best_n_neighbors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep n_neighbors = 41 to attempt at best balance between bias and variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the KNeighborsClassifier module from sklearn\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Instantiate the KNeighborsClassifier model with n_neighbors = 19 \n",
    "knn = KNeighborsClassifier(n_neighbors=41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=41)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model using the training data\n",
    "knn.fit(X_train_scaled, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.641860465116279\n"
     ]
    }
   ],
   "source": [
    "validation_accuracy = knn.score(X_val, y_val)\n",
    "print(\"Validation Accuracy:\", validation_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create predictions using the testing data\n",
    "y_pred = knn.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.97      0.82       139\n",
      "           1       0.85      0.29      0.43        76\n",
      "\n",
      "    accuracy                           0.73       215\n",
      "   macro avg       0.78      0.63      0.63       215\n",
      "weighted avg       0.76      0.73      0.68       215\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the classification report comparing the testing data to the model predictions\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalization to scale features to a range between 0 and 1 (want to bring data to common scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a MinMaxScaler instance\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit the training data to the standard scaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Transform the training data using the scaler\n",
    "X_train_scaled_norm = X_scaler.transform(X_train)\n",
    "\n",
    "# Transform the testing data using the scaler\n",
    "X_test_scaled_norm = X_scaler.transform(X_test)\n",
    "\n",
    "# Transform the validation data using the scaler\n",
    "X_val_scaled_norm = X_scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('minmaxscaler', MinMaxScaler()),\n",
       "                ('kneighborsclassifier', KNeighborsClassifier(n_neighbors=41))])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Create a pipeline with StandardScaler and KNN classifier\n",
    "pipeline = make_pipeline(MinMaxScaler(), KNeighborsClassifier(n_neighbors=41))\n",
    "\n",
    "# Fit the pipeline on the training data and make predictions\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the KNeighborsClassifier model with n_neighbors = 19 \n",
    "knn = KNeighborsClassifier(n_neighbors=41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=41)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model using the training data\n",
    "knn.fit(X_train_scaled_norm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.641860465116279\n"
     ]
    }
   ],
   "source": [
    "validation_accuracy = knn.score(X_val, y_val)\n",
    "print(\"Validation Accuracy:\", validation_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create predictions using the testing data\n",
    "y_pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      1.00      0.79       139\n",
      "           1       0.00      0.00      0.00        76\n",
      "\n",
      "    accuracy                           0.65       215\n",
      "   macro avg       0.32      0.50      0.39       215\n",
      "weighted avg       0.42      0.65      0.51       215\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yumai\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\yumai\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\yumai\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Print the classification report comparing the testing data to the model predictions\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalization and Pipeline Feature has the same validation accuracy, but lowers f1-score whilst increasing recall for [0], which decreasing for [1]. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NO IMPROVEMENT WITH CHANGE IN WEIGHT BY DISTANCE (uniform and distance the same)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a k-NN classifier with distance-based weighting\n",
    "knn_distance = KNeighborsClassifier(n_neighbors=41, weights='uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=41)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model using the training data\n",
    "knn_distance.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.641860465116279\n"
     ]
    }
   ],
   "source": [
    "validation_accuracy = knn_distance.score(X_val, y_val)\n",
    "print(\"Validation Accuracy:\", validation_accuracy)\n",
    "\n",
    "# validation decreased with weight change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create predictions using the testing data\n",
    "y_pred = knn_distance.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.97      0.82       139\n",
      "           1       0.85      0.29      0.43        76\n",
      "\n",
      "    accuracy                           0.73       215\n",
      "   macro avg       0.78      0.63      0.63       215\n",
      "weighted avg       0.76      0.73      0.68       215\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the classification report comparing the testing data to the model predictions\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try lowered n_neighbors (=19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the KNeighborsClassifier module from sklearn\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Instantiate the KNeighborsClassifier model with n_neighbors = 19 \n",
    "knn = KNeighborsClassifier(n_neighbors=19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=19)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model using the training data\n",
    "knn.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6232558139534884\n"
     ]
    }
   ],
   "source": [
    "validation_accuracy = knn.score(X_val, y_val)\n",
    "print(\"Validation Accuracy:\", validation_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create predictions using the testing data\n",
    "y_pred = knn.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.95      0.82       139\n",
      "           1       0.79      0.34      0.48        76\n",
      "\n",
      "    accuracy                           0.73       215\n",
      "   macro avg       0.76      0.65      0.65       215\n",
      "weighted avg       0.75      0.73      0.70       215\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the classification report comparing the testing data to the model predictions\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tried even lower n_neighbors (11) = lowered accuracy, recall, precision and approximately the same validation score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the KNeighborsClassifier module from sklearn\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Instantiate the KNeighborsClassifier model with n_neighbors = 19 \n",
    "knn = KNeighborsClassifier(n_neighbors=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=11)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model using the training data\n",
    "knn.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6\n"
     ]
    }
   ],
   "source": [
    "validation_accuracy = knn.score(X_val, y_val)\n",
    "print(\"Validation Accuracy:\", validation_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create predictions using the testing data\n",
    "y_pred = knn.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.91      0.79       139\n",
      "           1       0.64      0.28      0.39        76\n",
      "\n",
      "    accuracy                           0.69       215\n",
      "   macro avg       0.67      0.59      0.59       215\n",
      "weighted avg       0.68      0.69      0.65       215\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the classification report comparing the testing data to the model predictions\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the KNeighborsClassifier module from sklearn\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Instantiate the KNeighborsClassifier model with n_neighbors = 19 \n",
    "knn = KNeighborsClassifier(n_neighbors=31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=31)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model using the training data\n",
    "knn.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6325581395348837\n"
     ]
    }
   ],
   "source": [
    "validation_accuracy = knn.score(X_val, y_val)\n",
    "print(\"Validation Accuracy:\", validation_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create predictions using the testing data\n",
    "y_pred = knn.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.95      0.82       139\n",
      "           1       0.79      0.34      0.48        76\n",
      "\n",
      "    accuracy                           0.73       215\n",
      "   macro avg       0.76      0.65      0.65       215\n",
      "weighted avg       0.75      0.73      0.70       215\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the classification report comparing the testing data to the model predictions\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lowered validation accuracy for n_neighbors = 31. Keep n_neighbors =41. Low accuracy and averaged f1-score of 0.73 has urged consideration of deeper learning. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TESTING DEEP LEARNING MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1719 samples, validate on 215 samples\n",
      "Epoch 1/50\n",
      "1719/1719 [==============================] - 1s 320us/sample - loss: 0.7956 - accuracy: 0.5009 - val_loss: 0.7617 - val_accuracy: 0.5116\n",
      "Epoch 2/50\n",
      "1719/1719 [==============================] - 0s 41us/sample - loss: 0.6325 - accuracy: 0.6434 - val_loss: 0.6405 - val_accuracy: 0.6512\n",
      "Epoch 3/50\n",
      "1719/1719 [==============================] - 0s 46us/sample - loss: 0.5469 - accuracy: 0.7353 - val_loss: 0.5660 - val_accuracy: 0.6884\n",
      "Epoch 4/50\n",
      "1719/1719 [==============================] - 0s 47us/sample - loss: 0.4943 - accuracy: 0.7725 - val_loss: 0.5142 - val_accuracy: 0.7302\n",
      "Epoch 5/50\n",
      "1719/1719 [==============================] - 0s 41us/sample - loss: 0.4568 - accuracy: 0.7993 - val_loss: 0.4768 - val_accuracy: 0.7442\n",
      "Epoch 6/50\n",
      "1719/1719 [==============================] - 0s 58us/sample - loss: 0.4291 - accuracy: 0.8162 - val_loss: 0.4450 - val_accuracy: 0.7581\n",
      "Epoch 7/50\n",
      "1719/1719 [==============================] - 0s 45us/sample - loss: 0.4070 - accuracy: 0.8348 - val_loss: 0.4240 - val_accuracy: 0.7721\n",
      "Epoch 8/50\n",
      "1719/1719 [==============================] - 0s 42us/sample - loss: 0.3913 - accuracy: 0.8429 - val_loss: 0.4047 - val_accuracy: 0.7953\n",
      "Epoch 9/50\n",
      "1719/1719 [==============================] - 0s 47us/sample - loss: 0.3783 - accuracy: 0.8470 - val_loss: 0.3903 - val_accuracy: 0.7953\n",
      "Epoch 10/50\n",
      "1719/1719 [==============================] - 0s 49us/sample - loss: 0.3689 - accuracy: 0.8493 - val_loss: 0.3815 - val_accuracy: 0.7953\n",
      "Epoch 11/50\n",
      "1719/1719 [==============================] - 0s 39us/sample - loss: 0.3609 - accuracy: 0.8522 - val_loss: 0.3743 - val_accuracy: 0.8140\n",
      "Epoch 12/50\n",
      "1719/1719 [==============================] - 0s 52us/sample - loss: 0.3541 - accuracy: 0.8581 - val_loss: 0.3668 - val_accuracy: 0.8186\n",
      "Epoch 13/50\n",
      "1719/1719 [==============================] - 0s 35us/sample - loss: 0.3482 - accuracy: 0.8615 - val_loss: 0.3622 - val_accuracy: 0.8233\n",
      "Epoch 14/50\n",
      "1719/1719 [==============================] - 0s 49us/sample - loss: 0.3434 - accuracy: 0.8633 - val_loss: 0.3590 - val_accuracy: 0.8279\n",
      "Epoch 15/50\n",
      "1719/1719 [==============================] - 0s 49us/sample - loss: 0.3390 - accuracy: 0.8633 - val_loss: 0.3529 - val_accuracy: 0.8279\n",
      "Epoch 16/50\n",
      "1719/1719 [==============================] - 0s 41us/sample - loss: 0.3345 - accuracy: 0.8685 - val_loss: 0.3503 - val_accuracy: 0.8326\n",
      "Epoch 17/50\n",
      "1719/1719 [==============================] - 0s 41us/sample - loss: 0.3308 - accuracy: 0.8726 - val_loss: 0.3483 - val_accuracy: 0.8326\n",
      "Epoch 18/50\n",
      "1719/1719 [==============================] - 0s 35us/sample - loss: 0.3271 - accuracy: 0.8726 - val_loss: 0.3462 - val_accuracy: 0.8326\n",
      "Epoch 19/50\n",
      "1719/1719 [==============================] - 0s 41us/sample - loss: 0.3239 - accuracy: 0.8749 - val_loss: 0.3434 - val_accuracy: 0.8326\n",
      "Epoch 20/50\n",
      "1719/1719 [==============================] - 0s 41us/sample - loss: 0.3207 - accuracy: 0.8761 - val_loss: 0.3417 - val_accuracy: 0.8372\n",
      "Epoch 21/50\n",
      "1719/1719 [==============================] - 0s 70us/sample - loss: 0.3178 - accuracy: 0.8761 - val_loss: 0.3404 - val_accuracy: 0.8372\n",
      "Epoch 22/50\n",
      "1719/1719 [==============================] - 0s 41us/sample - loss: 0.3154 - accuracy: 0.8784 - val_loss: 0.3387 - val_accuracy: 0.8465\n",
      "Epoch 23/50\n",
      "1719/1719 [==============================] - 0s 41us/sample - loss: 0.3126 - accuracy: 0.8807 - val_loss: 0.3375 - val_accuracy: 0.8419\n",
      "Epoch 24/50\n",
      "1719/1719 [==============================] - 0s 43us/sample - loss: 0.3098 - accuracy: 0.8796 - val_loss: 0.3371 - val_accuracy: 0.8419\n",
      "Epoch 25/50\n",
      "1719/1719 [==============================] - 0s 77us/sample - loss: 0.3074 - accuracy: 0.8819 - val_loss: 0.3383 - val_accuracy: 0.8419\n",
      "Epoch 26/50\n",
      "1719/1719 [==============================] - 0s 39us/sample - loss: 0.3046 - accuracy: 0.8825 - val_loss: 0.3352 - val_accuracy: 0.8465\n",
      "Epoch 27/50\n",
      "1719/1719 [==============================] - 0s 38us/sample - loss: 0.3024 - accuracy: 0.8819 - val_loss: 0.3342 - val_accuracy: 0.8512\n",
      "Epoch 28/50\n",
      "1719/1719 [==============================] - 0s 41us/sample - loss: 0.3002 - accuracy: 0.8860 - val_loss: 0.3338 - val_accuracy: 0.8512\n",
      "Epoch 29/50\n",
      "1719/1719 [==============================] - 0s 41us/sample - loss: 0.2976 - accuracy: 0.8848 - val_loss: 0.3318 - val_accuracy: 0.8465\n",
      "Epoch 30/50\n",
      "1719/1719 [==============================] - 0s 47us/sample - loss: 0.2951 - accuracy: 0.8906 - val_loss: 0.3306 - val_accuracy: 0.8512\n",
      "Epoch 31/50\n",
      "1719/1719 [==============================] - 0s 35us/sample - loss: 0.2930 - accuracy: 0.8889 - val_loss: 0.3296 - val_accuracy: 0.8465\n",
      "Epoch 32/50\n",
      "1719/1719 [==============================] - 0s 41us/sample - loss: 0.2910 - accuracy: 0.8901 - val_loss: 0.3295 - val_accuracy: 0.8465\n",
      "Epoch 33/50\n",
      "1719/1719 [==============================] - 0s 47us/sample - loss: 0.2892 - accuracy: 0.8906 - val_loss: 0.3280 - val_accuracy: 0.8465\n",
      "Epoch 34/50\n",
      "1719/1719 [==============================] - 0s 52us/sample - loss: 0.2872 - accuracy: 0.8930 - val_loss: 0.3281 - val_accuracy: 0.8512\n",
      "Epoch 35/50\n",
      "1719/1719 [==============================] - 0s 46us/sample - loss: 0.2850 - accuracy: 0.8959 - val_loss: 0.3286 - val_accuracy: 0.8465\n",
      "Epoch 36/50\n",
      "1719/1719 [==============================] - 0s 56us/sample - loss: 0.2834 - accuracy: 0.8982 - val_loss: 0.3274 - val_accuracy: 0.8558\n",
      "Epoch 37/50\n",
      "1719/1719 [==============================] - 0s 54us/sample - loss: 0.2810 - accuracy: 0.8988 - val_loss: 0.3271 - val_accuracy: 0.8512\n",
      "Epoch 38/50\n",
      "1719/1719 [==============================] - 0s 58us/sample - loss: 0.2798 - accuracy: 0.8976 - val_loss: 0.3276 - val_accuracy: 0.8558\n",
      "Epoch 39/50\n",
      "1719/1719 [==============================] - 0s 61us/sample - loss: 0.2775 - accuracy: 0.9011 - val_loss: 0.3264 - val_accuracy: 0.8558\n",
      "Epoch 40/50\n",
      "1719/1719 [==============================] - 0s 64us/sample - loss: 0.2751 - accuracy: 0.8999 - val_loss: 0.3276 - val_accuracy: 0.8605\n",
      "Epoch 41/50\n",
      "1719/1719 [==============================] - 0s 70us/sample - loss: 0.2730 - accuracy: 0.9023 - val_loss: 0.3276 - val_accuracy: 0.8512\n",
      "Epoch 42/50\n",
      "1719/1719 [==============================] - 0s 81us/sample - loss: 0.2720 - accuracy: 0.9023 - val_loss: 0.3282 - val_accuracy: 0.8558\n",
      "Epoch 43/50\n",
      "1719/1719 [==============================] - 0s 81us/sample - loss: 0.2695 - accuracy: 0.9023 - val_loss: 0.3272 - val_accuracy: 0.8558\n",
      "Epoch 44/50\n",
      "1719/1719 [==============================] - 0s 83us/sample - loss: 0.2686 - accuracy: 0.9017 - val_loss: 0.3292 - val_accuracy: 0.8558\n",
      "Epoch 45/50\n",
      "1719/1719 [==============================] - 0s 84us/sample - loss: 0.2663 - accuracy: 0.9046 - val_loss: 0.3272 - val_accuracy: 0.8605\n",
      "Epoch 46/50\n",
      "1719/1719 [==============================] - 0s 86us/sample - loss: 0.2648 - accuracy: 0.9046 - val_loss: 0.3296 - val_accuracy: 0.8651\n",
      "Epoch 47/50\n",
      "1719/1719 [==============================] - 0s 71us/sample - loss: 0.2629 - accuracy: 0.9052 - val_loss: 0.3300 - val_accuracy: 0.8651\n",
      "Epoch 48/50\n",
      "1719/1719 [==============================] - 0s 83us/sample - loss: 0.2613 - accuracy: 0.9063 - val_loss: 0.3308 - val_accuracy: 0.8558\n",
      "Epoch 49/50\n",
      "1719/1719 [==============================] - 0s 77us/sample - loss: 0.2597 - accuracy: 0.9081 - val_loss: 0.3311 - val_accuracy: 0.8698\n",
      "Epoch 50/50\n",
      "1719/1719 [==============================] - 0s 71us/sample - loss: 0.2579 - accuracy: 0.9040 - val_loss: 0.3319 - val_accuracy: 0.8558\n",
      "215/215 - 0s - loss: 0.4964 - accuracy: 0.7721\n",
      "215/215 - 0s - loss: 0.3319 - accuracy: 0.8558\n",
      "Loss: 0.4963589056979778, Accuracy: 0.7720929980278015\n",
      "Validation Set - Loss: 0.3318569258201954, Accuracy: 0.8558139801025391\n"
     ]
    }
   ],
   "source": [
    "# Define the deep learning model \n",
    "nn_model = tf.keras.models.Sequential()\n",
    "nn_model.add(tf.keras.layers.Dense(units=16, activation=\"relu\", input_dim=32))\n",
    "\n",
    "# Output layer/binary classification so 1 neuron for 0 or 1\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Compile the Sequential model together and customize metrics\n",
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model w/ validation dataset\n",
    "fit_model = nn_model.fit(X_train_scaled, y_train, epochs=50, validation_data=(X_val_scaled, y_val))\n",
    "\n",
    "# Evaluate the model using the test data + validation data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "model_loss_val, model_accuracy_val = nn_model.evaluate(X_val_scaled, y_val, verbose=2)\n",
    "\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n",
    "print(f\"Validation Set - Loss: {model_loss_val}, Accuracy: {model_accuracy_val}\")\n",
    "\n",
    "# results promising; but attempt to improve "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First start w/ grid search to see if random neuron number was optimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'neurons': 8}\n",
      "Best Score:  0.840619695186615\n"
     ]
    }
   ],
   "source": [
    "# Define the deep learning model function\n",
    "\n",
    "def create_model(neurons=16):\n",
    "    nn_model = tf.keras.models.Sequential()\n",
    "    nn_model.add(tf.keras.layers.Dense(units=neurons, activation=\"relu\", input_dim=32))\n",
    "    nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "    nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "    return nn_model\n",
    "\n",
    "# Create a KerasClassifier based on the model function\n",
    "nn_model = KerasClassifier(build_fn=create_model, epochs=50, batch_size=10, verbose=0)\n",
    "\n",
    "# Define the grid of hyperparameters to search\n",
    "param_grid = {'neurons': [8, 16, 32, 64]}\n",
    "\n",
    "# Perform grid search\n",
    "grid = GridSearchCV(estimator=nn_model, param_grid=param_grid, cv=5)\n",
    "grid_result = grid.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best parameters and results\n",
    "print(\"Best Parameters: \", grid_result.best_params_)\n",
    "print(\"Best Score: \", grid_result.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test model using 8 neurons in layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----> optimized 8 neurons x 1 layer (50 epochs to test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1719 samples, validate on 215 samples\n",
      "Epoch 1/50\n",
      "1719/1719 [==============================] - 1s 297us/sample - loss: 0.7310 - accuracy: 0.5666 - val_loss: 0.6866 - val_accuracy: 0.5953\n",
      "Epoch 2/50\n",
      "1719/1719 [==============================] - 0s 45us/sample - loss: 0.6729 - accuracy: 0.6283 - val_loss: 0.6410 - val_accuracy: 0.6512\n",
      "Epoch 3/50\n",
      "1719/1719 [==============================] - 0s 45us/sample - loss: 0.6270 - accuracy: 0.6830 - val_loss: 0.6019 - val_accuracy: 0.6744\n",
      "Epoch 4/50\n",
      "1719/1719 [==============================] - 0s 42us/sample - loss: 0.5866 - accuracy: 0.7115 - val_loss: 0.5673 - val_accuracy: 0.6744\n",
      "Epoch 5/50\n",
      "1719/1719 [==============================] - 0s 42us/sample - loss: 0.5497 - accuracy: 0.7411 - val_loss: 0.5359 - val_accuracy: 0.7070\n",
      "Epoch 6/50\n",
      "1719/1719 [==============================] - 0s 48us/sample - loss: 0.5161 - accuracy: 0.7615 - val_loss: 0.5088 - val_accuracy: 0.7302\n",
      "Epoch 7/50\n",
      "1719/1719 [==============================] - 0s 43us/sample - loss: 0.4859 - accuracy: 0.7760 - val_loss: 0.4840 - val_accuracy: 0.7442\n",
      "Epoch 8/50\n",
      "1719/1719 [==============================] - 0s 42us/sample - loss: 0.4585 - accuracy: 0.7981 - val_loss: 0.4623 - val_accuracy: 0.7721\n",
      "Epoch 9/50\n",
      "1719/1719 [==============================] - 0s 48us/sample - loss: 0.4356 - accuracy: 0.8086 - val_loss: 0.4456 - val_accuracy: 0.7907\n",
      "Epoch 10/50\n",
      "1719/1719 [==============================] - 0s 44us/sample - loss: 0.4171 - accuracy: 0.8191 - val_loss: 0.4321 - val_accuracy: 0.8093\n",
      "Epoch 11/50\n",
      "1719/1719 [==============================] - 0s 41us/sample - loss: 0.4017 - accuracy: 0.8296 - val_loss: 0.4209 - val_accuracy: 0.8140\n",
      "Epoch 12/50\n",
      "1719/1719 [==============================] - 0s 43us/sample - loss: 0.3898 - accuracy: 0.8348 - val_loss: 0.4111 - val_accuracy: 0.8233\n",
      "Epoch 13/50\n",
      "1719/1719 [==============================] - 0s 43us/sample - loss: 0.3795 - accuracy: 0.8418 - val_loss: 0.4033 - val_accuracy: 0.8279\n",
      "Epoch 14/50\n",
      "1719/1719 [==============================] - 0s 53us/sample - loss: 0.3713 - accuracy: 0.8493 - val_loss: 0.3982 - val_accuracy: 0.8233\n",
      "Epoch 15/50\n",
      "1719/1719 [==============================] - 0s 48us/sample - loss: 0.3640 - accuracy: 0.8493 - val_loss: 0.3914 - val_accuracy: 0.8279\n",
      "Epoch 16/50\n",
      "1719/1719 [==============================] - 0s 43us/sample - loss: 0.3582 - accuracy: 0.8540 - val_loss: 0.3873 - val_accuracy: 0.8279\n",
      "Epoch 17/50\n",
      "1719/1719 [==============================] - 0s 48us/sample - loss: 0.3532 - accuracy: 0.8598 - val_loss: 0.3854 - val_accuracy: 0.8372\n",
      "Epoch 18/50\n",
      "1719/1719 [==============================] - 0s 44us/sample - loss: 0.3486 - accuracy: 0.8604 - val_loss: 0.3801 - val_accuracy: 0.8372\n",
      "Epoch 19/50\n",
      "1719/1719 [==============================] - 0s 37us/sample - loss: 0.3448 - accuracy: 0.8645 - val_loss: 0.3800 - val_accuracy: 0.8326\n",
      "Epoch 20/50\n",
      "1719/1719 [==============================] - 0s 36us/sample - loss: 0.3413 - accuracy: 0.8639 - val_loss: 0.3770 - val_accuracy: 0.8326\n",
      "Epoch 21/50\n",
      "1719/1719 [==============================] - 0s 42us/sample - loss: 0.3390 - accuracy: 0.8662 - val_loss: 0.3746 - val_accuracy: 0.8326\n",
      "Epoch 22/50\n",
      "1719/1719 [==============================] - 0s 43us/sample - loss: 0.3360 - accuracy: 0.8679 - val_loss: 0.3725 - val_accuracy: 0.8372\n",
      "Epoch 23/50\n",
      "1719/1719 [==============================] - 0s 78us/sample - loss: 0.3332 - accuracy: 0.8697 - val_loss: 0.3723 - val_accuracy: 0.8372\n",
      "Epoch 24/50\n",
      "1719/1719 [==============================] - 0s 34us/sample - loss: 0.3309 - accuracy: 0.8720 - val_loss: 0.3719 - val_accuracy: 0.8419\n",
      "Epoch 25/50\n",
      "1719/1719 [==============================] - 0s 36us/sample - loss: 0.3290 - accuracy: 0.8732 - val_loss: 0.3716 - val_accuracy: 0.8372\n",
      "Epoch 26/50\n",
      "1719/1719 [==============================] - 0s 40us/sample - loss: 0.3270 - accuracy: 0.8761 - val_loss: 0.3706 - val_accuracy: 0.8419\n",
      "Epoch 27/50\n",
      "1719/1719 [==============================] - 0s 44us/sample - loss: 0.3246 - accuracy: 0.8743 - val_loss: 0.3689 - val_accuracy: 0.8465\n",
      "Epoch 28/50\n",
      "1719/1719 [==============================] - 0s 39us/sample - loss: 0.3229 - accuracy: 0.8767 - val_loss: 0.3673 - val_accuracy: 0.8465\n",
      "Epoch 29/50\n",
      "1719/1719 [==============================] - 0s 42us/sample - loss: 0.3207 - accuracy: 0.8807 - val_loss: 0.3674 - val_accuracy: 0.8465\n",
      "Epoch 30/50\n",
      "1719/1719 [==============================] - 0s 40us/sample - loss: 0.3191 - accuracy: 0.8807 - val_loss: 0.3659 - val_accuracy: 0.8465\n",
      "Epoch 31/50\n",
      "1719/1719 [==============================] - 0s 41us/sample - loss: 0.3173 - accuracy: 0.8796 - val_loss: 0.3659 - val_accuracy: 0.8465\n",
      "Epoch 32/50\n",
      "1719/1719 [==============================] - 0s 44us/sample - loss: 0.3158 - accuracy: 0.8807 - val_loss: 0.3656 - val_accuracy: 0.8465\n",
      "Epoch 33/50\n",
      "1719/1719 [==============================] - 0s 44us/sample - loss: 0.3144 - accuracy: 0.8831 - val_loss: 0.3649 - val_accuracy: 0.8465\n",
      "Epoch 34/50\n",
      "1719/1719 [==============================] - 0s 45us/sample - loss: 0.3127 - accuracy: 0.8813 - val_loss: 0.3640 - val_accuracy: 0.8465\n",
      "Epoch 35/50\n",
      "1719/1719 [==============================] - 0s 37us/sample - loss: 0.3118 - accuracy: 0.8825 - val_loss: 0.3633 - val_accuracy: 0.8465\n",
      "Epoch 36/50\n",
      "1719/1719 [==============================] - 0s 38us/sample - loss: 0.3101 - accuracy: 0.8813 - val_loss: 0.3638 - val_accuracy: 0.8465\n",
      "Epoch 37/50\n",
      "1719/1719 [==============================] - 0s 43us/sample - loss: 0.3085 - accuracy: 0.8825 - val_loss: 0.3615 - val_accuracy: 0.8465\n",
      "Epoch 38/50\n",
      "1719/1719 [==============================] - 0s 44us/sample - loss: 0.3075 - accuracy: 0.8842 - val_loss: 0.3630 - val_accuracy: 0.8465\n",
      "Epoch 39/50\n",
      "1719/1719 [==============================] - 0s 42us/sample - loss: 0.3061 - accuracy: 0.8871 - val_loss: 0.3626 - val_accuracy: 0.8465\n",
      "Epoch 40/50\n",
      "1719/1719 [==============================] - 0s 45us/sample - loss: 0.3047 - accuracy: 0.8871 - val_loss: 0.3614 - val_accuracy: 0.8465\n",
      "Epoch 41/50\n",
      "1719/1719 [==============================] - 0s 40us/sample - loss: 0.3038 - accuracy: 0.8871 - val_loss: 0.3620 - val_accuracy: 0.8419\n",
      "Epoch 42/50\n",
      "1719/1719 [==============================] - 0s 41us/sample - loss: 0.3029 - accuracy: 0.8866 - val_loss: 0.3617 - val_accuracy: 0.8419\n",
      "Epoch 43/50\n",
      "1719/1719 [==============================] - 0s 44us/sample - loss: 0.3017 - accuracy: 0.8866 - val_loss: 0.3624 - val_accuracy: 0.8419\n",
      "Epoch 44/50\n",
      "1719/1719 [==============================] - 0s 40us/sample - loss: 0.3005 - accuracy: 0.8877 - val_loss: 0.3616 - val_accuracy: 0.8372\n",
      "Epoch 45/50\n",
      "1719/1719 [==============================] - 0s 44us/sample - loss: 0.2994 - accuracy: 0.8877 - val_loss: 0.3611 - val_accuracy: 0.8326\n",
      "Epoch 46/50\n",
      "1719/1719 [==============================] - 0s 39us/sample - loss: 0.2985 - accuracy: 0.8877 - val_loss: 0.3605 - val_accuracy: 0.8279\n",
      "Epoch 47/50\n",
      "1719/1719 [==============================] - 0s 40us/sample - loss: 0.2971 - accuracy: 0.8889 - val_loss: 0.3596 - val_accuracy: 0.8419\n",
      "Epoch 48/50\n",
      "1719/1719 [==============================] - 0s 46us/sample - loss: 0.2968 - accuracy: 0.8871 - val_loss: 0.3589 - val_accuracy: 0.8372\n",
      "Epoch 49/50\n",
      "1719/1719 [==============================] - 0s 69us/sample - loss: 0.2957 - accuracy: 0.8889 - val_loss: 0.3597 - val_accuracy: 0.8419\n",
      "Epoch 50/50\n",
      "1719/1719 [==============================] - 0s 48us/sample - loss: 0.2949 - accuracy: 0.8871 - val_loss: 0.3593 - val_accuracy: 0.8372\n",
      "215/215 - 0s - loss: 0.4471 - accuracy: 0.8093\n",
      "215/215 - 0s - loss: 0.3593 - accuracy: 0.8372\n",
      "Loss: 0.4471356630325317, Accuracy: 0.8093023300170898\n",
      "Validation Set - Loss: 0.35927448757859165, Accuracy: 0.8372092843055725\n"
     ]
    }
   ],
   "source": [
    "# Define the deep learning model \n",
    "nn_model = tf.keras.models.Sequential()\n",
    "nn_model.add(tf.keras.layers.Dense(units=8, activation=\"relu\", input_dim=32))\n",
    "\n",
    "# Output layer/binary classification so 1 neuron for 0 or 1\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Compile the Sequential model together and customize metrics\n",
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model w/ validation dataset\n",
    "fit_model = nn_model.fit(X_train_scaled, y_train, epochs=50, validation_data=(X_val_scaled, y_val))\n",
    "\n",
    "# Evaluate the model using the test data + validation data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "model_loss_val, model_accuracy_val = nn_model.evaluate(X_val_scaled, y_val, verbose=2)\n",
    "\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n",
    "print(f\"Validation Set - Loss: {model_loss_val}, Accuracy: {model_accuracy_val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decrease neurons to = 8 increase accuracy for model, and slight decrease in validation (both values now over 0.8; keep neurons = 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking optimization of epochs # using GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'epochs': 20}\n",
      "Best Score:  0.8429435849189758\n"
     ]
    }
   ],
   "source": [
    "# Define the deep learning model function\n",
    "\n",
    "def create_model(neurons=8):\n",
    "    nn_model = tf.keras.models.Sequential()\n",
    "    nn_model.add(tf.keras.layers.Dense(units=neurons, activation=\"relu\", input_dim=32))\n",
    "    nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "    nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "    return nn_model\n",
    "\n",
    "# Create a KerasClassifier based on the model function\n",
    "nn_model = KerasClassifier(build_fn=create_model, epochs=50, batch_size=10, verbose=0)\n",
    "\n",
    "# Define the grid of hyperparameters to search\n",
    "param_grid = {'epochs': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]}\n",
    "\n",
    "# Perform grid search\n",
    "grid = GridSearchCV(estimator=nn_model, param_grid=param_grid, cv=5)\n",
    "grid_result = grid.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best parameters and results\n",
    "print(\"Best Parameters: \", grid_result.best_params_)\n",
    "print(\"Best Score: \", grid_result.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking validation set using new parameters (optimized epochs=20 as well as neuron =8 in single layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1719 samples, validate on 215 samples\n",
      "Epoch 1/20\n",
      "1719/1719 [==============================] - 1s 294us/sample - loss: 0.6932 - accuracy: 0.6341 - val_loss: 0.6265 - val_accuracy: 0.6372\n",
      "Epoch 2/20\n",
      "1719/1719 [==============================] - 0s 40us/sample - loss: 0.6137 - accuracy: 0.6818 - val_loss: 0.5659 - val_accuracy: 0.6930\n",
      "Epoch 3/20\n",
      "1719/1719 [==============================] - 0s 41us/sample - loss: 0.5568 - accuracy: 0.7248 - val_loss: 0.5246 - val_accuracy: 0.7302\n",
      "Epoch 4/20\n",
      "1719/1719 [==============================] - 0s 41us/sample - loss: 0.5145 - accuracy: 0.7510 - val_loss: 0.4949 - val_accuracy: 0.7674\n",
      "Epoch 5/20\n",
      "1719/1719 [==============================] - 0s 41us/sample - loss: 0.4819 - accuracy: 0.7778 - val_loss: 0.4697 - val_accuracy: 0.7814\n",
      "Epoch 6/20\n",
      "1719/1719 [==============================] - 0s 41us/sample - loss: 0.4563 - accuracy: 0.7917 - val_loss: 0.4501 - val_accuracy: 0.7860\n",
      "Epoch 7/20\n",
      "1719/1719 [==============================] - 0s 41us/sample - loss: 0.4356 - accuracy: 0.8051 - val_loss: 0.4365 - val_accuracy: 0.7953\n",
      "Epoch 8/20\n",
      "1719/1719 [==============================] - 0s 46us/sample - loss: 0.4194 - accuracy: 0.8150 - val_loss: 0.4250 - val_accuracy: 0.7953\n",
      "Epoch 9/20\n",
      "1719/1719 [==============================] - 0s 43us/sample - loss: 0.4056 - accuracy: 0.8202 - val_loss: 0.4145 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "1719/1719 [==============================] - 0s 41us/sample - loss: 0.3949 - accuracy: 0.8261 - val_loss: 0.4076 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "1719/1719 [==============================] - 0s 43us/sample - loss: 0.3860 - accuracy: 0.8342 - val_loss: 0.4018 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "1719/1719 [==============================] - 0s 42us/sample - loss: 0.3784 - accuracy: 0.8354 - val_loss: 0.3961 - val_accuracy: 0.8047\n",
      "Epoch 13/20\n",
      "1719/1719 [==============================] - 0s 40us/sample - loss: 0.3712 - accuracy: 0.8406 - val_loss: 0.3910 - val_accuracy: 0.8140\n",
      "Epoch 14/20\n",
      "1719/1719 [==============================] - 0s 39us/sample - loss: 0.3661 - accuracy: 0.8464 - val_loss: 0.3881 - val_accuracy: 0.8093\n",
      "Epoch 15/20\n",
      "1719/1719 [==============================] - 0s 45us/sample - loss: 0.3614 - accuracy: 0.8528 - val_loss: 0.3845 - val_accuracy: 0.8186\n",
      "Epoch 16/20\n",
      "1719/1719 [==============================] - 0s 37us/sample - loss: 0.3576 - accuracy: 0.8499 - val_loss: 0.3821 - val_accuracy: 0.8279\n",
      "Epoch 17/20\n",
      "1719/1719 [==============================] - 0s 43us/sample - loss: 0.3537 - accuracy: 0.8551 - val_loss: 0.3800 - val_accuracy: 0.8279\n",
      "Epoch 18/20\n",
      "1719/1719 [==============================] - 0s 41us/sample - loss: 0.3506 - accuracy: 0.8586 - val_loss: 0.3776 - val_accuracy: 0.8233\n",
      "Epoch 19/20\n",
      "1719/1719 [==============================] - 0s 39us/sample - loss: 0.3479 - accuracy: 0.8592 - val_loss: 0.3776 - val_accuracy: 0.8233\n",
      "Epoch 20/20\n",
      "1719/1719 [==============================] - 0s 51us/sample - loss: 0.3452 - accuracy: 0.8610 - val_loss: 0.3755 - val_accuracy: 0.8279\n",
      "215/215 - 0s - loss: 0.4425 - accuracy: 0.8093\n",
      "215/215 - 0s - loss: 0.3755 - accuracy: 0.8279\n",
      "Loss: 0.44248663131580795, Accuracy: 0.8093023300170898\n",
      "Validation Set - Loss: 0.37551643321680467, Accuracy: 0.8279069662094116\n"
     ]
    }
   ],
   "source": [
    "# Define the deep learning model \n",
    "nn_model = tf.keras.models.Sequential()\n",
    "nn_model.add(tf.keras.layers.Dense(units=8, activation=\"relu\", input_dim=32))\n",
    "\n",
    "# Output layer/binary classification so 1 neuron for 0 or 1\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Compile the Sequential model together and customize metrics\n",
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model w/ validation dataset\n",
    "fit_model = nn_model.fit(X_train_scaled, y_train, epochs=20, validation_data=(X_val_scaled, y_val))\n",
    "\n",
    "# Evaluate the model using the test data + validation data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "model_loss_val, model_accuracy_val = nn_model.evaluate(X_val_scaled, y_val, verbose=2)\n",
    "\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n",
    "print(f\"Validation Set - Loss: {model_loss_val}, Accuracy: {model_accuracy_val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying epochs=40 because epochs=20 is lower than 50 (balanced with validation) -- keep epochs =50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1719 samples, validate on 215 samples\n",
      "Epoch 1/40\n",
      "1719/1719 [==============================] - 1s 387us/sample - loss: 1.0041 - accuracy: 0.3828 - val_loss: 0.9456 - val_accuracy: 0.4372\n",
      "Epoch 2/40\n",
      "1719/1719 [==============================] - 0s 40us/sample - loss: 0.8308 - accuracy: 0.4642 - val_loss: 0.8011 - val_accuracy: 0.4605\n",
      "Epoch 3/40\n",
      "1719/1719 [==============================] - 0s 44us/sample - loss: 0.7197 - accuracy: 0.5590 - val_loss: 0.7059 - val_accuracy: 0.5581\n",
      "Epoch 4/40\n",
      "1719/1719 [==============================] - 0s 44us/sample - loss: 0.6450 - accuracy: 0.6318 - val_loss: 0.6413 - val_accuracy: 0.6558\n",
      "Epoch 5/40\n",
      "1719/1719 [==============================] - 0s 46us/sample - loss: 0.5897 - accuracy: 0.6905 - val_loss: 0.5914 - val_accuracy: 0.6930\n",
      "Epoch 6/40\n",
      "1719/1719 [==============================] - 0s 41us/sample - loss: 0.5473 - accuracy: 0.7243 - val_loss: 0.5520 - val_accuracy: 0.7023\n",
      "Epoch 7/40\n",
      "1719/1719 [==============================] - 0s 45us/sample - loss: 0.5130 - accuracy: 0.7545 - val_loss: 0.5218 - val_accuracy: 0.7302\n",
      "Epoch 8/40\n",
      "1719/1719 [==============================] - 0s 42us/sample - loss: 0.4845 - accuracy: 0.7836 - val_loss: 0.4973 - val_accuracy: 0.7535\n",
      "Epoch 9/40\n",
      "1719/1719 [==============================] - 0s 47us/sample - loss: 0.4609 - accuracy: 0.8010 - val_loss: 0.4764 - val_accuracy: 0.7628\n",
      "Epoch 10/40\n",
      "1719/1719 [==============================] - 0s 43us/sample - loss: 0.4408 - accuracy: 0.8179 - val_loss: 0.4583 - val_accuracy: 0.7628\n",
      "Epoch 11/40\n",
      "1719/1719 [==============================] - 0s 41us/sample - loss: 0.4236 - accuracy: 0.8237 - val_loss: 0.4427 - val_accuracy: 0.7674\n",
      "Epoch 12/40\n",
      "1719/1719 [==============================] - 0s 55us/sample - loss: 0.4085 - accuracy: 0.8325 - val_loss: 0.4300 - val_accuracy: 0.7721\n",
      "Epoch 13/40\n",
      "1719/1719 [==============================] - 0s 35us/sample - loss: 0.3959 - accuracy: 0.8360 - val_loss: 0.4174 - val_accuracy: 0.7907\n",
      "Epoch 14/40\n",
      "1719/1719 [==============================] - 0s 41us/sample - loss: 0.3852 - accuracy: 0.8424 - val_loss: 0.4083 - val_accuracy: 0.8047\n",
      "Epoch 15/40\n",
      "1719/1719 [==============================] - 0s 41us/sample - loss: 0.3764 - accuracy: 0.8464 - val_loss: 0.4001 - val_accuracy: 0.8093\n",
      "Epoch 16/40\n",
      "1719/1719 [==============================] - 0s 39us/sample - loss: 0.3688 - accuracy: 0.8540 - val_loss: 0.3936 - val_accuracy: 0.8047\n",
      "Epoch 17/40\n",
      "1719/1719 [==============================] - 0s 42us/sample - loss: 0.3625 - accuracy: 0.8534 - val_loss: 0.3878 - val_accuracy: 0.8093\n",
      "Epoch 18/40\n",
      "1719/1719 [==============================] - 0s 42us/sample - loss: 0.3572 - accuracy: 0.8540 - val_loss: 0.3816 - val_accuracy: 0.8093\n",
      "Epoch 19/40\n",
      "1719/1719 [==============================] - 0s 44us/sample - loss: 0.3523 - accuracy: 0.8575 - val_loss: 0.3780 - val_accuracy: 0.8140\n",
      "Epoch 20/40\n",
      "1719/1719 [==============================] - 0s 45us/sample - loss: 0.3486 - accuracy: 0.8621 - val_loss: 0.3728 - val_accuracy: 0.8186\n",
      "Epoch 21/40\n",
      "1719/1719 [==============================] - 0s 41us/sample - loss: 0.3448 - accuracy: 0.8645 - val_loss: 0.3705 - val_accuracy: 0.8186\n",
      "Epoch 22/40\n",
      "1719/1719 [==============================] - 0s 78us/sample - loss: 0.3417 - accuracy: 0.8639 - val_loss: 0.3670 - val_accuracy: 0.8233\n",
      "Epoch 23/40\n",
      "1719/1719 [==============================] - 0s 35us/sample - loss: 0.3387 - accuracy: 0.8650 - val_loss: 0.3645 - val_accuracy: 0.8279\n",
      "Epoch 24/40\n",
      "1719/1719 [==============================] - 0s 32us/sample - loss: 0.3363 - accuracy: 0.8674 - val_loss: 0.3621 - val_accuracy: 0.8326\n",
      "Epoch 25/40\n",
      "1719/1719 [==============================] - 0s 39us/sample - loss: 0.3341 - accuracy: 0.8674 - val_loss: 0.3602 - val_accuracy: 0.8279\n",
      "Epoch 26/40\n",
      "1719/1719 [==============================] - 0s 40us/sample - loss: 0.3324 - accuracy: 0.8703 - val_loss: 0.3594 - val_accuracy: 0.8279\n",
      "Epoch 27/40\n",
      "1719/1719 [==============================] - 0s 43us/sample - loss: 0.3303 - accuracy: 0.8697 - val_loss: 0.3566 - val_accuracy: 0.8326\n",
      "Epoch 28/40\n",
      "1719/1719 [==============================] - 0s 41us/sample - loss: 0.3285 - accuracy: 0.8720 - val_loss: 0.3565 - val_accuracy: 0.8279\n",
      "Epoch 29/40\n",
      "1719/1719 [==============================] - 0s 36us/sample - loss: 0.3271 - accuracy: 0.8720 - val_loss: 0.3549 - val_accuracy: 0.8326\n",
      "Epoch 30/40\n",
      "1719/1719 [==============================] - 0s 39us/sample - loss: 0.3255 - accuracy: 0.8726 - val_loss: 0.3552 - val_accuracy: 0.8326\n",
      "Epoch 31/40\n",
      "1719/1719 [==============================] - 0s 45us/sample - loss: 0.3235 - accuracy: 0.8749 - val_loss: 0.3530 - val_accuracy: 0.8465\n",
      "Epoch 32/40\n",
      "1719/1719 [==============================] - 0s 34us/sample - loss: 0.3223 - accuracy: 0.8720 - val_loss: 0.3514 - val_accuracy: 0.8419\n",
      "Epoch 33/40\n",
      "1719/1719 [==============================] - 0s 35us/sample - loss: 0.3207 - accuracy: 0.8761 - val_loss: 0.3511 - val_accuracy: 0.8419\n",
      "Epoch 34/40\n",
      "1719/1719 [==============================] - 0s 39us/sample - loss: 0.3192 - accuracy: 0.8778 - val_loss: 0.3508 - val_accuracy: 0.8419\n",
      "Epoch 35/40\n",
      "1719/1719 [==============================] - 0s 43us/sample - loss: 0.3181 - accuracy: 0.8773 - val_loss: 0.3486 - val_accuracy: 0.8419\n",
      "Epoch 36/40\n",
      "1719/1719 [==============================] - 0s 42us/sample - loss: 0.3169 - accuracy: 0.8773 - val_loss: 0.3486 - val_accuracy: 0.8465\n",
      "Epoch 37/40\n",
      "1719/1719 [==============================] - 0s 38us/sample - loss: 0.3155 - accuracy: 0.8790 - val_loss: 0.3469 - val_accuracy: 0.8465\n",
      "Epoch 38/40\n",
      "1719/1719 [==============================] - 0s 43us/sample - loss: 0.3140 - accuracy: 0.8790 - val_loss: 0.3462 - val_accuracy: 0.8419\n",
      "Epoch 39/40\n",
      "1719/1719 [==============================] - 0s 37us/sample - loss: 0.3132 - accuracy: 0.8796 - val_loss: 0.3469 - val_accuracy: 0.8419\n",
      "Epoch 40/40\n",
      "1719/1719 [==============================] - 0s 45us/sample - loss: 0.3118 - accuracy: 0.8784 - val_loss: 0.3456 - val_accuracy: 0.8465\n",
      "215/215 - 0s - loss: 0.4788 - accuracy: 0.7767\n",
      "215/215 - 0s - loss: 0.3456 - accuracy: 0.8465\n",
      "Loss: 0.47875270386074864, Accuracy: 0.7767441868782043\n",
      "Validation Set - Loss: 0.3455992439458537, Accuracy: 0.8465116024017334\n"
     ]
    }
   ],
   "source": [
    "# Define the deep learning model \n",
    "nn_model = tf.keras.models.Sequential()\n",
    "nn_model.add(tf.keras.layers.Dense(units=8, activation=\"relu\", input_dim=32))\n",
    "\n",
    "# Output layer/binary classification so 1 neuron for 0 or 1\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Compile the Sequential model together and customize metrics\n",
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model w/ validation dataset\n",
    "fit_model = nn_model.fit(X_train_scaled, y_train, epochs=40, validation_data=(X_val_scaled, y_val))\n",
    "\n",
    "# Evaluate the model using the test data + validation data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "model_loss_val, model_accuracy_val = nn_model.evaluate(X_val_scaled, y_val, verbose=2)\n",
    "\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n",
    "print(f\"Validation Set - Loss: {model_loss_val}, Accuracy: {model_accuracy_val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increasing epochs further from 50 also lowers accuracy for both test and validation -- keep 50 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1719 samples, validate on 215 samples\n",
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 1s 323us/sample - loss: 0.8805 - accuracy: 0.4287 - val_loss: 0.7711 - val_accuracy: 0.5163\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 0s 56us/sample - loss: 0.7780 - accuracy: 0.5137 - val_loss: 0.6949 - val_accuracy: 0.5767\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 0s 45us/sample - loss: 0.7097 - accuracy: 0.5858 - val_loss: 0.6436 - val_accuracy: 0.6186\n",
      "Epoch 4/100\n",
      "1719/1719 [==============================] - 0s 41us/sample - loss: 0.6573 - accuracy: 0.6376 - val_loss: 0.6063 - val_accuracy: 0.6977\n",
      "Epoch 5/100\n",
      "1719/1719 [==============================] - 0s 41us/sample - loss: 0.6131 - accuracy: 0.6882 - val_loss: 0.5745 - val_accuracy: 0.7535\n",
      "Epoch 6/100\n",
      "1719/1719 [==============================] - 0s 39us/sample - loss: 0.5727 - accuracy: 0.7266 - val_loss: 0.5453 - val_accuracy: 0.7814\n",
      "Epoch 7/100\n",
      "1719/1719 [==============================] - 0s 43us/sample - loss: 0.5351 - accuracy: 0.7539 - val_loss: 0.5169 - val_accuracy: 0.7767\n",
      "Epoch 8/100\n",
      "1719/1719 [==============================] - 0s 41us/sample - loss: 0.5019 - accuracy: 0.7737 - val_loss: 0.4910 - val_accuracy: 0.7535\n",
      "Epoch 9/100\n",
      "1719/1719 [==============================] - 0s 42us/sample - loss: 0.4725 - accuracy: 0.7981 - val_loss: 0.4675 - val_accuracy: 0.7628\n",
      "Epoch 10/100\n",
      "1719/1719 [==============================] - 0s 49us/sample - loss: 0.4472 - accuracy: 0.8115 - val_loss: 0.4478 - val_accuracy: 0.7721\n",
      "Epoch 11/100\n",
      "1719/1719 [==============================] - 0s 47us/sample - loss: 0.4270 - accuracy: 0.8272 - val_loss: 0.4315 - val_accuracy: 0.7674\n",
      "Epoch 12/100\n",
      "1719/1719 [==============================] - 0s 46us/sample - loss: 0.4093 - accuracy: 0.8336 - val_loss: 0.4175 - val_accuracy: 0.7814\n",
      "Epoch 13/100\n",
      "1719/1719 [==============================] - 0s 45us/sample - loss: 0.3957 - accuracy: 0.8412 - val_loss: 0.4048 - val_accuracy: 0.7907\n",
      "Epoch 14/100\n",
      "1719/1719 [==============================] - 0s 43us/sample - loss: 0.3841 - accuracy: 0.8487 - val_loss: 0.3941 - val_accuracy: 0.7907\n",
      "Epoch 15/100\n",
      "1719/1719 [==============================] - 0s 41us/sample - loss: 0.3750 - accuracy: 0.8534 - val_loss: 0.3866 - val_accuracy: 0.7907\n",
      "Epoch 16/100\n",
      "1719/1719 [==============================] - 0s 48us/sample - loss: 0.3673 - accuracy: 0.8546 - val_loss: 0.3792 - val_accuracy: 0.7907\n",
      "Epoch 17/100\n",
      "1719/1719 [==============================] - 0s 45us/sample - loss: 0.3610 - accuracy: 0.8557 - val_loss: 0.3737 - val_accuracy: 0.8000\n",
      "Epoch 18/100\n",
      "1719/1719 [==============================] - 0s 45us/sample - loss: 0.3557 - accuracy: 0.8557 - val_loss: 0.3692 - val_accuracy: 0.8000\n",
      "Epoch 19/100\n",
      "1719/1719 [==============================] - 0s 71us/sample - loss: 0.3513 - accuracy: 0.8604 - val_loss: 0.3650 - val_accuracy: 0.8000\n",
      "Epoch 20/100\n",
      "1719/1719 [==============================] - 0s 48us/sample - loss: 0.3471 - accuracy: 0.8610 - val_loss: 0.3614 - val_accuracy: 0.8047\n",
      "Epoch 21/100\n",
      "1719/1719 [==============================] - 0s 35us/sample - loss: 0.3439 - accuracy: 0.8604 - val_loss: 0.3578 - val_accuracy: 0.8093\n",
      "Epoch 22/100\n",
      "1719/1719 [==============================] - 0s 37us/sample - loss: 0.3409 - accuracy: 0.8639 - val_loss: 0.3557 - val_accuracy: 0.8140\n",
      "Epoch 23/100\n",
      "1719/1719 [==============================] - 0s 47us/sample - loss: 0.3382 - accuracy: 0.8650 - val_loss: 0.3555 - val_accuracy: 0.8140\n",
      "Epoch 24/100\n",
      "1719/1719 [==============================] - 0s 42us/sample - loss: 0.3358 - accuracy: 0.8668 - val_loss: 0.3535 - val_accuracy: 0.8093\n",
      "Epoch 25/100\n",
      "1719/1719 [==============================] - 0s 39us/sample - loss: 0.3336 - accuracy: 0.8668 - val_loss: 0.3517 - val_accuracy: 0.8093\n",
      "Epoch 26/100\n",
      "1719/1719 [==============================] - 0s 47us/sample - loss: 0.3316 - accuracy: 0.8679 - val_loss: 0.3497 - val_accuracy: 0.8140\n",
      "Epoch 27/100\n",
      "1719/1719 [==============================] - 0s 39us/sample - loss: 0.3293 - accuracy: 0.8685 - val_loss: 0.3489 - val_accuracy: 0.8233\n",
      "Epoch 28/100\n",
      "1719/1719 [==============================] - 0s 37us/sample - loss: 0.3276 - accuracy: 0.8703 - val_loss: 0.3489 - val_accuracy: 0.8233\n",
      "Epoch 29/100\n",
      "1719/1719 [==============================] - 0s 43us/sample - loss: 0.3257 - accuracy: 0.8703 - val_loss: 0.3473 - val_accuracy: 0.8233\n",
      "Epoch 30/100\n",
      "1719/1719 [==============================] - 0s 36us/sample - loss: 0.3245 - accuracy: 0.8709 - val_loss: 0.3467 - val_accuracy: 0.8186\n",
      "Epoch 31/100\n",
      "1719/1719 [==============================] - 0s 45us/sample - loss: 0.3222 - accuracy: 0.8726 - val_loss: 0.3443 - val_accuracy: 0.8233\n",
      "Epoch 32/100\n",
      "1719/1719 [==============================] - 0s 46us/sample - loss: 0.3210 - accuracy: 0.8749 - val_loss: 0.3444 - val_accuracy: 0.8233\n",
      "Epoch 33/100\n",
      "1719/1719 [==============================] - 0s 43us/sample - loss: 0.3194 - accuracy: 0.8732 - val_loss: 0.3447 - val_accuracy: 0.8233\n",
      "Epoch 34/100\n",
      "1719/1719 [==============================] - 0s 41us/sample - loss: 0.3176 - accuracy: 0.8749 - val_loss: 0.3442 - val_accuracy: 0.8233\n",
      "Epoch 35/100\n",
      "1719/1719 [==============================] - 0s 51us/sample - loss: 0.3165 - accuracy: 0.8761 - val_loss: 0.3422 - val_accuracy: 0.8233\n",
      "Epoch 36/100\n",
      "1719/1719 [==============================] - 0s 43us/sample - loss: 0.3154 - accuracy: 0.8761 - val_loss: 0.3429 - val_accuracy: 0.8233\n",
      "Epoch 37/100\n",
      "1719/1719 [==============================] - 0s 54us/sample - loss: 0.3142 - accuracy: 0.8743 - val_loss: 0.3433 - val_accuracy: 0.8233\n",
      "Epoch 38/100\n",
      "1719/1719 [==============================] - 0s 39us/sample - loss: 0.3127 - accuracy: 0.8761 - val_loss: 0.3420 - val_accuracy: 0.8279\n",
      "Epoch 39/100\n",
      "1719/1719 [==============================] - 0s 74us/sample - loss: 0.3116 - accuracy: 0.8761 - val_loss: 0.3418 - val_accuracy: 0.8279\n",
      "Epoch 40/100\n",
      "1719/1719 [==============================] - 0s 48us/sample - loss: 0.3107 - accuracy: 0.8755 - val_loss: 0.3417 - val_accuracy: 0.8326\n",
      "Epoch 41/100\n",
      "1719/1719 [==============================] - 0s 45us/sample - loss: 0.3097 - accuracy: 0.8749 - val_loss: 0.3414 - val_accuracy: 0.8372\n",
      "Epoch 42/100\n",
      "1719/1719 [==============================] - 0s 42us/sample - loss: 0.3083 - accuracy: 0.8749 - val_loss: 0.3421 - val_accuracy: 0.8326\n",
      "Epoch 43/100\n",
      "1719/1719 [==============================] - 0s 43us/sample - loss: 0.3075 - accuracy: 0.8773 - val_loss: 0.3416 - val_accuracy: 0.8372\n",
      "Epoch 44/100\n",
      "1719/1719 [==============================] - 0s 41us/sample - loss: 0.3066 - accuracy: 0.8767 - val_loss: 0.3400 - val_accuracy: 0.8419\n",
      "Epoch 45/100\n",
      "1719/1719 [==============================] - 0s 50us/sample - loss: 0.3054 - accuracy: 0.8749 - val_loss: 0.3398 - val_accuracy: 0.8419\n",
      "Epoch 46/100\n",
      "1719/1719 [==============================] - 0s 37us/sample - loss: 0.3042 - accuracy: 0.8755 - val_loss: 0.3402 - val_accuracy: 0.8419\n",
      "Epoch 47/100\n",
      "1719/1719 [==============================] - 0s 49us/sample - loss: 0.3036 - accuracy: 0.8778 - val_loss: 0.3408 - val_accuracy: 0.8419\n",
      "Epoch 48/100\n",
      "1719/1719 [==============================] - 0s 38us/sample - loss: 0.3026 - accuracy: 0.8784 - val_loss: 0.3424 - val_accuracy: 0.8326\n",
      "Epoch 49/100\n",
      "1719/1719 [==============================] - 0s 53us/sample - loss: 0.3018 - accuracy: 0.8761 - val_loss: 0.3407 - val_accuracy: 0.8419\n",
      "Epoch 50/100\n",
      "1719/1719 [==============================] - 0s 47us/sample - loss: 0.3008 - accuracy: 0.8784 - val_loss: 0.3403 - val_accuracy: 0.8326\n",
      "Epoch 51/100\n",
      "1719/1719 [==============================] - 0s 39us/sample - loss: 0.2998 - accuracy: 0.8790 - val_loss: 0.3414 - val_accuracy: 0.8372\n",
      "Epoch 52/100\n",
      "1719/1719 [==============================] - 0s 46us/sample - loss: 0.2987 - accuracy: 0.8796 - val_loss: 0.3410 - val_accuracy: 0.8372\n",
      "Epoch 53/100\n",
      "1719/1719 [==============================] - 0s 45us/sample - loss: 0.2980 - accuracy: 0.8778 - val_loss: 0.3412 - val_accuracy: 0.8326\n",
      "Epoch 54/100\n",
      "1719/1719 [==============================] - 0s 39us/sample - loss: 0.2970 - accuracy: 0.8802 - val_loss: 0.3410 - val_accuracy: 0.8372\n",
      "Epoch 55/100\n",
      "1719/1719 [==============================] - 0s 38us/sample - loss: 0.2962 - accuracy: 0.8802 - val_loss: 0.3429 - val_accuracy: 0.8326\n",
      "Epoch 56/100\n",
      "1719/1719 [==============================] - 0s 40us/sample - loss: 0.2957 - accuracy: 0.8825 - val_loss: 0.3400 - val_accuracy: 0.8326\n",
      "Epoch 57/100\n",
      "1719/1719 [==============================] - 0s 41us/sample - loss: 0.2944 - accuracy: 0.8837 - val_loss: 0.3430 - val_accuracy: 0.8326\n",
      "Epoch 58/100\n",
      "1719/1719 [==============================] - 0s 36us/sample - loss: 0.2938 - accuracy: 0.8807 - val_loss: 0.3431 - val_accuracy: 0.8326\n",
      "Epoch 59/100\n",
      "1719/1719 [==============================] - 0s 35us/sample - loss: 0.2932 - accuracy: 0.8819 - val_loss: 0.3422 - val_accuracy: 0.8372\n",
      "Epoch 60/100\n",
      "1719/1719 [==============================] - 0s 41us/sample - loss: 0.2921 - accuracy: 0.8796 - val_loss: 0.3422 - val_accuracy: 0.8372\n",
      "Epoch 61/100\n",
      "1719/1719 [==============================] - 0s 45us/sample - loss: 0.2912 - accuracy: 0.8825 - val_loss: 0.3439 - val_accuracy: 0.8372\n",
      "Epoch 62/100\n",
      "1719/1719 [==============================] - 0s 41us/sample - loss: 0.2911 - accuracy: 0.8807 - val_loss: 0.3431 - val_accuracy: 0.8372\n",
      "Epoch 63/100\n",
      "1719/1719 [==============================] - 0s 52us/sample - loss: 0.2903 - accuracy: 0.8819 - val_loss: 0.3437 - val_accuracy: 0.8326\n",
      "Epoch 64/100\n",
      "1719/1719 [==============================] - 0s 39us/sample - loss: 0.2897 - accuracy: 0.8813 - val_loss: 0.3457 - val_accuracy: 0.8372\n",
      "Epoch 65/100\n",
      "1719/1719 [==============================] - 0s 44us/sample - loss: 0.2890 - accuracy: 0.8813 - val_loss: 0.3441 - val_accuracy: 0.8372\n",
      "Epoch 66/100\n",
      "1719/1719 [==============================] - 0s 48us/sample - loss: 0.2880 - accuracy: 0.8831 - val_loss: 0.3443 - val_accuracy: 0.8279\n",
      "Epoch 67/100\n",
      "1719/1719 [==============================] - 0s 40us/sample - loss: 0.2878 - accuracy: 0.8807 - val_loss: 0.3469 - val_accuracy: 0.8419\n",
      "Epoch 68/100\n",
      "1719/1719 [==============================] - 0s 41us/sample - loss: 0.2875 - accuracy: 0.8825 - val_loss: 0.3467 - val_accuracy: 0.8279\n",
      "Epoch 69/100\n",
      "1719/1719 [==============================] - 0s 48us/sample - loss: 0.2864 - accuracy: 0.8825 - val_loss: 0.3474 - val_accuracy: 0.8419\n",
      "Epoch 70/100\n",
      "1719/1719 [==============================] - 0s 42us/sample - loss: 0.2860 - accuracy: 0.8831 - val_loss: 0.3497 - val_accuracy: 0.8279\n",
      "Epoch 71/100\n",
      "1719/1719 [==============================] - 0s 39us/sample - loss: 0.2854 - accuracy: 0.8819 - val_loss: 0.3494 - val_accuracy: 0.8326\n",
      "Epoch 72/100\n",
      "1719/1719 [==============================] - 0s 48us/sample - loss: 0.2845 - accuracy: 0.8842 - val_loss: 0.3509 - val_accuracy: 0.8326\n",
      "Epoch 73/100\n",
      "1719/1719 [==============================] - 0s 40us/sample - loss: 0.2842 - accuracy: 0.8877 - val_loss: 0.3494 - val_accuracy: 0.8326\n",
      "Epoch 74/100\n",
      "1719/1719 [==============================] - 0s 41us/sample - loss: 0.2831 - accuracy: 0.8866 - val_loss: 0.3528 - val_accuracy: 0.8279\n",
      "Epoch 75/100\n",
      "1719/1719 [==============================] - 0s 48us/sample - loss: 0.2827 - accuracy: 0.8860 - val_loss: 0.3527 - val_accuracy: 0.8326\n",
      "Epoch 76/100\n",
      "1719/1719 [==============================] - 0s 38us/sample - loss: 0.2819 - accuracy: 0.8871 - val_loss: 0.3527 - val_accuracy: 0.8326\n",
      "Epoch 77/100\n",
      "1719/1719 [==============================] - 0s 50us/sample - loss: 0.2816 - accuracy: 0.8866 - val_loss: 0.3523 - val_accuracy: 0.8326\n",
      "Epoch 78/100\n",
      "1719/1719 [==============================] - 0s 39us/sample - loss: 0.2811 - accuracy: 0.8842 - val_loss: 0.3542 - val_accuracy: 0.8326\n",
      "Epoch 79/100\n",
      "1719/1719 [==============================] - 0s 83us/sample - loss: 0.2803 - accuracy: 0.8854 - val_loss: 0.3543 - val_accuracy: 0.8279\n",
      "Epoch 80/100\n",
      "1719/1719 [==============================] - 0s 43us/sample - loss: 0.2800 - accuracy: 0.8871 - val_loss: 0.3556 - val_accuracy: 0.8326\n",
      "Epoch 81/100\n",
      "1719/1719 [==============================] - 0s 38us/sample - loss: 0.2795 - accuracy: 0.8889 - val_loss: 0.3565 - val_accuracy: 0.8326\n",
      "Epoch 82/100\n",
      "1719/1719 [==============================] - 0s 45us/sample - loss: 0.2790 - accuracy: 0.8866 - val_loss: 0.3567 - val_accuracy: 0.8326\n",
      "Epoch 83/100\n",
      "1719/1719 [==============================] - 0s 41us/sample - loss: 0.2785 - accuracy: 0.8889 - val_loss: 0.3565 - val_accuracy: 0.8279\n",
      "Epoch 84/100\n",
      "1719/1719 [==============================] - 0s 46us/sample - loss: 0.2774 - accuracy: 0.8877 - val_loss: 0.3567 - val_accuracy: 0.8326\n",
      "Epoch 85/100\n",
      "1719/1719 [==============================] - 0s 51us/sample - loss: 0.2775 - accuracy: 0.8866 - val_loss: 0.3590 - val_accuracy: 0.8326\n",
      "Epoch 86/100\n",
      "1719/1719 [==============================] - 0s 39us/sample - loss: 0.2766 - accuracy: 0.8871 - val_loss: 0.3603 - val_accuracy: 0.8233\n",
      "Epoch 87/100\n",
      "1719/1719 [==============================] - 0s 42us/sample - loss: 0.2759 - accuracy: 0.8889 - val_loss: 0.3587 - val_accuracy: 0.8279\n",
      "Epoch 88/100\n",
      "1719/1719 [==============================] - 0s 42us/sample - loss: 0.2758 - accuracy: 0.8889 - val_loss: 0.3616 - val_accuracy: 0.8233\n",
      "Epoch 89/100\n",
      "1719/1719 [==============================] - 0s 47us/sample - loss: 0.2753 - accuracy: 0.8877 - val_loss: 0.3614 - val_accuracy: 0.8233\n",
      "Epoch 90/100\n",
      "1719/1719 [==============================] - 0s 44us/sample - loss: 0.2745 - accuracy: 0.8889 - val_loss: 0.3631 - val_accuracy: 0.8233\n",
      "Epoch 91/100\n",
      "1719/1719 [==============================] - 0s 46us/sample - loss: 0.2740 - accuracy: 0.8906 - val_loss: 0.3634 - val_accuracy: 0.8233\n",
      "Epoch 92/100\n",
      "1719/1719 [==============================] - 0s 46us/sample - loss: 0.2735 - accuracy: 0.8883 - val_loss: 0.3653 - val_accuracy: 0.8279\n",
      "Epoch 93/100\n",
      "1719/1719 [==============================] - 0s 39us/sample - loss: 0.2727 - accuracy: 0.8889 - val_loss: 0.3672 - val_accuracy: 0.8233\n",
      "Epoch 94/100\n",
      "1719/1719 [==============================] - 0s 41us/sample - loss: 0.2720 - accuracy: 0.8924 - val_loss: 0.3641 - val_accuracy: 0.8279\n",
      "Epoch 95/100\n",
      "1719/1719 [==============================] - 0s 48us/sample - loss: 0.2715 - accuracy: 0.8895 - val_loss: 0.3683 - val_accuracy: 0.8233\n",
      "Epoch 96/100\n",
      "1719/1719 [==============================] - 0s 37us/sample - loss: 0.2713 - accuracy: 0.8912 - val_loss: 0.3671 - val_accuracy: 0.8279\n",
      "Epoch 97/100\n",
      "1719/1719 [==============================] - 0s 43us/sample - loss: 0.2710 - accuracy: 0.8871 - val_loss: 0.3679 - val_accuracy: 0.8233\n",
      "Epoch 98/100\n",
      "1719/1719 [==============================] - 0s 44us/sample - loss: 0.2699 - accuracy: 0.8895 - val_loss: 0.3685 - val_accuracy: 0.8279\n",
      "Epoch 99/100\n",
      "1719/1719 [==============================] - 0s 44us/sample - loss: 0.2698 - accuracy: 0.8889 - val_loss: 0.3695 - val_accuracy: 0.8326\n",
      "Epoch 100/100\n",
      "1719/1719 [==============================] - 0s 46us/sample - loss: 0.2691 - accuracy: 0.8895 - val_loss: 0.3707 - val_accuracy: 0.8233\n",
      "215/215 - 0s - loss: 0.4670 - accuracy: 0.7860\n",
      "215/215 - 0s - loss: 0.3707 - accuracy: 0.8233\n",
      "Loss: 0.4669709230578223, Accuracy: 0.7860465049743652\n",
      "Validation Set - Loss: 0.37073829368103384, Accuracy: 0.8232558369636536\n"
     ]
    }
   ],
   "source": [
    "# Define the deep learning model \n",
    "nn_model = tf.keras.models.Sequential()\n",
    "nn_model.add(tf.keras.layers.Dense(units=8, activation=\"relu\", input_dim=32))\n",
    "\n",
    "# Output layer/binary classification so 1 neuron for 0 or 1\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Compile the Sequential model together and customize metrics\n",
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model w/ validation dataset\n",
    "fit_model = nn_model.fit(X_train_scaled, y_train, epochs=100, validation_data=(X_val_scaled, y_val))\n",
    "\n",
    "# Evaluate the model using the test data + validation data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "model_loss_val, model_accuracy_val = nn_model.evaluate(X_val_scaled, y_val, verbose=2)\n",
    "\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n",
    "print(f\"Validation Set - Loss: {model_loss_val}, Accuracy: {model_accuracy_val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking parameters neurons x optimizer for optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'neurons': 8, 'optimizer': 'RMSprop'}\n",
      "Best Score:  0.8499186396598816\n"
     ]
    }
   ],
   "source": [
    "# Define the deep learning model function\n",
    "\n",
    "def create_model(neurons=8, optimizer=\"adam\"):\n",
    "    nn_model = tf.keras.models.Sequential()\n",
    "    nn_model.add(tf.keras.layers.Dense(units=neurons, activation=\"relu\", input_dim=32))\n",
    "    nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "    nn_model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "    return nn_model\n",
    "\n",
    "# Create a KerasClassifier based on the model function\n",
    "nn_model = KerasClassifier(build_fn=create_model, epochs=50, batch_size=10, verbose=0)\n",
    "\n",
    "# Define the grid of hyperparameters to search\n",
    "param_grid = {'neurons': [8, 16, 32],'optimizer': [\"adam\", \"SGD\", \"RMSprop\"]}\n",
    "\n",
    "# Perform grid search\n",
    "grid = GridSearchCV(estimator=nn_model, param_grid=param_grid, cv=5)\n",
    "grid_result = grid.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best parameters and results\n",
    "print(\"Best Parameters: \", grid_result.best_params_)\n",
    "print(\"Best Score: \", grid_result.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1719 samples, validate on 215 samples\n",
      "Epoch 1/50\n",
      "1719/1719 [==============================] - 1s 336us/sample - loss: 0.7312 - accuracy: 0.5561 - val_loss: 0.7085 - val_accuracy: 0.5488\n",
      "Epoch 2/50\n",
      "1719/1719 [==============================] - 0s 43us/sample - loss: 0.6463 - accuracy: 0.6411 - val_loss: 0.6467 - val_accuracy: 0.5860\n",
      "Epoch 3/50\n",
      "1719/1719 [==============================] - 0s 49us/sample - loss: 0.5903 - accuracy: 0.6835 - val_loss: 0.6020 - val_accuracy: 0.6512\n",
      "Epoch 4/50\n",
      "1719/1719 [==============================] - 0s 41us/sample - loss: 0.5496 - accuracy: 0.7266 - val_loss: 0.5658 - val_accuracy: 0.7023\n",
      "Epoch 5/50\n",
      "1719/1719 [==============================] - 0s 48us/sample - loss: 0.5159 - accuracy: 0.7574 - val_loss: 0.5341 - val_accuracy: 0.7116\n",
      "Epoch 6/50\n",
      "1719/1719 [==============================] - 0s 48us/sample - loss: 0.4879 - accuracy: 0.7784 - val_loss: 0.5078 - val_accuracy: 0.7395\n",
      "Epoch 7/50\n",
      "1719/1719 [==============================] - 0s 49us/sample - loss: 0.4625 - accuracy: 0.8028 - val_loss: 0.4829 - val_accuracy: 0.7628\n",
      "Epoch 8/50\n",
      "1719/1719 [==============================] - 0s 47us/sample - loss: 0.4412 - accuracy: 0.8156 - val_loss: 0.4626 - val_accuracy: 0.7907\n",
      "Epoch 9/50\n",
      "1719/1719 [==============================] - 0s 53us/sample - loss: 0.4237 - accuracy: 0.8272 - val_loss: 0.4467 - val_accuracy: 0.7814\n",
      "Epoch 10/50\n",
      "1719/1719 [==============================] - 0s 49us/sample - loss: 0.4091 - accuracy: 0.8348 - val_loss: 0.4327 - val_accuracy: 0.7767\n",
      "Epoch 11/50\n",
      "1719/1719 [==============================] - 0s 49us/sample - loss: 0.3972 - accuracy: 0.8400 - val_loss: 0.4225 - val_accuracy: 0.7767\n",
      "Epoch 12/50\n",
      "1719/1719 [==============================] - 0s 42us/sample - loss: 0.3870 - accuracy: 0.8447 - val_loss: 0.4135 - val_accuracy: 0.7814\n",
      "Epoch 13/50\n",
      "1719/1719 [==============================] - 0s 43us/sample - loss: 0.3785 - accuracy: 0.8487 - val_loss: 0.4066 - val_accuracy: 0.7814\n",
      "Epoch 14/50\n",
      "1719/1719 [==============================] - 0s 50us/sample - loss: 0.3717 - accuracy: 0.8540 - val_loss: 0.4011 - val_accuracy: 0.7860\n",
      "Epoch 15/50\n",
      "1719/1719 [==============================] - 0s 44us/sample - loss: 0.3660 - accuracy: 0.8575 - val_loss: 0.3966 - val_accuracy: 0.7907\n",
      "Epoch 16/50\n",
      "1719/1719 [==============================] - 0s 37us/sample - loss: 0.3614 - accuracy: 0.8615 - val_loss: 0.3928 - val_accuracy: 0.8000\n",
      "Epoch 17/50\n",
      "1719/1719 [==============================] - 0s 42us/sample - loss: 0.3571 - accuracy: 0.8610 - val_loss: 0.3907 - val_accuracy: 0.8047\n",
      "Epoch 18/50\n",
      "1719/1719 [==============================] - 0s 47us/sample - loss: 0.3537 - accuracy: 0.8650 - val_loss: 0.3881 - val_accuracy: 0.8000\n",
      "Epoch 19/50\n",
      "1719/1719 [==============================] - 0s 36us/sample - loss: 0.3504 - accuracy: 0.8674 - val_loss: 0.3863 - val_accuracy: 0.8093\n",
      "Epoch 20/50\n",
      "1719/1719 [==============================] - 0s 37us/sample - loss: 0.3478 - accuracy: 0.8679 - val_loss: 0.3846 - val_accuracy: 0.8093\n",
      "Epoch 21/50\n",
      "1719/1719 [==============================] - 0s 48us/sample - loss: 0.3454 - accuracy: 0.8662 - val_loss: 0.3839 - val_accuracy: 0.8093\n",
      "Epoch 22/50\n",
      "1719/1719 [==============================] - 0s 44us/sample - loss: 0.3431 - accuracy: 0.8679 - val_loss: 0.3833 - val_accuracy: 0.8140\n",
      "Epoch 23/50\n",
      "1719/1719 [==============================] - 0s 43us/sample - loss: 0.3412 - accuracy: 0.8674 - val_loss: 0.3834 - val_accuracy: 0.8093\n",
      "Epoch 24/50\n",
      "1719/1719 [==============================] - 0s 42us/sample - loss: 0.3391 - accuracy: 0.8691 - val_loss: 0.3818 - val_accuracy: 0.8140\n",
      "Epoch 25/50\n",
      "1719/1719 [==============================] - 0s 39us/sample - loss: 0.3374 - accuracy: 0.8726 - val_loss: 0.3818 - val_accuracy: 0.8186\n",
      "Epoch 26/50\n",
      "1719/1719 [==============================] - 0s 45us/sample - loss: 0.3357 - accuracy: 0.8720 - val_loss: 0.3816 - val_accuracy: 0.8140\n",
      "Epoch 27/50\n",
      "1719/1719 [==============================] - 0s 39us/sample - loss: 0.3343 - accuracy: 0.8726 - val_loss: 0.3819 - val_accuracy: 0.8093\n",
      "Epoch 28/50\n",
      "1719/1719 [==============================] - 0s 45us/sample - loss: 0.3322 - accuracy: 0.8749 - val_loss: 0.3818 - val_accuracy: 0.8093\n",
      "Epoch 29/50\n",
      "1719/1719 [==============================] - 0s 37us/sample - loss: 0.3308 - accuracy: 0.8738 - val_loss: 0.3818 - val_accuracy: 0.8047\n",
      "Epoch 30/50\n",
      "1719/1719 [==============================] - 0s 47us/sample - loss: 0.3291 - accuracy: 0.8755 - val_loss: 0.3811 - val_accuracy: 0.8047\n",
      "Epoch 31/50\n",
      "1719/1719 [==============================] - 0s 67us/sample - loss: 0.3277 - accuracy: 0.8778 - val_loss: 0.3814 - val_accuracy: 0.8047\n",
      "Epoch 32/50\n",
      "1719/1719 [==============================] - 0s 36us/sample - loss: 0.3262 - accuracy: 0.8761 - val_loss: 0.3814 - val_accuracy: 0.8047\n",
      "Epoch 33/50\n",
      "1719/1719 [==============================] - 0s 47us/sample - loss: 0.3247 - accuracy: 0.8813 - val_loss: 0.3811 - val_accuracy: 0.8000\n",
      "Epoch 34/50\n",
      "1719/1719 [==============================] - 0s 34us/sample - loss: 0.3232 - accuracy: 0.8796 - val_loss: 0.3812 - val_accuracy: 0.8000\n",
      "Epoch 35/50\n",
      "1719/1719 [==============================] - 0s 40us/sample - loss: 0.3220 - accuracy: 0.8790 - val_loss: 0.3806 - val_accuracy: 0.8000\n",
      "Epoch 36/50\n",
      "1719/1719 [==============================] - 0s 44us/sample - loss: 0.3202 - accuracy: 0.8807 - val_loss: 0.3795 - val_accuracy: 0.8047\n",
      "Epoch 37/50\n",
      "1719/1719 [==============================] - 0s 37us/sample - loss: 0.3188 - accuracy: 0.8790 - val_loss: 0.3796 - val_accuracy: 0.8093\n",
      "Epoch 38/50\n",
      "1719/1719 [==============================] - 0s 47us/sample - loss: 0.3174 - accuracy: 0.8819 - val_loss: 0.3794 - val_accuracy: 0.8093\n",
      "Epoch 39/50\n",
      "1719/1719 [==============================] - 0s 40us/sample - loss: 0.3161 - accuracy: 0.8813 - val_loss: 0.3793 - val_accuracy: 0.8093\n",
      "Epoch 40/50\n",
      "1719/1719 [==============================] - 0s 41us/sample - loss: 0.3145 - accuracy: 0.8819 - val_loss: 0.3785 - val_accuracy: 0.8140\n",
      "Epoch 41/50\n",
      "1719/1719 [==============================] - 0s 44us/sample - loss: 0.3133 - accuracy: 0.8831 - val_loss: 0.3785 - val_accuracy: 0.8140\n",
      "Epoch 42/50\n",
      "1719/1719 [==============================] - 0s 51us/sample - loss: 0.3119 - accuracy: 0.8796 - val_loss: 0.3772 - val_accuracy: 0.8140\n",
      "Epoch 43/50\n",
      "1719/1719 [==============================] - 0s 42us/sample - loss: 0.3106 - accuracy: 0.8807 - val_loss: 0.3770 - val_accuracy: 0.8140\n",
      "Epoch 44/50\n",
      "1719/1719 [==============================] - 0s 44us/sample - loss: 0.3095 - accuracy: 0.8802 - val_loss: 0.3763 - val_accuracy: 0.8047\n",
      "Epoch 45/50\n",
      "1719/1719 [==============================] - 0s 43us/sample - loss: 0.3082 - accuracy: 0.8837 - val_loss: 0.3766 - val_accuracy: 0.8093\n",
      "Epoch 46/50\n",
      "1719/1719 [==============================] - 0s 44us/sample - loss: 0.3070 - accuracy: 0.8837 - val_loss: 0.3762 - val_accuracy: 0.8140\n",
      "Epoch 47/50\n",
      "1719/1719 [==============================] - 0s 43us/sample - loss: 0.3059 - accuracy: 0.8842 - val_loss: 0.3760 - val_accuracy: 0.8140\n",
      "Epoch 48/50\n",
      "1719/1719 [==============================] - 0s 44us/sample - loss: 0.3048 - accuracy: 0.8807 - val_loss: 0.3758 - val_accuracy: 0.8093\n",
      "Epoch 49/50\n",
      "1719/1719 [==============================] - 0s 42us/sample - loss: 0.3036 - accuracy: 0.8813 - val_loss: 0.3746 - val_accuracy: 0.8047\n",
      "Epoch 50/50\n",
      "1719/1719 [==============================] - 0s 42us/sample - loss: 0.3025 - accuracy: 0.8842 - val_loss: 0.3756 - val_accuracy: 0.8047\n",
      "215/215 - 0s - loss: 0.4477 - accuracy: 0.8140\n",
      "215/215 - 0s - loss: 0.3756 - accuracy: 0.8047\n",
      "Loss: 0.44765095156292584, Accuracy: 0.8139534592628479\n",
      "Validation Set - Loss: 0.375601616293885, Accuracy: 0.804651141166687\n"
     ]
    }
   ],
   "source": [
    "# Define the deep learning model \n",
    "nn_model = tf.keras.models.Sequential()\n",
    "nn_model.add(tf.keras.layers.Dense(units=8, activation=\"relu\", input_dim=32))\n",
    "\n",
    "# Output layer/binary classification so 1 neuron for 0 or 1\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Compile the Sequential model together and customize metrics\n",
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"RMSprop\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model w/ validation dataset\n",
    "fit_model = nn_model.fit(X_train_scaled, y_train, epochs=50, validation_data=(X_val_scaled, y_val))\n",
    "\n",
    "# Evaluate the model using the test data + validation data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "model_loss_val, model_accuracy_val = nn_model.evaluate(X_val_scaled, y_val, verbose=2)\n",
    "\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n",
    "print(f\"Validation Set - Loss: {model_loss_val}, Accuracy: {model_accuracy_val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "neuron =8, epochs =50, optimizer = RMSprop gives the best balance between test accuracy vs. validation accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing other activation functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---> AF = tanh decreases accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---> PReLU also decreases accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1719 samples, validate on 215 samples\n",
      "Epoch 1/50\n",
      "1719/1719 [==============================] - 1s 395us/sample - loss: 0.7101 - accuracy: 0.5550 - val_loss: 0.7222 - val_accuracy: 0.5023\n",
      "Epoch 2/50\n",
      "1719/1719 [==============================] - 0s 48us/sample - loss: 0.6331 - accuracy: 0.6248 - val_loss: 0.6463 - val_accuracy: 0.6140\n",
      "Epoch 3/50\n",
      "1719/1719 [==============================] - 0s 43us/sample - loss: 0.5707 - accuracy: 0.7068 - val_loss: 0.5860 - val_accuracy: 0.7023\n",
      "Epoch 4/50\n",
      "1719/1719 [==============================] - 0s 48us/sample - loss: 0.5189 - accuracy: 0.7632 - val_loss: 0.5356 - val_accuracy: 0.7442\n",
      "Epoch 5/50\n",
      "1719/1719 [==============================] - 0s 75us/sample - loss: 0.4764 - accuracy: 0.7976 - val_loss: 0.4962 - val_accuracy: 0.7628\n",
      "Epoch 6/50\n",
      "1719/1719 [==============================] - 0s 49us/sample - loss: 0.4430 - accuracy: 0.8220 - val_loss: 0.4657 - val_accuracy: 0.7721\n",
      "Epoch 7/50\n",
      "1719/1719 [==============================] - 0s 56us/sample - loss: 0.4176 - accuracy: 0.8383 - val_loss: 0.4430 - val_accuracy: 0.8047\n",
      "Epoch 8/50\n",
      "1719/1719 [==============================] - 0s 58us/sample - loss: 0.3990 - accuracy: 0.8505 - val_loss: 0.4276 - val_accuracy: 0.8233\n",
      "Epoch 9/50\n",
      "1719/1719 [==============================] - 0s 54us/sample - loss: 0.3854 - accuracy: 0.8517 - val_loss: 0.4150 - val_accuracy: 0.8233\n",
      "Epoch 10/50\n",
      "1719/1719 [==============================] - 0s 69us/sample - loss: 0.3757 - accuracy: 0.8551 - val_loss: 0.4064 - val_accuracy: 0.8140\n",
      "Epoch 11/50\n",
      "1719/1719 [==============================] - 0s 66us/sample - loss: 0.3688 - accuracy: 0.8563 - val_loss: 0.3999 - val_accuracy: 0.8186\n",
      "Epoch 12/50\n",
      "1719/1719 [==============================] - 0s 70us/sample - loss: 0.3639 - accuracy: 0.8540 - val_loss: 0.3953 - val_accuracy: 0.8233\n",
      "Epoch 13/50\n",
      "1719/1719 [==============================] - 0s 77us/sample - loss: 0.3601 - accuracy: 0.8557 - val_loss: 0.3918 - val_accuracy: 0.8233\n",
      "Epoch 14/50\n",
      "1719/1719 [==============================] - 0s 89us/sample - loss: 0.3573 - accuracy: 0.8581 - val_loss: 0.3897 - val_accuracy: 0.8186\n",
      "Epoch 15/50\n",
      "1719/1719 [==============================] - 0s 93us/sample - loss: 0.3551 - accuracy: 0.8598 - val_loss: 0.3876 - val_accuracy: 0.8233\n",
      "Epoch 16/50\n",
      "1719/1719 [==============================] - 0s 78us/sample - loss: 0.3532 - accuracy: 0.8604 - val_loss: 0.3852 - val_accuracy: 0.8279\n",
      "Epoch 17/50\n",
      "1719/1719 [==============================] - 0s 76us/sample - loss: 0.3518 - accuracy: 0.8586 - val_loss: 0.3837 - val_accuracy: 0.8279\n",
      "Epoch 18/50\n",
      "1719/1719 [==============================] - 0s 69us/sample - loss: 0.3501 - accuracy: 0.8610 - val_loss: 0.3823 - val_accuracy: 0.8279\n",
      "Epoch 19/50\n",
      "1719/1719 [==============================] - 0s 76us/sample - loss: 0.3488 - accuracy: 0.8621 - val_loss: 0.3818 - val_accuracy: 0.8279\n",
      "Epoch 20/50\n",
      "1719/1719 [==============================] - 0s 70us/sample - loss: 0.3477 - accuracy: 0.8621 - val_loss: 0.3819 - val_accuracy: 0.8279\n",
      "Epoch 21/50\n",
      "1719/1719 [==============================] - 0s 76us/sample - loss: 0.3467 - accuracy: 0.8627 - val_loss: 0.3809 - val_accuracy: 0.8279\n",
      "Epoch 22/50\n",
      "1719/1719 [==============================] - 0s 89us/sample - loss: 0.3457 - accuracy: 0.8627 - val_loss: 0.3814 - val_accuracy: 0.8279\n",
      "Epoch 23/50\n",
      "1719/1719 [==============================] - 0s 81us/sample - loss: 0.3446 - accuracy: 0.8627 - val_loss: 0.3817 - val_accuracy: 0.8279\n",
      "Epoch 24/50\n",
      "1719/1719 [==============================] - 0s 79us/sample - loss: 0.3438 - accuracy: 0.8627 - val_loss: 0.3816 - val_accuracy: 0.8279\n",
      "Epoch 25/50\n",
      "1719/1719 [==============================] - 0s 93us/sample - loss: 0.3428 - accuracy: 0.8639 - val_loss: 0.3812 - val_accuracy: 0.8279\n",
      "Epoch 26/50\n",
      "1719/1719 [==============================] - 0s 97us/sample - loss: 0.3421 - accuracy: 0.8656 - val_loss: 0.3810 - val_accuracy: 0.8279\n",
      "Epoch 27/50\n",
      "1719/1719 [==============================] - 0s 78us/sample - loss: 0.3412 - accuracy: 0.8621 - val_loss: 0.3814 - val_accuracy: 0.8326\n",
      "Epoch 28/50\n",
      "1719/1719 [==============================] - 0s 76us/sample - loss: 0.3401 - accuracy: 0.8656 - val_loss: 0.3815 - val_accuracy: 0.8279\n",
      "Epoch 29/50\n",
      "1719/1719 [==============================] - 0s 70us/sample - loss: 0.3394 - accuracy: 0.8674 - val_loss: 0.3812 - val_accuracy: 0.8326\n",
      "Epoch 30/50\n",
      "1719/1719 [==============================] - 0s 68us/sample - loss: 0.3386 - accuracy: 0.8668 - val_loss: 0.3818 - val_accuracy: 0.8279\n",
      "Epoch 31/50\n",
      "1719/1719 [==============================] - 0s 74us/sample - loss: 0.3378 - accuracy: 0.8674 - val_loss: 0.3806 - val_accuracy: 0.8326\n",
      "Epoch 32/50\n",
      "1719/1719 [==============================] - 0s 87us/sample - loss: 0.3371 - accuracy: 0.8674 - val_loss: 0.3802 - val_accuracy: 0.8372\n",
      "Epoch 33/50\n",
      "1719/1719 [==============================] - 0s 85us/sample - loss: 0.3362 - accuracy: 0.8703 - val_loss: 0.3809 - val_accuracy: 0.8279\n",
      "Epoch 34/50\n",
      "1719/1719 [==============================] - 0s 74us/sample - loss: 0.3357 - accuracy: 0.8674 - val_loss: 0.3816 - val_accuracy: 0.8326\n",
      "Epoch 35/50\n",
      "1719/1719 [==============================] - 0s 67us/sample - loss: 0.3349 - accuracy: 0.8697 - val_loss: 0.3818 - val_accuracy: 0.8326\n",
      "Epoch 36/50\n",
      "1719/1719 [==============================] - 0s 68us/sample - loss: 0.3340 - accuracy: 0.8685 - val_loss: 0.3821 - val_accuracy: 0.8326\n",
      "Epoch 37/50\n",
      "1719/1719 [==============================] - 0s 67us/sample - loss: 0.3334 - accuracy: 0.8674 - val_loss: 0.3827 - val_accuracy: 0.8326\n",
      "Epoch 38/50\n",
      "1719/1719 [==============================] - 0s 69us/sample - loss: 0.3328 - accuracy: 0.8674 - val_loss: 0.3826 - val_accuracy: 0.8326\n",
      "Epoch 39/50\n",
      "1719/1719 [==============================] - 0s 68us/sample - loss: 0.3320 - accuracy: 0.8703 - val_loss: 0.3829 - val_accuracy: 0.8326\n",
      "Epoch 40/50\n",
      "1719/1719 [==============================] - 0s 72us/sample - loss: 0.3313 - accuracy: 0.8697 - val_loss: 0.3823 - val_accuracy: 0.8372\n",
      "Epoch 41/50\n",
      "1719/1719 [==============================] - 0s 71us/sample - loss: 0.3308 - accuracy: 0.8726 - val_loss: 0.3826 - val_accuracy: 0.8372\n",
      "Epoch 42/50\n",
      "1719/1719 [==============================] - 0s 72us/sample - loss: 0.3300 - accuracy: 0.8720 - val_loss: 0.3825 - val_accuracy: 0.8372\n",
      "Epoch 43/50\n",
      "1719/1719 [==============================] - 0s 69us/sample - loss: 0.3294 - accuracy: 0.8720 - val_loss: 0.3831 - val_accuracy: 0.8372\n",
      "Epoch 44/50\n",
      "1719/1719 [==============================] - 0s 67us/sample - loss: 0.3286 - accuracy: 0.8726 - val_loss: 0.3836 - val_accuracy: 0.8372\n",
      "Epoch 45/50\n",
      "1719/1719 [==============================] - 0s 69us/sample - loss: 0.3280 - accuracy: 0.8720 - val_loss: 0.3832 - val_accuracy: 0.8326\n",
      "Epoch 46/50\n",
      "1719/1719 [==============================] - 0s 72us/sample - loss: 0.3274 - accuracy: 0.8714 - val_loss: 0.3832 - val_accuracy: 0.8372\n",
      "Epoch 47/50\n",
      "1719/1719 [==============================] - 0s 72us/sample - loss: 0.3267 - accuracy: 0.8720 - val_loss: 0.3837 - val_accuracy: 0.8372\n",
      "Epoch 48/50\n",
      "1719/1719 [==============================] - 0s 75us/sample - loss: 0.3260 - accuracy: 0.8709 - val_loss: 0.3842 - val_accuracy: 0.8372\n",
      "Epoch 49/50\n",
      "1719/1719 [==============================] - 0s 73us/sample - loss: 0.3255 - accuracy: 0.8720 - val_loss: 0.3854 - val_accuracy: 0.8326\n",
      "Epoch 50/50\n",
      "1719/1719 [==============================] - 0s 84us/sample - loss: 0.3247 - accuracy: 0.8703 - val_loss: 0.3858 - val_accuracy: 0.8279\n",
      "215/215 - 0s - loss: 0.4665 - accuracy: 0.7860\n",
      "215/215 - 0s - loss: 0.3858 - accuracy: 0.8279\n",
      "Loss: 0.4665170201035433, Accuracy: 0.7860465049743652\n",
      "Validation Set - Loss: 0.3858138135699339, Accuracy: 0.8279069662094116\n"
     ]
    }
   ],
   "source": [
    "# Define the deep learning model \n",
    "nn_model = tf.keras.models.Sequential()\n",
    "nn_model.add(tf.keras.layers.Dense(units=8, activation=\"tanh\", input_dim=32))\n",
    "\n",
    "# Output layer/binary classification so 1 neuron for 0 or 1\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Compile the Sequential model together and customize metrics\n",
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"RMSprop\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model w/ validation dataset\n",
    "fit_model = nn_model.fit(X_train_scaled, y_train, epochs=50, validation_data=(X_val_scaled, y_val))\n",
    "\n",
    "# Evaluate the model using the test data + validation data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "model_loss_val, model_accuracy_val = nn_model.evaluate(X_val_scaled, y_val, verbose=2)\n",
    "\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n",
    "print(f\"Validation Set - Loss: {model_loss_val}, Accuracy: {model_accuracy_val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 452\n",
      "Train on 1719 samples, validate on 215 samples\n",
      "Epoch 1/50\n",
      "1719/1719 [==============================] - 1s 396us/sample - loss: 0.6863 - accuracy: 0.5672 - val_loss: 0.6383 - val_accuracy: 0.6744\n",
      "Epoch 2/50\n",
      "1719/1719 [==============================] - 0s 54us/sample - loss: 0.6170 - accuracy: 0.6847 - val_loss: 0.5919 - val_accuracy: 0.7395\n",
      "Epoch 3/50\n",
      "1719/1719 [==============================] - 0s 49us/sample - loss: 0.5687 - accuracy: 0.7493 - val_loss: 0.5556 - val_accuracy: 0.7395\n",
      "Epoch 4/50\n",
      "1719/1719 [==============================] - 0s 58us/sample - loss: 0.5279 - accuracy: 0.7789 - val_loss: 0.5226 - val_accuracy: 0.7442\n",
      "Epoch 5/50\n",
      "1719/1719 [==============================] - 0s 50us/sample - loss: 0.4923 - accuracy: 0.8040 - val_loss: 0.4914 - val_accuracy: 0.7581\n",
      "Epoch 6/50\n",
      "1719/1719 [==============================] - 0s 53us/sample - loss: 0.4605 - accuracy: 0.8150 - val_loss: 0.4632 - val_accuracy: 0.7721\n",
      "Epoch 7/50\n",
      "1719/1719 [==============================] - 0s 50us/sample - loss: 0.4337 - accuracy: 0.8278 - val_loss: 0.4399 - val_accuracy: 0.7814\n",
      "Epoch 8/50\n",
      "1719/1719 [==============================] - 0s 53us/sample - loss: 0.4122 - accuracy: 0.8336 - val_loss: 0.4204 - val_accuracy: 0.7953\n",
      "Epoch 9/50\n",
      "1719/1719 [==============================] - 0s 53us/sample - loss: 0.3958 - accuracy: 0.8418 - val_loss: 0.4048 - val_accuracy: 0.7953\n",
      "Epoch 10/50\n",
      "1719/1719 [==============================] - 0s 81us/sample - loss: 0.3839 - accuracy: 0.8418 - val_loss: 0.3933 - val_accuracy: 0.8000\n",
      "Epoch 11/50\n",
      "1719/1719 [==============================] - 0s 54us/sample - loss: 0.3753 - accuracy: 0.8476 - val_loss: 0.3846 - val_accuracy: 0.8093\n",
      "Epoch 12/50\n",
      "1719/1719 [==============================] - 0s 48us/sample - loss: 0.3696 - accuracy: 0.8505 - val_loss: 0.3790 - val_accuracy: 0.8093\n",
      "Epoch 13/50\n",
      "1719/1719 [==============================] - 0s 50us/sample - loss: 0.3650 - accuracy: 0.8551 - val_loss: 0.3746 - val_accuracy: 0.8140\n",
      "Epoch 14/50\n",
      "1719/1719 [==============================] - 0s 65us/sample - loss: 0.3616 - accuracy: 0.8551 - val_loss: 0.3723 - val_accuracy: 0.8233\n",
      "Epoch 15/50\n",
      "1719/1719 [==============================] - 0s 57us/sample - loss: 0.3590 - accuracy: 0.8546 - val_loss: 0.3711 - val_accuracy: 0.8186\n",
      "Epoch 16/50\n",
      "1719/1719 [==============================] - 0s 43us/sample - loss: 0.3567 - accuracy: 0.8540 - val_loss: 0.3694 - val_accuracy: 0.8186\n",
      "Epoch 17/50\n",
      "1719/1719 [==============================] - 0s 47us/sample - loss: 0.3549 - accuracy: 0.8557 - val_loss: 0.3673 - val_accuracy: 0.8233\n",
      "Epoch 18/50\n",
      "1719/1719 [==============================] - 0s 55us/sample - loss: 0.3533 - accuracy: 0.8551 - val_loss: 0.3647 - val_accuracy: 0.8372\n",
      "Epoch 19/50\n",
      "1719/1719 [==============================] - 0s 51us/sample - loss: 0.3517 - accuracy: 0.8563 - val_loss: 0.3644 - val_accuracy: 0.8372\n",
      "Epoch 20/50\n",
      "1719/1719 [==============================] - 0s 47us/sample - loss: 0.3505 - accuracy: 0.8563 - val_loss: 0.3624 - val_accuracy: 0.8372\n",
      "Epoch 21/50\n",
      "1719/1719 [==============================] - 0s 57us/sample - loss: 0.3492 - accuracy: 0.8586 - val_loss: 0.3627 - val_accuracy: 0.8326\n",
      "Epoch 22/50\n",
      "1719/1719 [==============================] - 0s 59us/sample - loss: 0.3480 - accuracy: 0.8575 - val_loss: 0.3629 - val_accuracy: 0.8326\n",
      "Epoch 23/50\n",
      "1719/1719 [==============================] - 0s 59us/sample - loss: 0.3468 - accuracy: 0.8598 - val_loss: 0.3637 - val_accuracy: 0.8326\n",
      "Epoch 24/50\n",
      "1719/1719 [==============================] - 0s 56us/sample - loss: 0.3456 - accuracy: 0.8586 - val_loss: 0.3624 - val_accuracy: 0.8326\n",
      "Epoch 25/50\n",
      "1719/1719 [==============================] - 0s 63us/sample - loss: 0.3443 - accuracy: 0.8569 - val_loss: 0.3616 - val_accuracy: 0.8326\n",
      "Epoch 26/50\n",
      "1719/1719 [==============================] - 0s 71us/sample - loss: 0.3435 - accuracy: 0.8604 - val_loss: 0.3608 - val_accuracy: 0.8326\n",
      "Epoch 27/50\n",
      "1719/1719 [==============================] - 0s 77us/sample - loss: 0.3425 - accuracy: 0.8604 - val_loss: 0.3613 - val_accuracy: 0.8326\n",
      "Epoch 28/50\n",
      "1719/1719 [==============================] - 0s 77us/sample - loss: 0.3410 - accuracy: 0.8621 - val_loss: 0.3608 - val_accuracy: 0.8326\n",
      "Epoch 29/50\n",
      "1719/1719 [==============================] - 0s 78us/sample - loss: 0.3402 - accuracy: 0.8610 - val_loss: 0.3606 - val_accuracy: 0.8326\n",
      "Epoch 30/50\n",
      "1719/1719 [==============================] - 0s 77us/sample - loss: 0.3392 - accuracy: 0.8592 - val_loss: 0.3612 - val_accuracy: 0.8326\n",
      "Epoch 31/50\n",
      "1719/1719 [==============================] - 0s 86us/sample - loss: 0.3382 - accuracy: 0.8615 - val_loss: 0.3620 - val_accuracy: 0.8326\n",
      "Epoch 32/50\n",
      "1719/1719 [==============================] - 0s 93us/sample - loss: 0.3371 - accuracy: 0.8627 - val_loss: 0.3613 - val_accuracy: 0.8326\n",
      "Epoch 33/50\n",
      "1719/1719 [==============================] - 0s 88us/sample - loss: 0.3360 - accuracy: 0.8627 - val_loss: 0.3617 - val_accuracy: 0.8326\n",
      "Epoch 34/50\n",
      "1719/1719 [==============================] - 0s 85us/sample - loss: 0.3350 - accuracy: 0.8650 - val_loss: 0.3622 - val_accuracy: 0.8326\n",
      "Epoch 35/50\n",
      "1719/1719 [==============================] - 0s 77us/sample - loss: 0.3339 - accuracy: 0.8668 - val_loss: 0.3623 - val_accuracy: 0.8279\n",
      "Epoch 36/50\n",
      "1719/1719 [==============================] - 0s 82us/sample - loss: 0.3327 - accuracy: 0.8656 - val_loss: 0.3626 - val_accuracy: 0.8279\n",
      "Epoch 37/50\n",
      "1719/1719 [==============================] - 0s 81us/sample - loss: 0.3315 - accuracy: 0.8668 - val_loss: 0.3633 - val_accuracy: 0.8279\n",
      "Epoch 38/50\n",
      "1719/1719 [==============================] - 0s 108us/sample - loss: 0.3302 - accuracy: 0.8691 - val_loss: 0.3616 - val_accuracy: 0.8279\n",
      "Epoch 39/50\n",
      "1719/1719 [==============================] - 0s 96us/sample - loss: 0.3291 - accuracy: 0.8679 - val_loss: 0.3624 - val_accuracy: 0.8279\n",
      "Epoch 40/50\n",
      "1719/1719 [==============================] - 0s 80us/sample - loss: 0.3277 - accuracy: 0.8685 - val_loss: 0.3623 - val_accuracy: 0.8233\n",
      "Epoch 41/50\n",
      "1719/1719 [==============================] - 0s 80us/sample - loss: 0.3264 - accuracy: 0.8697 - val_loss: 0.3627 - val_accuracy: 0.8233\n",
      "Epoch 42/50\n",
      "1719/1719 [==============================] - 0s 79us/sample - loss: 0.3252 - accuracy: 0.8709 - val_loss: 0.3626 - val_accuracy: 0.8233\n",
      "Epoch 43/50\n",
      "1719/1719 [==============================] - 0s 84us/sample - loss: 0.3237 - accuracy: 0.8697 - val_loss: 0.3639 - val_accuracy: 0.8233\n",
      "Epoch 44/50\n",
      "1719/1719 [==============================] - 0s 88us/sample - loss: 0.3228 - accuracy: 0.8720 - val_loss: 0.3645 - val_accuracy: 0.8233\n",
      "Epoch 45/50\n",
      "1719/1719 [==============================] - ETA: 0s - loss: 0.3134 - accuracy: 0.86 - 0s 94us/sample - loss: 0.3215 - accuracy: 0.8726 - val_loss: 0.3658 - val_accuracy: 0.8233\n",
      "Epoch 46/50\n",
      "1719/1719 [==============================] - 0s 94us/sample - loss: 0.3201 - accuracy: 0.8703 - val_loss: 0.3668 - val_accuracy: 0.8233\n",
      "Epoch 47/50\n",
      "1719/1719 [==============================] - 0s 81us/sample - loss: 0.3187 - accuracy: 0.8726 - val_loss: 0.3680 - val_accuracy: 0.8186\n",
      "Epoch 48/50\n",
      "1719/1719 [==============================] - 0s 79us/sample - loss: 0.3176 - accuracy: 0.8738 - val_loss: 0.3676 - val_accuracy: 0.8186\n",
      "Epoch 49/50\n",
      "1719/1719 [==============================] - 0s 88us/sample - loss: 0.3164 - accuracy: 0.8749 - val_loss: 0.3687 - val_accuracy: 0.8186\n",
      "Epoch 50/50\n",
      "1719/1719 [==============================] - 0s 79us/sample - loss: 0.3152 - accuracy: 0.8767 - val_loss: 0.3695 - val_accuracy: 0.8186\n",
      "215/215 - 0s - loss: 0.4722 - accuracy: 0.8000\n",
      "215/215 - 0s - loss: 0.3695 - accuracy: 0.8186\n",
      "Loss: 0.47216000778730527, Accuracy: 0.800000011920929\n",
      "Validation Set - Loss: 0.3694671855416409, Accuracy: 0.8186046481132507\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import PReLU\n",
    "\n",
    "# Define the deep learning model \n",
    "nn_model = tf.keras.models.Sequential()\n",
    "nn_model.add(tf.keras.layers.Dense(units=8, input_dim=32))\n",
    "nn_model.add(PReLU())  # Adding PReLU activation function here\n",
    "\n",
    "# Output layer for binary classification (1 neuron for 0 or 1)\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Compile the Sequential model together and customize metrics\n",
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"RMSprop\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model with validation dataset\n",
    "fit_model = nn_model.fit(X_train_scaled, y_train, epochs=50, validation_data=(X_val_scaled, y_val))\n",
    "\n",
    "# Evaluate the model using the test data and validation data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "model_loss_val, model_accuracy_val = nn_model.evaluate(X_val_scaled, y_val, verbose=2)\n",
    "\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n",
    "print(f\"Validation Set - Loss: {model_loss_val}, Accuracy: {model_accuracy_val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing addition of more hidden layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---> adding a hidden layer decreased accuracy and increased loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1719 samples, validate on 215 samples\n",
      "Epoch 1/50\n",
      "1719/1719 [==============================] - 1s 662us/sample - loss: 0.7791 - accuracy: 0.4090 - val_loss: 0.7078 - val_accuracy: 0.5163\n",
      "Epoch 2/50\n",
      "1719/1719 [==============================] - 0s 78us/sample - loss: 0.7022 - accuracy: 0.5102 - val_loss: 0.6681 - val_accuracy: 0.6186\n",
      "Epoch 3/50\n",
      "1719/1719 [==============================] - 0s 75us/sample - loss: 0.6657 - accuracy: 0.6353 - val_loss: 0.6459 - val_accuracy: 0.6837\n",
      "Epoch 4/50\n",
      "1719/1719 [==============================] - 0s 76us/sample - loss: 0.6402 - accuracy: 0.6946 - val_loss: 0.6243 - val_accuracy: 0.6930\n",
      "Epoch 5/50\n",
      "1719/1719 [==============================] - 0s 76us/sample - loss: 0.6135 - accuracy: 0.7208 - val_loss: 0.5994 - val_accuracy: 0.7163\n",
      "Epoch 6/50\n",
      "1719/1719 [==============================] - 0s 76us/sample - loss: 0.5822 - accuracy: 0.7574 - val_loss: 0.5705 - val_accuracy: 0.7395\n",
      "Epoch 7/50\n",
      "1719/1719 [==============================] - 0s 75us/sample - loss: 0.5458 - accuracy: 0.7877 - val_loss: 0.5379 - val_accuracy: 0.7674\n",
      "Epoch 8/50\n",
      "1719/1719 [==============================] - 0s 73us/sample - loss: 0.5073 - accuracy: 0.8045 - val_loss: 0.5031 - val_accuracy: 0.7767\n",
      "Epoch 9/50\n",
      "1719/1719 [==============================] - 0s 68us/sample - loss: 0.4702 - accuracy: 0.8109 - val_loss: 0.4711 - val_accuracy: 0.8000\n",
      "Epoch 10/50\n",
      "1719/1719 [==============================] - 0s 86us/sample - loss: 0.4384 - accuracy: 0.8255 - val_loss: 0.4444 - val_accuracy: 0.7953\n",
      "Epoch 11/50\n",
      "1719/1719 [==============================] - 0s 83us/sample - loss: 0.4125 - accuracy: 0.8342 - val_loss: 0.4251 - val_accuracy: 0.7953\n",
      "Epoch 12/50\n",
      "1719/1719 [==============================] - 0s 75us/sample - loss: 0.3942 - accuracy: 0.8360 - val_loss: 0.4118 - val_accuracy: 0.7953\n",
      "Epoch 13/50\n",
      "1719/1719 [==============================] - 0s 72us/sample - loss: 0.3815 - accuracy: 0.8406 - val_loss: 0.4036 - val_accuracy: 0.8000\n",
      "Epoch 14/50\n",
      "1719/1719 [==============================] - 0s 71us/sample - loss: 0.3725 - accuracy: 0.8447 - val_loss: 0.4002 - val_accuracy: 0.8047\n",
      "Epoch 15/50\n",
      "1719/1719 [==============================] - 0s 68us/sample - loss: 0.3659 - accuracy: 0.8482 - val_loss: 0.3957 - val_accuracy: 0.8000\n",
      "Epoch 16/50\n",
      "1719/1719 [==============================] - 0s 69us/sample - loss: 0.3609 - accuracy: 0.8517 - val_loss: 0.3948 - val_accuracy: 0.8000\n",
      "Epoch 17/50\n",
      "1719/1719 [==============================] - 0s 68us/sample - loss: 0.3565 - accuracy: 0.8546 - val_loss: 0.3913 - val_accuracy: 0.8000\n",
      "Epoch 18/50\n",
      "1719/1719 [==============================] - 0s 70us/sample - loss: 0.3532 - accuracy: 0.8522 - val_loss: 0.3915 - val_accuracy: 0.8000\n",
      "Epoch 19/50\n",
      "1719/1719 [==============================] - 0s 72us/sample - loss: 0.3502 - accuracy: 0.8546 - val_loss: 0.3901 - val_accuracy: 0.8000\n",
      "Epoch 20/50\n",
      "1719/1719 [==============================] - 0s 89us/sample - loss: 0.3475 - accuracy: 0.8534 - val_loss: 0.3890 - val_accuracy: 0.8000\n",
      "Epoch 21/50\n",
      "1719/1719 [==============================] - 0s 79us/sample - loss: 0.3447 - accuracy: 0.8581 - val_loss: 0.3875 - val_accuracy: 0.8047\n",
      "Epoch 22/50\n",
      "1719/1719 [==============================] - 0s 75us/sample - loss: 0.3424 - accuracy: 0.8557 - val_loss: 0.3871 - val_accuracy: 0.8047\n",
      "Epoch 23/50\n",
      "1719/1719 [==============================] - 0s 68us/sample - loss: 0.3403 - accuracy: 0.8575 - val_loss: 0.3868 - val_accuracy: 0.8093\n",
      "Epoch 24/50\n",
      "1719/1719 [==============================] - 0s 68us/sample - loss: 0.3381 - accuracy: 0.8557 - val_loss: 0.3878 - val_accuracy: 0.8093\n",
      "Epoch 25/50\n",
      "1719/1719 [==============================] - 0s 77us/sample - loss: 0.3359 - accuracy: 0.8592 - val_loss: 0.3870 - val_accuracy: 0.8047\n",
      "Epoch 26/50\n",
      "1719/1719 [==============================] - 0s 70us/sample - loss: 0.3340 - accuracy: 0.8633 - val_loss: 0.3849 - val_accuracy: 0.8047\n",
      "Epoch 27/50\n",
      "1719/1719 [==============================] - 0s 68us/sample - loss: 0.3320 - accuracy: 0.8586 - val_loss: 0.3855 - val_accuracy: 0.8093\n",
      "Epoch 28/50\n",
      "1719/1719 [==============================] - 0s 68us/sample - loss: 0.3301 - accuracy: 0.8592 - val_loss: 0.3861 - val_accuracy: 0.8093\n",
      "Epoch 29/50\n",
      "1719/1719 [==============================] - 0s 74us/sample - loss: 0.3283 - accuracy: 0.8633 - val_loss: 0.3865 - val_accuracy: 0.8140\n",
      "Epoch 30/50\n",
      "1719/1719 [==============================] - 0s 75us/sample - loss: 0.3268 - accuracy: 0.8656 - val_loss: 0.3877 - val_accuracy: 0.8140\n",
      "Epoch 31/50\n",
      "1719/1719 [==============================] - 0s 77us/sample - loss: 0.3254 - accuracy: 0.8633 - val_loss: 0.3889 - val_accuracy: 0.8093\n",
      "Epoch 32/50\n",
      "1719/1719 [==============================] - 0s 70us/sample - loss: 0.3239 - accuracy: 0.8610 - val_loss: 0.3880 - val_accuracy: 0.8047\n",
      "Epoch 33/50\n",
      "1719/1719 [==============================] - 0s 69us/sample - loss: 0.3220 - accuracy: 0.8639 - val_loss: 0.3915 - val_accuracy: 0.8047\n",
      "Epoch 34/50\n",
      "1719/1719 [==============================] - 0s 74us/sample - loss: 0.3212 - accuracy: 0.8662 - val_loss: 0.3910 - val_accuracy: 0.8047\n",
      "Epoch 35/50\n",
      "1719/1719 [==============================] - 0s 72us/sample - loss: 0.3197 - accuracy: 0.8627 - val_loss: 0.3909 - val_accuracy: 0.8000\n",
      "Epoch 36/50\n",
      "1719/1719 [==============================] - 0s 80us/sample - loss: 0.3185 - accuracy: 0.8650 - val_loss: 0.3907 - val_accuracy: 0.8000\n",
      "Epoch 37/50\n",
      "1719/1719 [==============================] - 0s 77us/sample - loss: 0.3175 - accuracy: 0.8639 - val_loss: 0.3920 - val_accuracy: 0.8047\n",
      "Epoch 38/50\n",
      "1719/1719 [==============================] - 0s 73us/sample - loss: 0.3163 - accuracy: 0.8650 - val_loss: 0.3927 - val_accuracy: 0.8000\n",
      "Epoch 39/50\n",
      "1719/1719 [==============================] - 0s 67us/sample - loss: 0.3153 - accuracy: 0.8662 - val_loss: 0.3942 - val_accuracy: 0.8047\n",
      "Epoch 40/50\n",
      "1719/1719 [==============================] - 0s 63us/sample - loss: 0.3143 - accuracy: 0.8656 - val_loss: 0.3934 - val_accuracy: 0.8047\n",
      "Epoch 41/50\n",
      "1719/1719 [==============================] - 0s 64us/sample - loss: 0.3130 - accuracy: 0.8703 - val_loss: 0.3964 - val_accuracy: 0.8047\n",
      "Epoch 42/50\n",
      "1719/1719 [==============================] - 0s 62us/sample - loss: 0.3120 - accuracy: 0.8645 - val_loss: 0.3969 - val_accuracy: 0.8047\n",
      "Epoch 43/50\n",
      "1719/1719 [==============================] - 0s 65us/sample - loss: 0.3112 - accuracy: 0.8679 - val_loss: 0.3990 - val_accuracy: 0.8000\n",
      "Epoch 44/50\n",
      "1719/1719 [==============================] - 0s 72us/sample - loss: 0.3102 - accuracy: 0.8685 - val_loss: 0.3987 - val_accuracy: 0.8000\n",
      "Epoch 45/50\n",
      "1719/1719 [==============================] - 0s 72us/sample - loss: 0.3093 - accuracy: 0.8685 - val_loss: 0.4004 - val_accuracy: 0.8000\n",
      "Epoch 46/50\n",
      "1719/1719 [==============================] - 0s 134us/sample - loss: 0.3084 - accuracy: 0.8709 - val_loss: 0.4008 - val_accuracy: 0.7953\n",
      "Epoch 47/50\n",
      "1719/1719 [==============================] - 0s 81us/sample - loss: 0.3071 - accuracy: 0.8703 - val_loss: 0.4029 - val_accuracy: 0.7953\n",
      "Epoch 48/50\n",
      "1719/1719 [==============================] - 0s 67us/sample - loss: 0.3063 - accuracy: 0.8714 - val_loss: 0.4057 - val_accuracy: 0.8000\n",
      "Epoch 49/50\n",
      "1719/1719 [==============================] - 0s 71us/sample - loss: 0.3057 - accuracy: 0.8709 - val_loss: 0.4061 - val_accuracy: 0.7953\n",
      "Epoch 50/50\n",
      "1719/1719 [==============================] - 0s 70us/sample - loss: 0.3044 - accuracy: 0.8732 - val_loss: 0.4072 - val_accuracy: 0.8047\n",
      "215/215 - 0s - loss: 0.4555 - accuracy: 0.7907\n",
      "215/215 - 0s - loss: 0.4072 - accuracy: 0.8047\n",
      "Loss: 0.45547000114307845, Accuracy: 0.7906976938247681\n",
      "Validation Set - Loss: 0.4072035289087961, Accuracy: 0.804651141166687\n"
     ]
    }
   ],
   "source": [
    "# Define the deep learning model \n",
    "nn_model = tf.keras.models.Sequential()\n",
    "nn_model.add(tf.keras.layers.Dense(units=8, activation=\"relu\", input_dim=32))\n",
    "nn_model.add(Dense(units=8, activation='relu'))\n",
    "\n",
    "# Output layer/binary classification so 1 neuron for 0 or 1\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Compile the Sequential model together and customize metrics\n",
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"RMSprop\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model w/ validation dataset\n",
    "fit_model = nn_model.fit(X_train_scaled, y_train, epochs=50, validation_data=(X_val_scaled, y_val))\n",
    "\n",
    "# Evaluate the model using the test data + validation data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "model_loss_val, model_accuracy_val = nn_model.evaluate(X_val_scaled, y_val, verbose=2)\n",
    "\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n",
    "print(f\"Validation Set - Loss: {model_loss_val}, Accuracy: {model_accuracy_val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizing learning speeds!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---> LR = 0.001 decreases accuracy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---> LR = 0.005 increases accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---> LR = 0.0001 decreases accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---> LR = 0.01 decreases accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1719 samples, validate on 215 samples\n",
      "Epoch 1/50\n",
      "1719/1719 [==============================] - 1s 331us/sample - loss: 0.7469 - accuracy: 0.5462 - val_loss: 0.7051 - val_accuracy: 0.6000\n",
      "Epoch 2/50\n",
      "1719/1719 [==============================] - 0s 50us/sample - loss: 0.6578 - accuracy: 0.6131 - val_loss: 0.6351 - val_accuracy: 0.6512\n",
      "Epoch 3/50\n",
      "1719/1719 [==============================] - 0s 42us/sample - loss: 0.5971 - accuracy: 0.6643 - val_loss: 0.5842 - val_accuracy: 0.6791\n",
      "Epoch 4/50\n",
      "1719/1719 [==============================] - 0s 43us/sample - loss: 0.5504 - accuracy: 0.7167 - val_loss: 0.5456 - val_accuracy: 0.7209\n",
      "Epoch 5/50\n",
      "1719/1719 [==============================] - 0s 38us/sample - loss: 0.5133 - accuracy: 0.7464 - val_loss: 0.5135 - val_accuracy: 0.7442\n",
      "Epoch 6/50\n",
      "1719/1719 [==============================] - 0s 38us/sample - loss: 0.4822 - accuracy: 0.7725 - val_loss: 0.4867 - val_accuracy: 0.7721\n",
      "Epoch 7/50\n",
      "1719/1719 [==============================] - 0s 37us/sample - loss: 0.4555 - accuracy: 0.7935 - val_loss: 0.4637 - val_accuracy: 0.7907\n",
      "Epoch 8/50\n",
      "1719/1719 [==============================] - 0s 42us/sample - loss: 0.4337 - accuracy: 0.8080 - val_loss: 0.4447 - val_accuracy: 0.7953\n",
      "Epoch 9/50\n",
      "1719/1719 [==============================] - 0s 42us/sample - loss: 0.4158 - accuracy: 0.8191 - val_loss: 0.4288 - val_accuracy: 0.8047\n",
      "Epoch 10/50\n",
      "1719/1719 [==============================] - 0s 43us/sample - loss: 0.4018 - accuracy: 0.8266 - val_loss: 0.4165 - val_accuracy: 0.8093\n",
      "Epoch 11/50\n",
      "1719/1719 [==============================] - 0s 35us/sample - loss: 0.3907 - accuracy: 0.8325 - val_loss: 0.4051 - val_accuracy: 0.8186\n",
      "Epoch 12/50\n",
      "1719/1719 [==============================] - 0s 40us/sample - loss: 0.3817 - accuracy: 0.8354 - val_loss: 0.3969 - val_accuracy: 0.8279\n",
      "Epoch 13/50\n",
      "1719/1719 [==============================] - 0s 40us/sample - loss: 0.3742 - accuracy: 0.8412 - val_loss: 0.3892 - val_accuracy: 0.8279\n",
      "Epoch 14/50\n",
      "1719/1719 [==============================] - 0s 58us/sample - loss: 0.3682 - accuracy: 0.8412 - val_loss: 0.3838 - val_accuracy: 0.8326\n",
      "Epoch 15/50\n",
      "1719/1719 [==============================] - 0s 79us/sample - loss: 0.3630 - accuracy: 0.8441 - val_loss: 0.3801 - val_accuracy: 0.8279\n",
      "Epoch 16/50\n",
      "1719/1719 [==============================] - 0s 39us/sample - loss: 0.3585 - accuracy: 0.8470 - val_loss: 0.3765 - val_accuracy: 0.8419\n",
      "Epoch 17/50\n",
      "1719/1719 [==============================] - 0s 41us/sample - loss: 0.3545 - accuracy: 0.8482 - val_loss: 0.3735 - val_accuracy: 0.8372\n",
      "Epoch 18/50\n",
      "1719/1719 [==============================] - 0s 45us/sample - loss: 0.3508 - accuracy: 0.8482 - val_loss: 0.3719 - val_accuracy: 0.8326\n",
      "Epoch 19/50\n",
      "1719/1719 [==============================] - 0s 39us/sample - loss: 0.3476 - accuracy: 0.8487 - val_loss: 0.3701 - val_accuracy: 0.8372\n",
      "Epoch 20/50\n",
      "1719/1719 [==============================] - 0s 39us/sample - loss: 0.3450 - accuracy: 0.8522 - val_loss: 0.3685 - val_accuracy: 0.8372\n",
      "Epoch 21/50\n",
      "1719/1719 [==============================] - 0s 49us/sample - loss: 0.3426 - accuracy: 0.8528 - val_loss: 0.3678 - val_accuracy: 0.8372\n",
      "Epoch 22/50\n",
      "1719/1719 [==============================] - 0s 38us/sample - loss: 0.3403 - accuracy: 0.8569 - val_loss: 0.3666 - val_accuracy: 0.8372\n",
      "Epoch 23/50\n",
      "1719/1719 [==============================] - 0s 51us/sample - loss: 0.3379 - accuracy: 0.8569 - val_loss: 0.3658 - val_accuracy: 0.8326\n",
      "Epoch 24/50\n",
      "1719/1719 [==============================] - 0s 40us/sample - loss: 0.3356 - accuracy: 0.8581 - val_loss: 0.3651 - val_accuracy: 0.8326\n",
      "Epoch 25/50\n",
      "1719/1719 [==============================] - 0s 45us/sample - loss: 0.3333 - accuracy: 0.8598 - val_loss: 0.3648 - val_accuracy: 0.8326\n",
      "Epoch 26/50\n",
      "1719/1719 [==============================] - 0s 43us/sample - loss: 0.3312 - accuracy: 0.8627 - val_loss: 0.3638 - val_accuracy: 0.8326\n",
      "Epoch 27/50\n",
      "1719/1719 [==============================] - 0s 42us/sample - loss: 0.3290 - accuracy: 0.8633 - val_loss: 0.3624 - val_accuracy: 0.8326\n",
      "Epoch 28/50\n",
      "1719/1719 [==============================] - 0s 43us/sample - loss: 0.3270 - accuracy: 0.8645 - val_loss: 0.3618 - val_accuracy: 0.8326\n",
      "Epoch 29/50\n",
      "1719/1719 [==============================] - 0s 52us/sample - loss: 0.3250 - accuracy: 0.8639 - val_loss: 0.3610 - val_accuracy: 0.8326\n",
      "Epoch 30/50\n",
      "1719/1719 [==============================] - 0s 44us/sample - loss: 0.3231 - accuracy: 0.8662 - val_loss: 0.3611 - val_accuracy: 0.8326\n",
      "Epoch 31/50\n",
      "1719/1719 [==============================] - 0s 49us/sample - loss: 0.3215 - accuracy: 0.8679 - val_loss: 0.3597 - val_accuracy: 0.8326\n",
      "Epoch 32/50\n",
      "1719/1719 [==============================] - 0s 48us/sample - loss: 0.3200 - accuracy: 0.8685 - val_loss: 0.3597 - val_accuracy: 0.8279\n",
      "Epoch 33/50\n",
      "1719/1719 [==============================] - 0s 51us/sample - loss: 0.3186 - accuracy: 0.8679 - val_loss: 0.3586 - val_accuracy: 0.8279\n",
      "Epoch 34/50\n",
      "1719/1719 [==============================] - 0s 55us/sample - loss: 0.3171 - accuracy: 0.8633 - val_loss: 0.3588 - val_accuracy: 0.8279\n",
      "Epoch 35/50\n",
      "1719/1719 [==============================] - 0s 61us/sample - loss: 0.3155 - accuracy: 0.8703 - val_loss: 0.3578 - val_accuracy: 0.8279\n",
      "Epoch 36/50\n",
      "1719/1719 [==============================] - 0s 63us/sample - loss: 0.3140 - accuracy: 0.8703 - val_loss: 0.3585 - val_accuracy: 0.8279\n",
      "Epoch 37/50\n",
      "1719/1719 [==============================] - 0s 60us/sample - loss: 0.3129 - accuracy: 0.8697 - val_loss: 0.3576 - val_accuracy: 0.8279\n",
      "Epoch 38/50\n",
      "1719/1719 [==============================] - 0s 60us/sample - loss: 0.3114 - accuracy: 0.8714 - val_loss: 0.3584 - val_accuracy: 0.8326\n",
      "Epoch 39/50\n",
      "1719/1719 [==============================] - 0s 66us/sample - loss: 0.3099 - accuracy: 0.8703 - val_loss: 0.3581 - val_accuracy: 0.8326\n",
      "Epoch 40/50\n",
      "1719/1719 [==============================] - 0s 64us/sample - loss: 0.3089 - accuracy: 0.8720 - val_loss: 0.3591 - val_accuracy: 0.8326\n",
      "Epoch 41/50\n",
      "1719/1719 [==============================] - 0s 64us/sample - loss: 0.3076 - accuracy: 0.8755 - val_loss: 0.3603 - val_accuracy: 0.8326\n",
      "Epoch 42/50\n",
      "1719/1719 [==============================] - 0s 68us/sample - loss: 0.3066 - accuracy: 0.8743 - val_loss: 0.3603 - val_accuracy: 0.8279\n",
      "Epoch 43/50\n",
      "1719/1719 [==============================] - 0s 66us/sample - loss: 0.3055 - accuracy: 0.8773 - val_loss: 0.3596 - val_accuracy: 0.8279\n",
      "Epoch 44/50\n",
      "1719/1719 [==============================] - 0s 76us/sample - loss: 0.3045 - accuracy: 0.8767 - val_loss: 0.3596 - val_accuracy: 0.8279\n",
      "Epoch 45/50\n",
      "1719/1719 [==============================] - 0s 65us/sample - loss: 0.3033 - accuracy: 0.8790 - val_loss: 0.3603 - val_accuracy: 0.8326\n",
      "Epoch 46/50\n",
      "1719/1719 [==============================] - 0s 65us/sample - loss: 0.3021 - accuracy: 0.8802 - val_loss: 0.3596 - val_accuracy: 0.8279\n",
      "Epoch 47/50\n",
      "1719/1719 [==============================] - 0s 81us/sample - loss: 0.3006 - accuracy: 0.8813 - val_loss: 0.3596 - val_accuracy: 0.8279\n",
      "Epoch 48/50\n",
      "1719/1719 [==============================] - 0s 75us/sample - loss: 0.2997 - accuracy: 0.8773 - val_loss: 0.3592 - val_accuracy: 0.8279\n",
      "Epoch 49/50\n",
      "1719/1719 [==============================] - 0s 86us/sample - loss: 0.2984 - accuracy: 0.8807 - val_loss: 0.3606 - val_accuracy: 0.8326\n",
      "Epoch 50/50\n",
      "1719/1719 [==============================] - 0s 75us/sample - loss: 0.2974 - accuracy: 0.8790 - val_loss: 0.3604 - val_accuracy: 0.8326\n",
      "215/215 - 0s - loss: 0.4570 - accuracy: 0.8000\n",
      "215/215 - 0s - loss: 0.3604 - accuracy: 0.8326\n",
      "Loss: 0.457002972170364, Accuracy: 0.800000011920929\n",
      "Validation Set - Loss: 0.3603828771169795, Accuracy: 0.8325581550598145\n"
     ]
    }
   ],
   "source": [
    "# Define the deep learning model \n",
    "nn_model = tf.keras.models.Sequential()\n",
    "nn_model.add(tf.keras.layers.Dense(units=8, activation=\"relu\", input_dim=32))\n",
    "\n",
    "# Output layer/binary classification so 1 neuron for 0 or 1\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.001)\n",
    "\n",
    "# Compile the Sequential model together and customize metrics\n",
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model w/ validation dataset\n",
    "fit_model = nn_model.fit(X_train_scaled, y_train, epochs=50, validation_data=(X_val_scaled, y_val))\n",
    "\n",
    "# Evaluate the model using the test data + validation data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "model_loss_val, model_accuracy_val = nn_model.evaluate(X_val_scaled, y_val, verbose=2)\n",
    "\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n",
    "print(f\"Validation Set - Loss: {model_loss_val}, Accuracy: {model_accuracy_val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1719 samples, validate on 215 samples\n",
      "Epoch 1/50\n",
      "1719/1719 [==============================] - 1s 337us/sample - loss: 0.6269 - accuracy: 0.6789 - val_loss: 0.4485 - val_accuracy: 0.8140\n",
      "Epoch 2/50\n",
      "1719/1719 [==============================] - 0s 39us/sample - loss: 0.4482 - accuracy: 0.8092 - val_loss: 0.3842 - val_accuracy: 0.8419\n",
      "Epoch 3/50\n",
      "1719/1719 [==============================] - 0s 40us/sample - loss: 0.3868 - accuracy: 0.8406 - val_loss: 0.3600 - val_accuracy: 0.8279\n",
      "Epoch 4/50\n",
      "1719/1719 [==============================] - 0s 36us/sample - loss: 0.3646 - accuracy: 0.8505 - val_loss: 0.3577 - val_accuracy: 0.8233\n",
      "Epoch 5/50\n",
      "1719/1719 [==============================] - 0s 41us/sample - loss: 0.3505 - accuracy: 0.8517 - val_loss: 0.3527 - val_accuracy: 0.8279\n",
      "Epoch 6/50\n",
      "1719/1719 [==============================] - 0s 40us/sample - loss: 0.3420 - accuracy: 0.8551 - val_loss: 0.3584 - val_accuracy: 0.8279\n",
      "Epoch 7/50\n",
      "1719/1719 [==============================] - 0s 41us/sample - loss: 0.3345 - accuracy: 0.8639 - val_loss: 0.3560 - val_accuracy: 0.8372\n",
      "Epoch 8/50\n",
      "1719/1719 [==============================] - 0s 40us/sample - loss: 0.3267 - accuracy: 0.8668 - val_loss: 0.3563 - val_accuracy: 0.8512\n",
      "Epoch 9/50\n",
      "1719/1719 [==============================] - 0s 55us/sample - loss: 0.3219 - accuracy: 0.8749 - val_loss: 0.3644 - val_accuracy: 0.8372\n",
      "Epoch 10/50\n",
      "1719/1719 [==============================] - 0s 44us/sample - loss: 0.3174 - accuracy: 0.8761 - val_loss: 0.3468 - val_accuracy: 0.8419\n",
      "Epoch 11/50\n",
      "1719/1719 [==============================] - 0s 44us/sample - loss: 0.3120 - accuracy: 0.8726 - val_loss: 0.3584 - val_accuracy: 0.8419\n",
      "Epoch 12/50\n",
      "1719/1719 [==============================] - 0s 48us/sample - loss: 0.3087 - accuracy: 0.8749 - val_loss: 0.3520 - val_accuracy: 0.8419\n",
      "Epoch 13/50\n",
      "1719/1719 [==============================] - 0s 49us/sample - loss: 0.3046 - accuracy: 0.8796 - val_loss: 0.3495 - val_accuracy: 0.8465\n",
      "Epoch 14/50\n",
      "1719/1719 [==============================] - 0s 45us/sample - loss: 0.2993 - accuracy: 0.8807 - val_loss: 0.3581 - val_accuracy: 0.8372\n",
      "Epoch 15/50\n",
      "1719/1719 [==============================] - 0s 46us/sample - loss: 0.2976 - accuracy: 0.8831 - val_loss: 0.3551 - val_accuracy: 0.8372\n",
      "Epoch 16/50\n",
      "1719/1719 [==============================] - 0s 43us/sample - loss: 0.2921 - accuracy: 0.8866 - val_loss: 0.3547 - val_accuracy: 0.8465\n",
      "Epoch 17/50\n",
      "1719/1719 [==============================] - 0s 57us/sample - loss: 0.2893 - accuracy: 0.8848 - val_loss: 0.3586 - val_accuracy: 0.8419\n",
      "Epoch 18/50\n",
      "1719/1719 [==============================] - 0s 49us/sample - loss: 0.2859 - accuracy: 0.8912 - val_loss: 0.3551 - val_accuracy: 0.8465\n",
      "Epoch 19/50\n",
      "1719/1719 [==============================] - 0s 54us/sample - loss: 0.2818 - accuracy: 0.8959 - val_loss: 0.3558 - val_accuracy: 0.8372\n",
      "Epoch 20/50\n",
      "1719/1719 [==============================] - 0s 55us/sample - loss: 0.2781 - accuracy: 0.8982 - val_loss: 0.3668 - val_accuracy: 0.8372\n",
      "Epoch 21/50\n",
      "1719/1719 [==============================] - 0s 66us/sample - loss: 0.2749 - accuracy: 0.8965 - val_loss: 0.3671 - val_accuracy: 0.8512\n",
      "Epoch 22/50\n",
      "1719/1719 [==============================] - 0s 63us/sample - loss: 0.2719 - accuracy: 0.8970 - val_loss: 0.3737 - val_accuracy: 0.8419\n",
      "Epoch 23/50\n",
      "1719/1719 [==============================] - 0s 67us/sample - loss: 0.2686 - accuracy: 0.8959 - val_loss: 0.3715 - val_accuracy: 0.8279\n",
      "Epoch 24/50\n",
      "1719/1719 [==============================] - 0s 68us/sample - loss: 0.2662 - accuracy: 0.9005 - val_loss: 0.3785 - val_accuracy: 0.8279\n",
      "Epoch 25/50\n",
      "1719/1719 [==============================] - 0s 68us/sample - loss: 0.2614 - accuracy: 0.9075 - val_loss: 0.3799 - val_accuracy: 0.8372\n",
      "Epoch 26/50\n",
      "1719/1719 [==============================] - 0s 66us/sample - loss: 0.2601 - accuracy: 0.9011 - val_loss: 0.3662 - val_accuracy: 0.8186\n",
      "Epoch 27/50\n",
      "1719/1719 [==============================] - 0s 66us/sample - loss: 0.2565 - accuracy: 0.9058 - val_loss: 0.3777 - val_accuracy: 0.8233\n",
      "Epoch 28/50\n",
      "1719/1719 [==============================] - 0s 70us/sample - loss: 0.2553 - accuracy: 0.9052 - val_loss: 0.3706 - val_accuracy: 0.8372\n",
      "Epoch 29/50\n",
      "1719/1719 [==============================] - 0s 67us/sample - loss: 0.2530 - accuracy: 0.9092 - val_loss: 0.3792 - val_accuracy: 0.8233\n",
      "Epoch 30/50\n",
      "1719/1719 [==============================] - 0s 67us/sample - loss: 0.2503 - accuracy: 0.9081 - val_loss: 0.3774 - val_accuracy: 0.8279\n",
      "Epoch 31/50\n",
      "1719/1719 [==============================] - 0s 68us/sample - loss: 0.2495 - accuracy: 0.9116 - val_loss: 0.3746 - val_accuracy: 0.8186\n",
      "Epoch 32/50\n",
      "1719/1719 [==============================] - 0s 68us/sample - loss: 0.2469 - accuracy: 0.9052 - val_loss: 0.3862 - val_accuracy: 0.8186\n",
      "Epoch 33/50\n",
      "1719/1719 [==============================] - 0s 69us/sample - loss: 0.2443 - accuracy: 0.9087 - val_loss: 0.3834 - val_accuracy: 0.8279\n",
      "Epoch 34/50\n",
      "1719/1719 [==============================] - 0s 70us/sample - loss: 0.2417 - accuracy: 0.9110 - val_loss: 0.3739 - val_accuracy: 0.8419\n",
      "Epoch 35/50\n",
      "1719/1719 [==============================] - 0s 67us/sample - loss: 0.2405 - accuracy: 0.9127 - val_loss: 0.3681 - val_accuracy: 0.8372\n",
      "Epoch 36/50\n",
      "1719/1719 [==============================] - 0s 67us/sample - loss: 0.2376 - accuracy: 0.9133 - val_loss: 0.3816 - val_accuracy: 0.8279\n",
      "Epoch 37/50\n",
      "1719/1719 [==============================] - 0s 72us/sample - loss: 0.2373 - accuracy: 0.9116 - val_loss: 0.3730 - val_accuracy: 0.8419\n",
      "Epoch 38/50\n",
      "1719/1719 [==============================] - 0s 75us/sample - loss: 0.2356 - accuracy: 0.9133 - val_loss: 0.3740 - val_accuracy: 0.8279\n",
      "Epoch 39/50\n",
      "1719/1719 [==============================] - 0s 97us/sample - loss: 0.2338 - accuracy: 0.9162 - val_loss: 0.3586 - val_accuracy: 0.8465\n",
      "Epoch 40/50\n",
      "1719/1719 [==============================] - 0s 73us/sample - loss: 0.2304 - accuracy: 0.9209 - val_loss: 0.3686 - val_accuracy: 0.8372\n",
      "Epoch 41/50\n",
      "1719/1719 [==============================] - 0s 70us/sample - loss: 0.2303 - accuracy: 0.9209 - val_loss: 0.3638 - val_accuracy: 0.8419\n",
      "Epoch 42/50\n",
      "1719/1719 [==============================] - 0s 73us/sample - loss: 0.2283 - accuracy: 0.9122 - val_loss: 0.3659 - val_accuracy: 0.8326\n",
      "Epoch 43/50\n",
      "1719/1719 [==============================] - 0s 77us/sample - loss: 0.2267 - accuracy: 0.9151 - val_loss: 0.3617 - val_accuracy: 0.8558\n",
      "Epoch 44/50\n",
      "1719/1719 [==============================] - 0s 68us/sample - loss: 0.2256 - accuracy: 0.9168 - val_loss: 0.3681 - val_accuracy: 0.8419\n",
      "Epoch 45/50\n",
      "1719/1719 [==============================] - 0s 80us/sample - loss: 0.2234 - accuracy: 0.9186 - val_loss: 0.3713 - val_accuracy: 0.8558\n",
      "Epoch 46/50\n",
      "1719/1719 [==============================] - 0s 75us/sample - loss: 0.2226 - accuracy: 0.9191 - val_loss: 0.3638 - val_accuracy: 0.8605\n",
      "Epoch 47/50\n",
      "1719/1719 [==============================] - 0s 80us/sample - loss: 0.2220 - accuracy: 0.9209 - val_loss: 0.3671 - val_accuracy: 0.8512\n",
      "Epoch 48/50\n",
      "1719/1719 [==============================] - 0s 75us/sample - loss: 0.2190 - accuracy: 0.9220 - val_loss: 0.3930 - val_accuracy: 0.8279\n",
      "Epoch 49/50\n",
      "1719/1719 [==============================] - 0s 73us/sample - loss: 0.2189 - accuracy: 0.9180 - val_loss: 0.3837 - val_accuracy: 0.8512\n",
      "Epoch 50/50\n",
      "1719/1719 [==============================] - 0s 81us/sample - loss: 0.2188 - accuracy: 0.9255 - val_loss: 0.3911 - val_accuracy: 0.8372\n",
      "215/215 - 0s - loss: 0.5088 - accuracy: 0.8140\n",
      "215/215 - 0s - loss: 0.3911 - accuracy: 0.8372\n",
      "Loss: 0.5087994292724964, Accuracy: 0.8139534592628479\n",
      "Validation Set - Loss: 0.39105257336483445, Accuracy: 0.8372092843055725\n"
     ]
    }
   ],
   "source": [
    "# Define the deep learning model \n",
    "nn_model = tf.keras.models.Sequential()\n",
    "nn_model.add(tf.keras.layers.Dense(units=8, activation=\"relu\", input_dim=32))\n",
    "\n",
    "# Output layer/binary classification so 1 neuron for 0 or 1\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.005)\n",
    "\n",
    "# Compile the Sequential model together and customize metrics\n",
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model w/ validation dataset\n",
    "fit_model = nn_model.fit(X_train_scaled, y_train, epochs=50, validation_data=(X_val_scaled, y_val))\n",
    "\n",
    "# Evaluate the model using the test data + validation data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "model_loss_val, model_accuracy_val = nn_model.evaluate(X_val_scaled, y_val, verbose=2)\n",
    "\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n",
    "print(f\"Validation Set - Loss: {model_loss_val}, Accuracy: {model_accuracy_val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1719 samples, validate on 215 samples\n",
      "Epoch 1/50\n",
      "1719/1719 [==============================] - 1s 342us/sample - loss: 0.5135 - accuracy: 0.7627 - val_loss: 0.4122 - val_accuracy: 0.7814\n",
      "Epoch 2/50\n",
      "1719/1719 [==============================] - 0s 40us/sample - loss: 0.3842 - accuracy: 0.8429 - val_loss: 0.3733 - val_accuracy: 0.7953\n",
      "Epoch 3/50\n",
      "1719/1719 [==============================] - 0s 39us/sample - loss: 0.3594 - accuracy: 0.8522 - val_loss: 0.3793 - val_accuracy: 0.8047\n",
      "Epoch 4/50\n",
      "1719/1719 [==============================] - 0s 42us/sample - loss: 0.3472 - accuracy: 0.8650 - val_loss: 0.3647 - val_accuracy: 0.8093\n",
      "Epoch 5/50\n",
      "1719/1719 [==============================] - 0s 41us/sample - loss: 0.3369 - accuracy: 0.8633 - val_loss: 0.3633 - val_accuracy: 0.8326\n",
      "Epoch 6/50\n",
      "1719/1719 [==============================] - 0s 47us/sample - loss: 0.3272 - accuracy: 0.8726 - val_loss: 0.3755 - val_accuracy: 0.8326\n",
      "Epoch 7/50\n",
      "1719/1719 [==============================] - 0s 43us/sample - loss: 0.3210 - accuracy: 0.8726 - val_loss: 0.3627 - val_accuracy: 0.8233\n",
      "Epoch 8/50\n",
      "1719/1719 [==============================] - 0s 36us/sample - loss: 0.3143 - accuracy: 0.8854 - val_loss: 0.3596 - val_accuracy: 0.8326\n",
      "Epoch 9/50\n",
      "1719/1719 [==============================] - 0s 40us/sample - loss: 0.3070 - accuracy: 0.8778 - val_loss: 0.3740 - val_accuracy: 0.8186\n",
      "Epoch 10/50\n",
      "1719/1719 [==============================] - 0s 38us/sample - loss: 0.3004 - accuracy: 0.8889 - val_loss: 0.3526 - val_accuracy: 0.8419\n",
      "Epoch 11/50\n",
      "1719/1719 [==============================] - 0s 45us/sample - loss: 0.2973 - accuracy: 0.8813 - val_loss: 0.3720 - val_accuracy: 0.8279\n",
      "Epoch 12/50\n",
      "1719/1719 [==============================] - 0s 51us/sample - loss: 0.2914 - accuracy: 0.8901 - val_loss: 0.3666 - val_accuracy: 0.8419\n",
      "Epoch 13/50\n",
      "1719/1719 [==============================] - 0s 40us/sample - loss: 0.2886 - accuracy: 0.8837 - val_loss: 0.3492 - val_accuracy: 0.8605\n",
      "Epoch 14/50\n",
      "1719/1719 [==============================] - 0s 41us/sample - loss: 0.2846 - accuracy: 0.8930 - val_loss: 0.3647 - val_accuracy: 0.8279\n",
      "Epoch 15/50\n",
      "1719/1719 [==============================] - 0s 46us/sample - loss: 0.2824 - accuracy: 0.8953 - val_loss: 0.3661 - val_accuracy: 0.8372\n",
      "Epoch 16/50\n",
      "1719/1719 [==============================] - 0s 35us/sample - loss: 0.2787 - accuracy: 0.8941 - val_loss: 0.3470 - val_accuracy: 0.8558\n",
      "Epoch 17/50\n",
      "1719/1719 [==============================] - 0s 34us/sample - loss: 0.2773 - accuracy: 0.8877 - val_loss: 0.3441 - val_accuracy: 0.8605\n",
      "Epoch 18/50\n",
      "1719/1719 [==============================] - 0s 36us/sample - loss: 0.2739 - accuracy: 0.8918 - val_loss: 0.3583 - val_accuracy: 0.8465\n",
      "Epoch 19/50\n",
      "1719/1719 [==============================] - 0s 39us/sample - loss: 0.2686 - accuracy: 0.9011 - val_loss: 0.3640 - val_accuracy: 0.8465\n",
      "Epoch 20/50\n",
      "1719/1719 [==============================] - 0s 42us/sample - loss: 0.2658 - accuracy: 0.8941 - val_loss: 0.3710 - val_accuracy: 0.8419\n",
      "Epoch 21/50\n",
      "1719/1719 [==============================] - 0s 42us/sample - loss: 0.2642 - accuracy: 0.8959 - val_loss: 0.3774 - val_accuracy: 0.8279\n",
      "Epoch 22/50\n",
      "1719/1719 [==============================] - 0s 47us/sample - loss: 0.2594 - accuracy: 0.9023 - val_loss: 0.3683 - val_accuracy: 0.8279\n",
      "Epoch 23/50\n",
      "1719/1719 [==============================] - 0s 46us/sample - loss: 0.2581 - accuracy: 0.8988 - val_loss: 0.3781 - val_accuracy: 0.8465\n",
      "Epoch 24/50\n",
      "1719/1719 [==============================] - 0s 40us/sample - loss: 0.2532 - accuracy: 0.9046 - val_loss: 0.3832 - val_accuracy: 0.8512\n",
      "Epoch 25/50\n",
      "1719/1719 [==============================] - 0s 42us/sample - loss: 0.2537 - accuracy: 0.9034 - val_loss: 0.3891 - val_accuracy: 0.8372\n",
      "Epoch 26/50\n",
      "1719/1719 [==============================] - 0s 67us/sample - loss: 0.2485 - accuracy: 0.9052 - val_loss: 0.3814 - val_accuracy: 0.8372\n",
      "Epoch 27/50\n",
      "1719/1719 [==============================] - 0s 38us/sample - loss: 0.2517 - accuracy: 0.9058 - val_loss: 0.3694 - val_accuracy: 0.8372\n",
      "Epoch 28/50\n",
      "1719/1719 [==============================] - 0s 45us/sample - loss: 0.2483 - accuracy: 0.9040 - val_loss: 0.3859 - val_accuracy: 0.8372\n",
      "Epoch 29/50\n",
      "1719/1719 [==============================] - 0s 40us/sample - loss: 0.2472 - accuracy: 0.9052 - val_loss: 0.3998 - val_accuracy: 0.8419\n",
      "Epoch 30/50\n",
      "1719/1719 [==============================] - 0s 44us/sample - loss: 0.2444 - accuracy: 0.9052 - val_loss: 0.4069 - val_accuracy: 0.8233\n",
      "Epoch 31/50\n",
      "1719/1719 [==============================] - 0s 41us/sample - loss: 0.2436 - accuracy: 0.9029 - val_loss: 0.3981 - val_accuracy: 0.8372\n",
      "Epoch 32/50\n",
      "1719/1719 [==============================] - 0s 36us/sample - loss: 0.2432 - accuracy: 0.9104 - val_loss: 0.4068 - val_accuracy: 0.8233\n",
      "Epoch 33/50\n",
      "1719/1719 [==============================] - 0s 45us/sample - loss: 0.2431 - accuracy: 0.9034 - val_loss: 0.3972 - val_accuracy: 0.8279\n",
      "Epoch 34/50\n",
      "1719/1719 [==============================] - 0s 39us/sample - loss: 0.2419 - accuracy: 0.9116 - val_loss: 0.3777 - val_accuracy: 0.8419\n",
      "Epoch 35/50\n",
      "1719/1719 [==============================] - 0s 44us/sample - loss: 0.2409 - accuracy: 0.9110 - val_loss: 0.4162 - val_accuracy: 0.8233\n",
      "Epoch 36/50\n",
      "1719/1719 [==============================] - 0s 39us/sample - loss: 0.2385 - accuracy: 0.9116 - val_loss: 0.3987 - val_accuracy: 0.8279\n",
      "Epoch 37/50\n",
      "1719/1719 [==============================] - 0s 40us/sample - loss: 0.2342 - accuracy: 0.9127 - val_loss: 0.4077 - val_accuracy: 0.8279\n",
      "Epoch 38/50\n",
      "1719/1719 [==============================] - 0s 52us/sample - loss: 0.2398 - accuracy: 0.9122 - val_loss: 0.3972 - val_accuracy: 0.8372\n",
      "Epoch 39/50\n",
      "1719/1719 [==============================] - 0s 43us/sample - loss: 0.2377 - accuracy: 0.9122 - val_loss: 0.4016 - val_accuracy: 0.8279\n",
      "Epoch 40/50\n",
      "1719/1719 [==============================] - 0s 41us/sample - loss: 0.2341 - accuracy: 0.9151 - val_loss: 0.3996 - val_accuracy: 0.8326\n",
      "Epoch 41/50\n",
      "1719/1719 [==============================] - 0s 43us/sample - loss: 0.2342 - accuracy: 0.9156 - val_loss: 0.4146 - val_accuracy: 0.8279\n",
      "Epoch 42/50\n",
      "1719/1719 [==============================] - 0s 45us/sample - loss: 0.2365 - accuracy: 0.9133 - val_loss: 0.4218 - val_accuracy: 0.8372\n",
      "Epoch 43/50\n",
      "1719/1719 [==============================] - 0s 42us/sample - loss: 0.2331 - accuracy: 0.9104 - val_loss: 0.3941 - val_accuracy: 0.8465\n",
      "Epoch 44/50\n",
      "1719/1719 [==============================] - 0s 49us/sample - loss: 0.2287 - accuracy: 0.9145 - val_loss: 0.4107 - val_accuracy: 0.8419\n",
      "Epoch 45/50\n",
      "1719/1719 [==============================] - 0s 49us/sample - loss: 0.2350 - accuracy: 0.9098 - val_loss: 0.3986 - val_accuracy: 0.8279\n",
      "Epoch 46/50\n",
      "1719/1719 [==============================] - 0s 50us/sample - loss: 0.2335 - accuracy: 0.9127 - val_loss: 0.4114 - val_accuracy: 0.8233\n",
      "Epoch 47/50\n",
      "1719/1719 [==============================] - 0s 57us/sample - loss: 0.2309 - accuracy: 0.9145 - val_loss: 0.3846 - val_accuracy: 0.8465\n",
      "Epoch 48/50\n",
      "1719/1719 [==============================] - 0s 59us/sample - loss: 0.2280 - accuracy: 0.9139 - val_loss: 0.4107 - val_accuracy: 0.8372\n",
      "Epoch 49/50\n",
      "1719/1719 [==============================] - 0s 60us/sample - loss: 0.2302 - accuracy: 0.9127 - val_loss: 0.4047 - val_accuracy: 0.8326\n",
      "Epoch 50/50\n",
      "1719/1719 [==============================] - 0s 74us/sample - loss: 0.2307 - accuracy: 0.9162 - val_loss: 0.4254 - val_accuracy: 0.8372\n",
      "215/215 - 0s - loss: 0.5780 - accuracy: 0.7907\n",
      "215/215 - 0s - loss: 0.4254 - accuracy: 0.8372\n",
      "Loss: 0.5780076121175012, Accuracy: 0.7906976938247681\n",
      "Validation Set - Loss: 0.42541782315387283, Accuracy: 0.8372092843055725\n"
     ]
    }
   ],
   "source": [
    "# Define the deep learning model \n",
    "nn_model = tf.keras.models.Sequential()\n",
    "nn_model.add(tf.keras.layers.Dense(units=8, activation=\"relu\", input_dim=32))\n",
    "\n",
    "# Output layer/binary classification so 1 neuron for 0 or 1\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.01)\n",
    "\n",
    "# Compile the Sequential model together and customize metrics\n",
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model w/ validation dataset\n",
    "fit_model = nn_model.fit(X_train_scaled, y_train, epochs=50, validation_data=(X_val_scaled, y_val))\n",
    "\n",
    "# Evaluate the model using the test data + validation data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "model_loss_val, model_accuracy_val = nn_model.evaluate(X_val_scaled, y_val, verbose=2)\n",
    "\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n",
    "print(f\"Validation Set - Loss: {model_loss_val}, Accuracy: {model_accuracy_val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1719 samples, validate on 215 samples\n",
      "Epoch 1/50\n",
      "1719/1719 [==============================] - 1s 346us/sample - loss: 0.7561 - accuracy: 0.5492 - val_loss: 0.7017 - val_accuracy: 0.6000\n",
      "Epoch 2/50\n",
      "1719/1719 [==============================] - 0s 41us/sample - loss: 0.7425 - accuracy: 0.5544 - val_loss: 0.6917 - val_accuracy: 0.6093\n",
      "Epoch 3/50\n",
      "1719/1719 [==============================] - 0s 47us/sample - loss: 0.7297 - accuracy: 0.5649 - val_loss: 0.6821 - val_accuracy: 0.6140\n",
      "Epoch 4/50\n",
      "1719/1719 [==============================] - 0s 47us/sample - loss: 0.7175 - accuracy: 0.5736 - val_loss: 0.6730 - val_accuracy: 0.6140\n",
      "Epoch 5/50\n",
      "1719/1719 [==============================] - 0s 46us/sample - loss: 0.7058 - accuracy: 0.5817 - val_loss: 0.6645 - val_accuracy: 0.6233\n",
      "Epoch 6/50\n",
      "1719/1719 [==============================] - 0s 43us/sample - loss: 0.6945 - accuracy: 0.5910 - val_loss: 0.6560 - val_accuracy: 0.6465\n",
      "Epoch 7/50\n",
      "1719/1719 [==============================] - 0s 43us/sample - loss: 0.6836 - accuracy: 0.5945 - val_loss: 0.6481 - val_accuracy: 0.6512\n",
      "Epoch 8/50\n",
      "1719/1719 [==============================] - 0s 42us/sample - loss: 0.6736 - accuracy: 0.6038 - val_loss: 0.6406 - val_accuracy: 0.6605\n",
      "Epoch 9/50\n",
      "1719/1719 [==============================] - 0s 46us/sample - loss: 0.6640 - accuracy: 0.6097 - val_loss: 0.6336 - val_accuracy: 0.6651\n",
      "Epoch 10/50\n",
      "1719/1719 [==============================] - 0s 48us/sample - loss: 0.6546 - accuracy: 0.6166 - val_loss: 0.6268 - val_accuracy: 0.6791\n",
      "Epoch 11/50\n",
      "1719/1719 [==============================] - 0s 44us/sample - loss: 0.6454 - accuracy: 0.6236 - val_loss: 0.6201 - val_accuracy: 0.6837\n",
      "Epoch 12/50\n",
      "1719/1719 [==============================] - 0s 44us/sample - loss: 0.6368 - accuracy: 0.6289 - val_loss: 0.6138 - val_accuracy: 0.6837\n",
      "Epoch 13/50\n",
      "1719/1719 [==============================] - 0s 50us/sample - loss: 0.6285 - accuracy: 0.6364 - val_loss: 0.6077 - val_accuracy: 0.6837\n",
      "Epoch 14/50\n",
      "1719/1719 [==============================] - 0s 50us/sample - loss: 0.6205 - accuracy: 0.6457 - val_loss: 0.6020 - val_accuracy: 0.6791\n",
      "Epoch 15/50\n",
      "1719/1719 [==============================] - 0s 44us/sample - loss: 0.6129 - accuracy: 0.6527 - val_loss: 0.5965 - val_accuracy: 0.6837\n",
      "Epoch 16/50\n",
      "1719/1719 [==============================] - 0s 42us/sample - loss: 0.6056 - accuracy: 0.6608 - val_loss: 0.5912 - val_accuracy: 0.6884\n",
      "Epoch 17/50\n",
      "1719/1719 [==============================] - 0s 46us/sample - loss: 0.5986 - accuracy: 0.6661 - val_loss: 0.5863 - val_accuracy: 0.6930\n",
      "Epoch 18/50\n",
      "1719/1719 [==============================] - 0s 46us/sample - loss: 0.5918 - accuracy: 0.6713 - val_loss: 0.5814 - val_accuracy: 0.6930\n",
      "Epoch 19/50\n",
      "1719/1719 [==============================] - 0s 47us/sample - loss: 0.5853 - accuracy: 0.6789 - val_loss: 0.5766 - val_accuracy: 0.6930\n",
      "Epoch 20/50\n",
      "1719/1719 [==============================] - 0s 100us/sample - loss: 0.5792 - accuracy: 0.6830 - val_loss: 0.5721 - val_accuracy: 0.6977\n",
      "Epoch 21/50\n",
      "1719/1719 [==============================] - 0s 52us/sample - loss: 0.5733 - accuracy: 0.6882 - val_loss: 0.5678 - val_accuracy: 0.6977\n",
      "Epoch 22/50\n",
      "1719/1719 [==============================] - 0s 58us/sample - loss: 0.5675 - accuracy: 0.6946 - val_loss: 0.5636 - val_accuracy: 0.7023\n",
      "Epoch 23/50\n",
      "1719/1719 [==============================] - 0s 61us/sample - loss: 0.5620 - accuracy: 0.7039 - val_loss: 0.5597 - val_accuracy: 0.7116\n",
      "Epoch 24/50\n",
      "1719/1719 [==============================] - 0s 64us/sample - loss: 0.5567 - accuracy: 0.7097 - val_loss: 0.5559 - val_accuracy: 0.7116\n",
      "Epoch 25/50\n",
      "1719/1719 [==============================] - 0s 63us/sample - loss: 0.5515 - accuracy: 0.7150 - val_loss: 0.5522 - val_accuracy: 0.7116\n",
      "Epoch 26/50\n",
      "1719/1719 [==============================] - 0s 67us/sample - loss: 0.5466 - accuracy: 0.7208 - val_loss: 0.5486 - val_accuracy: 0.7256\n",
      "Epoch 27/50\n",
      "1719/1719 [==============================] - 0s 67us/sample - loss: 0.5420 - accuracy: 0.7231 - val_loss: 0.5451 - val_accuracy: 0.7256\n",
      "Epoch 28/50\n",
      "1719/1719 [==============================] - 0s 68us/sample - loss: 0.5374 - accuracy: 0.7237 - val_loss: 0.5418 - val_accuracy: 0.7349\n",
      "Epoch 29/50\n",
      "1719/1719 [==============================] - 0s 83us/sample - loss: 0.5329 - accuracy: 0.7289 - val_loss: 0.5385 - val_accuracy: 0.7395\n",
      "Epoch 30/50\n",
      "1719/1719 [==============================] - 0s 85us/sample - loss: 0.5285 - accuracy: 0.7341 - val_loss: 0.5353 - val_accuracy: 0.7349\n",
      "Epoch 31/50\n",
      "1719/1719 [==============================] - 0s 63us/sample - loss: 0.5243 - accuracy: 0.7394 - val_loss: 0.5322 - val_accuracy: 0.7256\n",
      "Epoch 32/50\n",
      "1719/1719 [==============================] - 0s 75us/sample - loss: 0.5202 - accuracy: 0.7429 - val_loss: 0.5292 - val_accuracy: 0.7256\n",
      "Epoch 33/50\n",
      "1719/1719 [==============================] - 0s 73us/sample - loss: 0.5163 - accuracy: 0.7452 - val_loss: 0.5263 - val_accuracy: 0.7209\n",
      "Epoch 34/50\n",
      "1719/1719 [==============================] - 0s 72us/sample - loss: 0.5124 - accuracy: 0.7493 - val_loss: 0.5234 - val_accuracy: 0.7209\n",
      "Epoch 35/50\n",
      "1719/1719 [==============================] - 0s 69us/sample - loss: 0.5087 - accuracy: 0.7504 - val_loss: 0.5206 - val_accuracy: 0.7070\n",
      "Epoch 36/50\n",
      "1719/1719 [==============================] - 0s 73us/sample - loss: 0.5050 - accuracy: 0.7545 - val_loss: 0.5178 - val_accuracy: 0.7116\n",
      "Epoch 37/50\n",
      "1719/1719 [==============================] - 0s 68us/sample - loss: 0.5015 - accuracy: 0.7592 - val_loss: 0.5151 - val_accuracy: 0.7116\n",
      "Epoch 38/50\n",
      "1719/1719 [==============================] - 0s 69us/sample - loss: 0.4981 - accuracy: 0.7592 - val_loss: 0.5125 - val_accuracy: 0.7116\n",
      "Epoch 39/50\n",
      "1719/1719 [==============================] - 0s 68us/sample - loss: 0.4947 - accuracy: 0.7632 - val_loss: 0.5100 - val_accuracy: 0.7070\n",
      "Epoch 40/50\n",
      "1719/1719 [==============================] - 0s 66us/sample - loss: 0.4915 - accuracy: 0.7656 - val_loss: 0.5075 - val_accuracy: 0.7116\n",
      "Epoch 41/50\n",
      "1719/1719 [==============================] - 0s 72us/sample - loss: 0.4884 - accuracy: 0.7679 - val_loss: 0.5051 - val_accuracy: 0.7116\n",
      "Epoch 42/50\n",
      "1719/1719 [==============================] - 0s 71us/sample - loss: 0.4853 - accuracy: 0.7702 - val_loss: 0.5026 - val_accuracy: 0.7116\n",
      "Epoch 43/50\n",
      "1719/1719 [==============================] - 0s 71us/sample - loss: 0.4823 - accuracy: 0.7731 - val_loss: 0.5001 - val_accuracy: 0.7163\n",
      "Epoch 44/50\n",
      "1719/1719 [==============================] - 0s 70us/sample - loss: 0.4793 - accuracy: 0.7755 - val_loss: 0.4977 - val_accuracy: 0.7163\n",
      "Epoch 45/50\n",
      "1719/1719 [==============================] - 0s 71us/sample - loss: 0.4764 - accuracy: 0.7778 - val_loss: 0.4953 - val_accuracy: 0.7209\n",
      "Epoch 46/50\n",
      "1719/1719 [==============================] - 0s 68us/sample - loss: 0.4736 - accuracy: 0.7818 - val_loss: 0.4930 - val_accuracy: 0.7256\n",
      "Epoch 47/50\n",
      "1719/1719 [==============================] - 0s 112us/sample - loss: 0.4708 - accuracy: 0.7877 - val_loss: 0.4908 - val_accuracy: 0.7256\n",
      "Epoch 48/50\n",
      "1719/1719 [==============================] - 0s 74us/sample - loss: 0.4680 - accuracy: 0.7894 - val_loss: 0.4886 - val_accuracy: 0.7302\n",
      "Epoch 49/50\n",
      "1719/1719 [==============================] - 0s 70us/sample - loss: 0.4654 - accuracy: 0.7929 - val_loss: 0.4865 - val_accuracy: 0.7302\n",
      "Epoch 50/50\n",
      "1719/1719 [==============================] - 0s 70us/sample - loss: 0.4628 - accuracy: 0.7958 - val_loss: 0.4844 - val_accuracy: 0.7349\n",
      "215/215 - 0s - loss: 0.5132 - accuracy: 0.7163\n",
      "215/215 - 0s - loss: 0.4844 - accuracy: 0.7349\n",
      "Loss: 0.5132466205330782, Accuracy: 0.7162790894508362\n",
      "Validation Set - Loss: 0.4843922340592673, Accuracy: 0.734883725643158\n"
     ]
    }
   ],
   "source": [
    "# Define the deep learning model \n",
    "nn_model = tf.keras.models.Sequential()\n",
    "nn_model.add(tf.keras.layers.Dense(units=8, activation=\"relu\", input_dim=32))\n",
    "\n",
    "# Output layer/binary classification so 1 neuron for 0 or 1\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.0001)\n",
    "\n",
    "# Compile the Sequential model together and customize metrics\n",
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model w/ validation dataset\n",
    "fit_model = nn_model.fit(X_train_scaled, y_train, epochs=50, validation_data=(X_val_scaled, y_val))\n",
    "\n",
    "# Evaluate the model using the test data + validation data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "model_loss_val, model_accuracy_val = nn_model.evaluate(X_val_scaled, y_val, verbose=2)\n",
    "\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n",
    "print(f\"Validation Set - Loss: {model_loss_val}, Accuracy: {model_accuracy_val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1719 samples, validate on 215 samples\n",
      "Epoch 1/50\n",
      "1719/1719 [==============================] - 1s 391us/sample - loss: 0.5940 - accuracy: 0.6958 - val_loss: 0.5280 - val_accuracy: 0.7070\n",
      "Epoch 2/50\n",
      "1719/1719 [==============================] - 0s 48us/sample - loss: 0.4555 - accuracy: 0.7964 - val_loss: 0.4447 - val_accuracy: 0.7860\n",
      "Epoch 3/50\n",
      "1719/1719 [==============================] - 0s 44us/sample - loss: 0.3942 - accuracy: 0.8319 - val_loss: 0.4071 - val_accuracy: 0.7907\n",
      "Epoch 4/50\n",
      "1719/1719 [==============================] - 0s 46us/sample - loss: 0.3675 - accuracy: 0.8505 - val_loss: 0.3886 - val_accuracy: 0.8233\n",
      "Epoch 5/50\n",
      "1719/1719 [==============================] - 0s 39us/sample - loss: 0.3519 - accuracy: 0.8633 - val_loss: 0.3806 - val_accuracy: 0.8140\n",
      "Epoch 6/50\n",
      "1719/1719 [==============================] - 0s 40us/sample - loss: 0.3430 - accuracy: 0.8633 - val_loss: 0.3776 - val_accuracy: 0.8279\n",
      "Epoch 7/50\n",
      "1719/1719 [==============================] - 0s 43us/sample - loss: 0.3358 - accuracy: 0.8697 - val_loss: 0.3798 - val_accuracy: 0.8140\n",
      "Epoch 8/50\n",
      "1719/1719 [==============================] - 0s 46us/sample - loss: 0.3284 - accuracy: 0.8738 - val_loss: 0.3749 - val_accuracy: 0.8279\n",
      "Epoch 9/50\n",
      "1719/1719 [==============================] - 0s 50us/sample - loss: 0.3223 - accuracy: 0.8761 - val_loss: 0.3728 - val_accuracy: 0.8279\n",
      "Epoch 10/50\n",
      "1719/1719 [==============================] - 0s 46us/sample - loss: 0.3168 - accuracy: 0.8761 - val_loss: 0.3755 - val_accuracy: 0.8233\n",
      "Epoch 11/50\n",
      "1719/1719 [==============================] - 0s 46us/sample - loss: 0.3130 - accuracy: 0.8790 - val_loss: 0.3690 - val_accuracy: 0.8279\n",
      "Epoch 12/50\n",
      "1719/1719 [==============================] - 0s 48us/sample - loss: 0.3074 - accuracy: 0.8749 - val_loss: 0.3737 - val_accuracy: 0.8326\n",
      "Epoch 13/50\n",
      "1719/1719 [==============================] - 0s 40us/sample - loss: 0.3043 - accuracy: 0.8842 - val_loss: 0.3763 - val_accuracy: 0.8372\n",
      "Epoch 14/50\n",
      "1719/1719 [==============================] - 0s 47us/sample - loss: 0.2991 - accuracy: 0.8825 - val_loss: 0.3753 - val_accuracy: 0.8233\n",
      "Epoch 15/50\n",
      "1719/1719 [==============================] - 0s 49us/sample - loss: 0.2956 - accuracy: 0.8889 - val_loss: 0.3757 - val_accuracy: 0.8233\n",
      "Epoch 16/50\n",
      "1719/1719 [==============================] - 0s 55us/sample - loss: 0.2929 - accuracy: 0.8837 - val_loss: 0.3730 - val_accuracy: 0.8279\n",
      "Epoch 17/50\n",
      "1719/1719 [==============================] - 0s 58us/sample - loss: 0.2891 - accuracy: 0.8889 - val_loss: 0.3699 - val_accuracy: 0.8233\n",
      "Epoch 18/50\n",
      "1719/1719 [==============================] - 0s 92us/sample - loss: 0.2861 - accuracy: 0.8906 - val_loss: 0.3607 - val_accuracy: 0.8372\n",
      "Epoch 19/50\n",
      "1719/1719 [==============================] - 0s 71us/sample - loss: 0.2820 - accuracy: 0.8901 - val_loss: 0.3624 - val_accuracy: 0.8326\n",
      "Epoch 20/50\n",
      "1719/1719 [==============================] - 0s 60us/sample - loss: 0.2796 - accuracy: 0.8935 - val_loss: 0.3705 - val_accuracy: 0.8233\n",
      "Epoch 21/50\n",
      "1719/1719 [==============================] - 0s 67us/sample - loss: 0.2757 - accuracy: 0.8988 - val_loss: 0.3584 - val_accuracy: 0.8279\n",
      "Epoch 22/50\n",
      "1719/1719 [==============================] - 0s 68us/sample - loss: 0.2726 - accuracy: 0.8959 - val_loss: 0.3652 - val_accuracy: 0.8326\n",
      "Epoch 23/50\n",
      "1719/1719 [==============================] - 0s 66us/sample - loss: 0.2709 - accuracy: 0.8959 - val_loss: 0.3676 - val_accuracy: 0.8279\n",
      "Epoch 24/50\n",
      "1719/1719 [==============================] - 0s 67us/sample - loss: 0.2684 - accuracy: 0.8953 - val_loss: 0.3602 - val_accuracy: 0.8419\n",
      "Epoch 25/50\n",
      "1719/1719 [==============================] - 0s 66us/sample - loss: 0.2664 - accuracy: 0.9011 - val_loss: 0.3584 - val_accuracy: 0.8279\n",
      "Epoch 26/50\n",
      "1719/1719 [==============================] - 0s 68us/sample - loss: 0.2645 - accuracy: 0.9017 - val_loss: 0.3603 - val_accuracy: 0.8279\n",
      "Epoch 27/50\n",
      "1719/1719 [==============================] - 0s 70us/sample - loss: 0.2630 - accuracy: 0.9011 - val_loss: 0.3637 - val_accuracy: 0.8326\n",
      "Epoch 28/50\n",
      "1719/1719 [==============================] - 0s 77us/sample - loss: 0.2616 - accuracy: 0.9040 - val_loss: 0.3604 - val_accuracy: 0.8419\n",
      "Epoch 29/50\n",
      "1719/1719 [==============================] - 0s 71us/sample - loss: 0.2588 - accuracy: 0.9063 - val_loss: 0.3557 - val_accuracy: 0.8465\n",
      "Epoch 30/50\n",
      "1719/1719 [==============================] - 0s 73us/sample - loss: 0.2589 - accuracy: 0.9029 - val_loss: 0.3680 - val_accuracy: 0.8279\n",
      "Epoch 31/50\n",
      "1719/1719 [==============================] - 0s 73us/sample - loss: 0.2570 - accuracy: 0.9110 - val_loss: 0.3686 - val_accuracy: 0.8326\n",
      "Epoch 32/50\n",
      "1719/1719 [==============================] - 0s 70us/sample - loss: 0.2548 - accuracy: 0.9127 - val_loss: 0.3583 - val_accuracy: 0.8512\n",
      "Epoch 33/50\n",
      "1719/1719 [==============================] - 0s 70us/sample - loss: 0.2545 - accuracy: 0.9087 - val_loss: 0.3645 - val_accuracy: 0.8419\n",
      "Epoch 34/50\n",
      "1719/1719 [==============================] - 0s 69us/sample - loss: 0.2527 - accuracy: 0.9127 - val_loss: 0.3711 - val_accuracy: 0.8326\n",
      "Epoch 35/50\n",
      "1719/1719 [==============================] - 0s 69us/sample - loss: 0.2517 - accuracy: 0.9116 - val_loss: 0.3704 - val_accuracy: 0.8465\n",
      "Epoch 36/50\n",
      "1719/1719 [==============================] - 0s 67us/sample - loss: 0.2510 - accuracy: 0.9104 - val_loss: 0.3676 - val_accuracy: 0.8372\n",
      "Epoch 37/50\n",
      "1719/1719 [==============================] - 0s 66us/sample - loss: 0.2490 - accuracy: 0.9122 - val_loss: 0.3799 - val_accuracy: 0.8326\n",
      "Epoch 38/50\n",
      "1719/1719 [==============================] - 0s 66us/sample - loss: 0.2496 - accuracy: 0.9052 - val_loss: 0.3827 - val_accuracy: 0.8279\n",
      "Epoch 39/50\n",
      "1719/1719 [==============================] - 0s 66us/sample - loss: 0.2477 - accuracy: 0.9133 - val_loss: 0.3628 - val_accuracy: 0.8326\n",
      "Epoch 40/50\n",
      "1719/1719 [==============================] - 0s 66us/sample - loss: 0.2452 - accuracy: 0.9122 - val_loss: 0.3571 - val_accuracy: 0.8465\n",
      "Epoch 41/50\n",
      "1719/1719 [==============================] - 0s 67us/sample - loss: 0.2471 - accuracy: 0.9122 - val_loss: 0.3712 - val_accuracy: 0.8326\n",
      "Epoch 42/50\n",
      "1719/1719 [==============================] - 0s 63us/sample - loss: 0.2457 - accuracy: 0.9151 - val_loss: 0.3685 - val_accuracy: 0.8465\n",
      "Epoch 43/50\n",
      "1719/1719 [==============================] - 0s 65us/sample - loss: 0.2439 - accuracy: 0.9127 - val_loss: 0.3566 - val_accuracy: 0.8512\n",
      "Epoch 44/50\n",
      "1719/1719 [==============================] - 0s 66us/sample - loss: 0.2428 - accuracy: 0.9110 - val_loss: 0.3778 - val_accuracy: 0.8372\n",
      "Epoch 45/50\n",
      "1719/1719 [==============================] - 0s 63us/sample - loss: 0.2430 - accuracy: 0.9145 - val_loss: 0.3765 - val_accuracy: 0.8419\n",
      "Epoch 46/50\n",
      "1719/1719 [==============================] - 0s 65us/sample - loss: 0.2405 - accuracy: 0.9156 - val_loss: 0.3773 - val_accuracy: 0.8372\n",
      "Epoch 47/50\n",
      "1719/1719 [==============================] - 0s 64us/sample - loss: 0.2406 - accuracy: 0.9145 - val_loss: 0.3825 - val_accuracy: 0.8233\n",
      "Epoch 48/50\n",
      "1719/1719 [==============================] - 0s 66us/sample - loss: 0.2400 - accuracy: 0.9174 - val_loss: 0.3838 - val_accuracy: 0.8512\n",
      "Epoch 49/50\n",
      "1719/1719 [==============================] - 0s 72us/sample - loss: 0.2380 - accuracy: 0.9151 - val_loss: 0.3725 - val_accuracy: 0.8465\n",
      "Epoch 50/50\n",
      "1719/1719 [==============================] - 0s 65us/sample - loss: 0.2383 - accuracy: 0.9174 - val_loss: 0.3853 - val_accuracy: 0.8512\n",
      "215/215 - 0s - loss: 0.4715 - accuracy: 0.8140\n",
      "215/215 - 0s - loss: 0.3853 - accuracy: 0.8512\n",
      "Loss: 0.4715019203895746, Accuracy: 0.8139534592628479\n",
      "Validation Set - Loss: 0.3852890559407168, Accuracy: 0.8511627912521362\n"
     ]
    }
   ],
   "source": [
    "# Define the deep learning model \n",
    "final32_model = tf.keras.models.Sequential()\n",
    "final32_model.add(tf.keras.layers.Dense(units=8, activation=\"relu\", input_dim=32))\n",
    "\n",
    "# Output layer/binary classification so 1 neuron for 0 or 1\n",
    "final32_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.005)\n",
    "\n",
    "# Compile the Sequential model together and customize metrics\n",
    "final32_model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model w/ validation dataset\n",
    "fit32_model = final32_model.fit(X_train_scaled, y_train, epochs=50, validation_data=(X_val_scaled, y_val))\n",
    "\n",
    "# Evaluate the model using the test data + validation data\n",
    "model_loss, model_accuracy = final32_model.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "model_loss_val, model_accuracy_val = final32_model.evaluate(X_val_scaled, y_val, verbose=2)\n",
    "\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n",
    "print(f\"Validation Set - Loss: {model_loss_val}, Accuracy: {model_accuracy_val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "final32_model.save(\"NN_AllFeatures_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000001A6913C1378> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: No module named 'tensorflow_core.estimator'\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000001A6913C1378> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: No module named 'tensorflow_core.estimator'\n",
      "WARNING:tensorflow:From c:\\Users\\yumai\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: NN_AllFeatures_model\\assets\n"
     ]
    }
   ],
   "source": [
    "final32_model.save(\"NN_AllFeatures_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranked Features based on Spearman's Correlation Coefficients:\n",
      "Diagnosis                    1.000000\n",
      "FunctionalAssessment         0.366687\n",
      "ADL                          0.330450\n",
      "MemoryComplaints             0.306742\n",
      "MMSE                         0.236271\n",
      "BehavioralProblems           0.224350\n",
      "SleepQuality                 0.056069\n",
      "EducationLevel               0.043325\n",
      "CholesterolHDL               0.042542\n",
      "Hypertension                 0.035080\n",
      "FamilyHistoryAlzheimers      0.032900\n",
      "CholesterolLDL               0.032010\n",
      "Diabetes                     0.031508\n",
      "CardiovascularDisease        0.031490\n",
      "BMI                          0.026402\n",
      "Disorientation               0.024648\n",
      "CholesterolTriglycerides     0.023072\n",
      "HeadInjury                   0.021411\n",
      "Gender                       0.020975\n",
      "PersonalityChanges           0.020627\n",
      "Confusion                    0.019186\n",
      "Ethnicity                    0.017744\n",
      "SystolicBP                   0.015822\n",
      "DifficultyCompletingTasks    0.009069\n",
      "DietQuality                  0.008670\n",
      "AlcoholConsumption           0.008631\n",
      "Depression                   0.005893\n",
      "PhysicalActivity             0.005866\n",
      "CholesterolTotal             0.005791\n",
      "Age                          0.005731\n",
      "DiastolicBP                  0.005162\n",
      "Smoking                      0.004865\n",
      "Forgetfulness                0.000354\n",
      "Name: Diagnosis, dtype: float64\n",
      "Top Features selected:\n",
      "['Diagnosis', 'FunctionalAssessment', 'ADL', 'MemoryComplaints', 'MMSE', 'BehavioralProblems', 'SleepQuality', 'EducationLevel', 'CholesterolHDL', 'Hypertension']\n"
     ]
    }
   ],
   "source": [
    "# Calculate Spearman's rank correlation coefficients with the target variable\n",
    "spearman_corr = df.corr(method='spearman')['Diagnosis'].abs().sort_values(ascending=False)\n",
    "\n",
    "# Print the ranked features based on Spearman's correlation coefficients\n",
    "print(\"Ranked Features based on Spearman's Correlation Coefficients:\")\n",
    "print(spearman_corr)\n",
    "\n",
    "# Select the top 'k' features based on your criteria\n",
    "# For example, selecting the top 5 features\n",
    "top_features = spearman_corr.index[:10].tolist()\n",
    "print(\"Top Features selected:\")\n",
    "print(top_features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
