{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "from matplotlib import style\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import regularizers\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PatientID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>EducationLevel</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoking</th>\n",
       "      <th>AlcoholConsumption</th>\n",
       "      <th>PhysicalActivity</th>\n",
       "      <th>DietQuality</th>\n",
       "      <th>...</th>\n",
       "      <th>MemoryComplaints</th>\n",
       "      <th>BehavioralProblems</th>\n",
       "      <th>ADL</th>\n",
       "      <th>Confusion</th>\n",
       "      <th>Disorientation</th>\n",
       "      <th>PersonalityChanges</th>\n",
       "      <th>DifficultyCompletingTasks</th>\n",
       "      <th>Forgetfulness</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>DoctorInCharge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4751</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>22.927749</td>\n",
       "      <td>0</td>\n",
       "      <td>13.297218</td>\n",
       "      <td>6.327112</td>\n",
       "      <td>1.347214</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.725883</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>XXXConfid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4752</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.827681</td>\n",
       "      <td>0</td>\n",
       "      <td>4.542524</td>\n",
       "      <td>7.619885</td>\n",
       "      <td>0.518767</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.592424</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>XXXConfid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4753</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>17.795882</td>\n",
       "      <td>0</td>\n",
       "      <td>19.555085</td>\n",
       "      <td>7.844988</td>\n",
       "      <td>1.826335</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.119548</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>XXXConfid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4754</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>33.800817</td>\n",
       "      <td>1</td>\n",
       "      <td>12.209266</td>\n",
       "      <td>8.428001</td>\n",
       "      <td>7.435604</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.481226</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>XXXConfid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4755</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20.716974</td>\n",
       "      <td>0</td>\n",
       "      <td>18.454356</td>\n",
       "      <td>6.310461</td>\n",
       "      <td>0.795498</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.014691</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>XXXConfid</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PatientID  Age  Gender  Ethnicity  EducationLevel        BMI  Smoking  \\\n",
       "0       4751   73       0          0               2  22.927749        0   \n",
       "1       4752   89       0          0               0  26.827681        0   \n",
       "2       4753   73       0          3               1  17.795882        0   \n",
       "3       4754   74       1          0               1  33.800817        1   \n",
       "4       4755   89       0          0               0  20.716974        0   \n",
       "\n",
       "   AlcoholConsumption  PhysicalActivity  DietQuality  ...  MemoryComplaints  \\\n",
       "0           13.297218          6.327112     1.347214  ...                 0   \n",
       "1            4.542524          7.619885     0.518767  ...                 0   \n",
       "2           19.555085          7.844988     1.826335  ...                 0   \n",
       "3           12.209266          8.428001     7.435604  ...                 0   \n",
       "4           18.454356          6.310461     0.795498  ...                 0   \n",
       "\n",
       "   BehavioralProblems       ADL  Confusion  Disorientation  \\\n",
       "0                   0  1.725883          0               0   \n",
       "1                   0  2.592424          0               0   \n",
       "2                   0  7.119548          0               1   \n",
       "3                   1  6.481226          0               0   \n",
       "4                   0  0.014691          0               0   \n",
       "\n",
       "   PersonalityChanges  DifficultyCompletingTasks  Forgetfulness  Diagnosis  \\\n",
       "0                   0                          1              0          0   \n",
       "1                   0                          0              1          0   \n",
       "2                   0                          1              0          0   \n",
       "3                   0                          0              0          0   \n",
       "4                   1                          1              0          0   \n",
       "\n",
       "   DoctorInCharge  \n",
       "0       XXXConfid  \n",
       "1       XXXConfid  \n",
       "2       XXXConfid  \n",
       "3       XXXConfid  \n",
       "4       XXXConfid  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame for the healthcare-dataset-stroke-data.csv. \n",
    "file_path = Path(\"Resources/alzheimers_disease_data.csv\")\n",
    "alzheimer_df = pd.read_csv(file_path)\n",
    "alzheimer_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Data cleaning and preparation process \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of total rows: 2149\n",
      "Number of total columns: 35\n"
     ]
    }
   ],
   "source": [
    "# determine the number of rows and columns.\n",
    "alzheimer_df_rc, alzheimer_df_cc = alzheimer_df.shape\n",
    "print('Number of total rows:', alzheimer_df_rc)\n",
    "print('Number of total columns:', alzheimer_df_cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PatientID', 'Age', 'Gender', 'Ethnicity', 'EducationLevel', 'BMI',\n",
       "       'Smoking', 'AlcoholConsumption', 'PhysicalActivity', 'DietQuality',\n",
       "       'SleepQuality', 'FamilyHistoryAlzheimers', 'CardiovascularDisease',\n",
       "       'Diabetes', 'Depression', 'HeadInjury', 'Hypertension', 'SystolicBP',\n",
       "       'DiastolicBP', 'CholesterolTotal', 'CholesterolLDL', 'CholesterolHDL',\n",
       "       'CholesterolTriglycerides', 'MMSE', 'FunctionalAssessment',\n",
       "       'MemoryComplaints', 'BehavioralProblems', 'ADL', 'Confusion',\n",
       "       'Disorientation', 'PersonalityChanges', 'DifficultyCompletingTasks',\n",
       "       'Forgetfulness', 'Diagnosis', 'DoctorInCharge'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check all columns inside of the DataFrame\n",
    "alzheimer_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate Rows: 0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show duplicates\n",
    "duplicate = alzheimer_df[alzheimer_df.duplicated()]\n",
    "print(\"Duplicate Rows:\", len(duplicate), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PatientID                    0\n",
       "Age                          0\n",
       "Gender                       0\n",
       "Ethnicity                    0\n",
       "EducationLevel               0\n",
       "BMI                          0\n",
       "Smoking                      0\n",
       "AlcoholConsumption           0\n",
       "PhysicalActivity             0\n",
       "DietQuality                  0\n",
       "SleepQuality                 0\n",
       "FamilyHistoryAlzheimers      0\n",
       "CardiovascularDisease        0\n",
       "Diabetes                     0\n",
       "Depression                   0\n",
       "HeadInjury                   0\n",
       "Hypertension                 0\n",
       "SystolicBP                   0\n",
       "DiastolicBP                  0\n",
       "CholesterolTotal             0\n",
       "CholesterolLDL               0\n",
       "CholesterolHDL               0\n",
       "CholesterolTriglycerides     0\n",
       "MMSE                         0\n",
       "FunctionalAssessment         0\n",
       "MemoryComplaints             0\n",
       "BehavioralProblems           0\n",
       "ADL                          0\n",
       "Confusion                    0\n",
       "Disorientation               0\n",
       "PersonalityChanges           0\n",
       "DifficultyCompletingTasks    0\n",
       "Forgetfulness                0\n",
       "Diagnosis                    0\n",
       "DoctorInCharge               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values\n",
    "alzheimer_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all rows with missing information \n",
    "alzheimer_df = alzheimer_df.dropna(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PatientID 2149\n",
      "Age 31\n",
      "Gender 2\n",
      "Ethnicity 4\n",
      "EducationLevel 4\n",
      "BMI 2149\n",
      "Smoking 2\n",
      "AlcoholConsumption 2149\n",
      "PhysicalActivity 2149\n",
      "DietQuality 2149\n",
      "SleepQuality 2149\n",
      "FamilyHistoryAlzheimers 2\n",
      "CardiovascularDisease 2\n",
      "Diabetes 2\n",
      "Depression 2\n",
      "HeadInjury 2\n",
      "Hypertension 2\n",
      "SystolicBP 90\n",
      "DiastolicBP 60\n",
      "CholesterolTotal 2149\n",
      "CholesterolLDL 2149\n",
      "CholesterolHDL 2149\n",
      "CholesterolTriglycerides 2149\n",
      "MMSE 2149\n",
      "FunctionalAssessment 2149\n",
      "MemoryComplaints 2\n",
      "BehavioralProblems 2\n",
      "ADL 2149\n",
      "Confusion 2\n",
      "Disorientation 2\n",
      "PersonalityChanges 2\n",
      "DifficultyCompletingTasks 2\n",
      "Forgetfulness 2\n",
      "Diagnosis 2\n",
      "DoctorInCharge 1\n"
     ]
    }
   ],
   "source": [
    "# print out columns and number of unique values\n",
    "for col in alzheimer_df.columns:\n",
    "    print(col, alzheimer_df[col].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Exploratory Data Analysis (EDA)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Diagnosis\n",
       "0    1389\n",
       "1     760\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the stroke outcome value counts\n",
    "alzheimer_counts = alzheimer_df['Diagnosis'].value_counts()\n",
    "alzheimer_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>EducationLevel</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>MemoryComplaints</th>\n",
       "      <th>BehavioralProblems</th>\n",
       "      <th>MMSE</th>\n",
       "      <th>FunctionalAssessment</th>\n",
       "      <th>ADL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21.463532</td>\n",
       "      <td>6.518877</td>\n",
       "      <td>1.725883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20.613267</td>\n",
       "      <td>7.118696</td>\n",
       "      <td>2.592424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.356249</td>\n",
       "      <td>5.895077</td>\n",
       "      <td>7.119548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13.991127</td>\n",
       "      <td>8.965106</td>\n",
       "      <td>6.481226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.517609</td>\n",
       "      <td>6.045039</td>\n",
       "      <td>0.014691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2144</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.201190</td>\n",
       "      <td>0.238667</td>\n",
       "      <td>4.492838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2145</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.458060</td>\n",
       "      <td>8.687480</td>\n",
       "      <td>9.204952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2146</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17.011003</td>\n",
       "      <td>1.972137</td>\n",
       "      <td>5.036334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2147</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.030491</td>\n",
       "      <td>5.173891</td>\n",
       "      <td>3.785399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2148</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11.114777</td>\n",
       "      <td>6.307543</td>\n",
       "      <td>8.327563</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2149 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Ethnicity  Gender  Age  EducationLevel  Diagnosis  MemoryComplaints  \\\n",
       "0             0       0   73               2          0                 0   \n",
       "1             0       0   89               0          0                 0   \n",
       "2             3       0   73               1          0                 0   \n",
       "3             0       1   74               1          0                 0   \n",
       "4             0       0   89               0          0                 0   \n",
       "...         ...     ...  ...             ...        ...               ...   \n",
       "2144          0       0   61               1          1                 0   \n",
       "2145          0       0   75               2          1                 0   \n",
       "2146          0       0   77               1          1                 0   \n",
       "2147          3       1   78               1          1                 0   \n",
       "2148          0       0   72               2          0                 0   \n",
       "\n",
       "      BehavioralProblems       MMSE  FunctionalAssessment       ADL  \n",
       "0                      0  21.463532              6.518877  1.725883  \n",
       "1                      0  20.613267              7.118696  2.592424  \n",
       "2                      0   7.356249              5.895077  7.119548  \n",
       "3                      1  13.991127              8.965106  6.481226  \n",
       "4                      0  13.517609              6.045039  0.014691  \n",
       "...                  ...        ...                   ...       ...  \n",
       "2144                   0   1.201190              0.238667  4.492838  \n",
       "2145                   1   6.458060              8.687480  9.204952  \n",
       "2146                   0  17.011003              1.972137  5.036334  \n",
       "2147                   0   4.030491              5.173891  3.785399  \n",
       "2148                   1  11.114777              6.307543  8.327563  \n",
       "\n",
       "[2149 rows x 10 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keep part of columns for abalysis\n",
    "alzheimer_cleanML_df = alzheimer_df[['Ethnicity', 'Gender', 'Age', 'EducationLevel', 'Diagnosis', 'MemoryComplaints','BehavioralProblems', 'MMSE', 'FunctionalAssessment','ADL']]\n",
    "alzheimer_cleanML_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Age: The age of the patients ranges from 60 to 90 years.\n",
    "**Gender: Gender of the patients, where 0 represents Male and 1 represents Female.\n",
    "**Ethnicity: The ethnicity of the patients, coded as follows:\n",
    "0: Caucasian\n",
    "1: African American\n",
    "2: Asian\n",
    "3: Other\n",
    "**EducationLevel: The education level of the patients, coded as follows:\n",
    "0: None\n",
    "1: High School\n",
    "2: Bachelor's\n",
    "3: Higher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>MemoryComplaints</th>\n",
       "      <th>BehavioralProblems</th>\n",
       "      <th>MMSE</th>\n",
       "      <th>FunctionalAssessment</th>\n",
       "      <th>ADL</th>\n",
       "      <th>Caucasian</th>\n",
       "      <th>African American</th>\n",
       "      <th>Asian</th>\n",
       "      <th>Other</th>\n",
       "      <th>None</th>\n",
       "      <th>High School</th>\n",
       "      <th>Bachelor's</th>\n",
       "      <th>Higher</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21.463532</td>\n",
       "      <td>6.518877</td>\n",
       "      <td>1.725883</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20.613267</td>\n",
       "      <td>7.118696</td>\n",
       "      <td>2.592424</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.356249</td>\n",
       "      <td>5.895077</td>\n",
       "      <td>7.119548</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13.991127</td>\n",
       "      <td>8.965106</td>\n",
       "      <td>6.481226</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.517609</td>\n",
       "      <td>6.045039</td>\n",
       "      <td>0.014691</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2144</th>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.201190</td>\n",
       "      <td>0.238667</td>\n",
       "      <td>4.492838</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2145</th>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.458060</td>\n",
       "      <td>8.687480</td>\n",
       "      <td>9.204952</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2146</th>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17.011003</td>\n",
       "      <td>1.972137</td>\n",
       "      <td>5.036334</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2147</th>\n",
       "      <td>1</td>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.030491</td>\n",
       "      <td>5.173891</td>\n",
       "      <td>3.785399</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2148</th>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11.114777</td>\n",
       "      <td>6.307543</td>\n",
       "      <td>8.327563</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2149 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Gender  Age  Diagnosis  MemoryComplaints  BehavioralProblems       MMSE  \\\n",
       "0          0   73          0                 0                   0  21.463532   \n",
       "1          0   89          0                 0                   0  20.613267   \n",
       "2          0   73          0                 0                   0   7.356249   \n",
       "3          1   74          0                 0                   1  13.991127   \n",
       "4          0   89          0                 0                   0  13.517609   \n",
       "...      ...  ...        ...               ...                 ...        ...   \n",
       "2144       0   61          1                 0                   0   1.201190   \n",
       "2145       0   75          1                 0                   1   6.458060   \n",
       "2146       0   77          1                 0                   0  17.011003   \n",
       "2147       1   78          1                 0                   0   4.030491   \n",
       "2148       0   72          0                 0                   1  11.114777   \n",
       "\n",
       "      FunctionalAssessment       ADL  Caucasian  African American  Asian  \\\n",
       "0                 6.518877  1.725883          1                 0      0   \n",
       "1                 7.118696  2.592424          1                 0      0   \n",
       "2                 5.895077  7.119548          0                 0      0   \n",
       "3                 8.965106  6.481226          1                 0      0   \n",
       "4                 6.045039  0.014691          1                 0      0   \n",
       "...                    ...       ...        ...               ...    ...   \n",
       "2144              0.238667  4.492838          1                 0      0   \n",
       "2145              8.687480  9.204952          1                 0      0   \n",
       "2146              1.972137  5.036334          1                 0      0   \n",
       "2147              5.173891  3.785399          0                 0      0   \n",
       "2148              6.307543  8.327563          1                 0      0   \n",
       "\n",
       "      Other  None  High School  Bachelor's  Higher  \n",
       "0         0     0            0           1       0  \n",
       "1         0     1            0           0       0  \n",
       "2         1     0            1           0       0  \n",
       "3         0     0            1           0       0  \n",
       "4         0     1            0           0       0  \n",
       "...     ...   ...          ...         ...     ...  \n",
       "2144      0     0            1           0       0  \n",
       "2145      0     0            0           1       0  \n",
       "2146      0     0            1           0       0  \n",
       "2147      1     0            1           0       0  \n",
       "2148      0     0            0           1       0  \n",
       "\n",
       "[2149 rows x 16 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create new columns for each ethnicity and education level\n",
    "alzheimer_cleanML_df['Caucasian'] = (alzheimer_cleanML_df['Ethnicity'] == 0).astype(int)\n",
    "alzheimer_cleanML_df['African American'] = (alzheimer_cleanML_df['Ethnicity'] == 1).astype(int)\n",
    "alzheimer_cleanML_df['Asian'] = (alzheimer_cleanML_df['Ethnicity'] == 2).astype(int)\n",
    "alzheimer_cleanML_df['Other'] = (alzheimer_cleanML_df['Ethnicity'] == 3).astype(int)\n",
    "\n",
    "alzheimer_cleanML_df['None'] = (alzheimer_cleanML_df['EducationLevel'] == 0).astype(int)\n",
    "alzheimer_cleanML_df['High School'] = (alzheimer_cleanML_df['EducationLevel'] == 1).astype(int)\n",
    "alzheimer_cleanML_df['Bachelor\\'s'] = (alzheimer_cleanML_df['EducationLevel'] == 2).astype(int)\n",
    "alzheimer_cleanML_df['Higher'] = (alzheimer_cleanML_df['EducationLevel'] == 3).astype(int)\n",
    "\n",
    "# Drop the original Ethnicity and EducationLevel columns\n",
    "alzheimer_cleanML_df = alzheimer_cleanML_df.drop('Ethnicity', axis=1)\n",
    "alzheimer_cleanML_df = alzheimer_cleanML_df.drop('EducationLevel', axis=1)\n",
    "\n",
    "# Display the first few rows of the reshaped dataframe\n",
    "alzheimer_cleanML_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data:\n",
    "X = alzheimer_cleanML_df.drop('Diagnosis', axis=1)  \n",
    "y = alzheimer_cleanML_df['Diagnosis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "# Review number of features\n",
    "print(len(X_train_scaled[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dense(16, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5973 - loss: 0.6546 - val_accuracy: 0.7849 - val_loss: 0.4869\n",
      "Epoch 2/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8480 - loss: 0.3901 - val_accuracy: 0.8285 - val_loss: 0.4053\n",
      "Epoch 3/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8535 - loss: 0.3425 - val_accuracy: 0.8256 - val_loss: 0.4020\n",
      "Epoch 4/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8803 - loss: 0.3119 - val_accuracy: 0.8372 - val_loss: 0.3736\n",
      "Epoch 5/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8821 - loss: 0.3088 - val_accuracy: 0.8488 - val_loss: 0.3687\n",
      "Epoch 6/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8934 - loss: 0.2715 - val_accuracy: 0.8547 - val_loss: 0.3593\n",
      "Epoch 7/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8986 - loss: 0.2611 - val_accuracy: 0.8459 - val_loss: 0.3542\n",
      "Epoch 8/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9117 - loss: 0.2451 - val_accuracy: 0.8605 - val_loss: 0.3517\n",
      "Epoch 9/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9062 - loss: 0.2247 - val_accuracy: 0.8576 - val_loss: 0.3431\n",
      "Epoch 10/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9378 - loss: 0.1769 - val_accuracy: 0.8430 - val_loss: 0.3655\n",
      "Epoch 11/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9212 - loss: 0.2148 - val_accuracy: 0.8605 - val_loss: 0.3435\n",
      "Epoch 12/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9368 - loss: 0.1924 - val_accuracy: 0.8488 - val_loss: 0.3562\n",
      "Epoch 13/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9470 - loss: 0.1634 - val_accuracy: 0.8459 - val_loss: 0.3682\n",
      "Epoch 14/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9325 - loss: 0.1786 - val_accuracy: 0.8227 - val_loss: 0.3927\n",
      "Epoch 15/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9311 - loss: 0.1875 - val_accuracy: 0.8372 - val_loss: 0.3944\n",
      "Epoch 16/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9364 - loss: 0.1766 - val_accuracy: 0.8721 - val_loss: 0.3498\n",
      "Epoch 17/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9587 - loss: 0.1320 - val_accuracy: 0.8605 - val_loss: 0.3739\n",
      "Epoch 18/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9586 - loss: 0.1353 - val_accuracy: 0.8576 - val_loss: 0.3613\n",
      "Epoch 19/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9582 - loss: 0.1237 - val_accuracy: 0.8576 - val_loss: 0.4043\n",
      "Epoch 20/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9694 - loss: 0.1119 - val_accuracy: 0.8372 - val_loss: 0.4397\n",
      "Epoch 21/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9640 - loss: 0.1199 - val_accuracy: 0.8372 - val_loss: 0.4457\n",
      "Epoch 22/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9664 - loss: 0.1035 - val_accuracy: 0.8547 - val_loss: 0.4120\n",
      "Epoch 23/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9684 - loss: 0.0936 - val_accuracy: 0.8692 - val_loss: 0.4443\n",
      "Epoch 24/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9697 - loss: 0.0965 - val_accuracy: 0.8517 - val_loss: 0.4826\n",
      "Epoch 25/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9763 - loss: 0.0931 - val_accuracy: 0.8488 - val_loss: 0.4513\n",
      "Epoch 26/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9729 - loss: 0.0893 - val_accuracy: 0.8517 - val_loss: 0.4388\n",
      "Epoch 27/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9796 - loss: 0.0750 - val_accuracy: 0.8401 - val_loss: 0.5396\n",
      "Epoch 28/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9625 - loss: 0.1075 - val_accuracy: 0.8343 - val_loss: 0.5255\n",
      "Epoch 29/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9803 - loss: 0.0668 - val_accuracy: 0.8285 - val_loss: 0.5460\n",
      "Epoch 30/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9883 - loss: 0.0536 - val_accuracy: 0.8663 - val_loss: 0.5121\n",
      "Epoch 31/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9836 - loss: 0.0525 - val_accuracy: 0.8401 - val_loss: 0.5693\n",
      "Epoch 32/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9885 - loss: 0.0527 - val_accuracy: 0.8459 - val_loss: 0.5284\n",
      "Epoch 33/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9848 - loss: 0.0454 - val_accuracy: 0.8430 - val_loss: 0.6110\n",
      "Epoch 34/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9816 - loss: 0.0550 - val_accuracy: 0.8256 - val_loss: 0.7216\n",
      "Epoch 35/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9853 - loss: 0.0556 - val_accuracy: 0.8343 - val_loss: 0.6097\n",
      "Epoch 36/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9750 - loss: 0.0742 - val_accuracy: 0.8517 - val_loss: 0.6502\n",
      "Epoch 37/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9748 - loss: 0.0755 - val_accuracy: 0.8372 - val_loss: 0.6874\n",
      "Epoch 38/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9851 - loss: 0.0530 - val_accuracy: 0.8547 - val_loss: 0.6705\n",
      "Epoch 39/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9901 - loss: 0.0445 - val_accuracy: 0.8517 - val_loss: 0.6228\n",
      "Epoch 40/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9896 - loss: 0.0451 - val_accuracy: 0.8430 - val_loss: 0.6718\n",
      "Epoch 41/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9879 - loss: 0.0333 - val_accuracy: 0.8517 - val_loss: 0.6742\n",
      "Epoch 42/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9892 - loss: 0.0335 - val_accuracy: 0.8459 - val_loss: 0.7245\n",
      "Epoch 43/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9872 - loss: 0.0411 - val_accuracy: 0.8314 - val_loss: 0.7212\n",
      "Epoch 44/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9892 - loss: 0.0442 - val_accuracy: 0.8401 - val_loss: 0.7657\n",
      "Epoch 45/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9918 - loss: 0.0310 - val_accuracy: 0.8459 - val_loss: 0.7458\n",
      "Epoch 46/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9896 - loss: 0.0343 - val_accuracy: 0.8547 - val_loss: 0.7215\n",
      "Epoch 47/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9918 - loss: 0.0263 - val_accuracy: 0.8517 - val_loss: 0.7806\n",
      "Epoch 48/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9959 - loss: 0.0222 - val_accuracy: 0.8488 - val_loss: 0.7818\n",
      "Epoch 49/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9938 - loss: 0.0269 - val_accuracy: 0.8547 - val_loss: 0.7971\n",
      "Epoch 50/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9966 - loss: 0.0192 - val_accuracy: 0.8372 - val_loss: 0.8087\n",
      "Epoch 51/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9909 - loss: 0.0209 - val_accuracy: 0.8314 - val_loss: 0.7952\n",
      "Epoch 52/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9960 - loss: 0.0181 - val_accuracy: 0.8401 - val_loss: 0.7893\n",
      "Epoch 53/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9959 - loss: 0.0181 - val_accuracy: 0.8547 - val_loss: 0.8390\n",
      "Epoch 54/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9912 - loss: 0.0345 - val_accuracy: 0.8343 - val_loss: 0.8436\n",
      "Epoch 55/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9925 - loss: 0.0195 - val_accuracy: 0.8459 - val_loss: 0.8390\n",
      "Epoch 56/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9914 - loss: 0.0254 - val_accuracy: 0.8401 - val_loss: 0.9085\n",
      "Epoch 57/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9932 - loss: 0.0175 - val_accuracy: 0.8401 - val_loss: 0.9230\n",
      "Epoch 58/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9943 - loss: 0.0199 - val_accuracy: 0.8430 - val_loss: 0.9421\n",
      "Epoch 59/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9952 - loss: 0.0176 - val_accuracy: 0.8401 - val_loss: 0.9756\n",
      "Epoch 60/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9955 - loss: 0.0177 - val_accuracy: 0.8459 - val_loss: 0.9440\n",
      "Epoch 61/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9953 - loss: 0.0146 - val_accuracy: 0.8314 - val_loss: 1.0942\n",
      "Epoch 62/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9887 - loss: 0.0298 - val_accuracy: 0.8430 - val_loss: 1.0434\n",
      "Epoch 63/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9900 - loss: 0.0206 - val_accuracy: 0.8343 - val_loss: 1.0602\n",
      "Epoch 64/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9898 - loss: 0.0288 - val_accuracy: 0.8256 - val_loss: 1.2236\n",
      "Epoch 65/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9752 - loss: 0.0592 - val_accuracy: 0.8430 - val_loss: 0.9689\n",
      "Epoch 66/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9843 - loss: 0.0455 - val_accuracy: 0.8430 - val_loss: 0.9463\n",
      "Epoch 67/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9911 - loss: 0.0222 - val_accuracy: 0.8343 - val_loss: 0.8908\n",
      "Epoch 68/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9903 - loss: 0.0315 - val_accuracy: 0.8488 - val_loss: 0.9053\n",
      "Epoch 69/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9945 - loss: 0.0167 - val_accuracy: 0.8488 - val_loss: 0.8817\n",
      "Epoch 70/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9980 - loss: 0.0094 - val_accuracy: 0.8459 - val_loss: 0.9878\n",
      "Epoch 71/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9970 - loss: 0.0085 - val_accuracy: 0.8430 - val_loss: 0.9868\n",
      "Epoch 72/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9923 - loss: 0.0145 - val_accuracy: 0.8488 - val_loss: 0.9706\n",
      "Epoch 73/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9958 - loss: 0.0092 - val_accuracy: 0.8459 - val_loss: 0.9920\n",
      "Epoch 74/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9968 - loss: 0.0095 - val_accuracy: 0.8430 - val_loss: 1.0894\n",
      "Epoch 75/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9971 - loss: 0.0103 - val_accuracy: 0.8430 - val_loss: 1.0737\n",
      "Epoch 76/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9965 - loss: 0.0083 - val_accuracy: 0.8401 - val_loss: 1.0860\n",
      "Epoch 77/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9953 - loss: 0.0103 - val_accuracy: 0.8430 - val_loss: 1.1112\n",
      "Epoch 78/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9970 - loss: 0.0101 - val_accuracy: 0.8488 - val_loss: 1.0471\n",
      "Epoch 79/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9949 - loss: 0.0100 - val_accuracy: 0.8547 - val_loss: 1.0513\n",
      "Epoch 80/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9952 - loss: 0.0084 - val_accuracy: 0.8459 - val_loss: 1.0496\n",
      "Epoch 81/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9985 - loss: 0.0047 - val_accuracy: 0.8488 - val_loss: 1.0966\n",
      "Epoch 82/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9978 - loss: 0.0053 - val_accuracy: 0.8459 - val_loss: 1.1548\n",
      "Epoch 83/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9986 - loss: 0.0051 - val_accuracy: 0.8430 - val_loss: 1.0745\n",
      "Epoch 84/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9991 - loss: 0.0054 - val_accuracy: 0.8401 - val_loss: 1.1893\n",
      "Epoch 85/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9968 - loss: 0.0072 - val_accuracy: 0.8401 - val_loss: 1.0858\n",
      "Epoch 86/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9947 - loss: 0.0115 - val_accuracy: 0.8314 - val_loss: 1.0913\n",
      "Epoch 87/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9970 - loss: 0.0128 - val_accuracy: 0.8459 - val_loss: 1.1308\n",
      "Epoch 88/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9964 - loss: 0.0060 - val_accuracy: 0.8488 - val_loss: 1.1457\n",
      "Epoch 89/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9982 - loss: 0.0045 - val_accuracy: 0.8430 - val_loss: 1.1790\n",
      "Epoch 90/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9973 - loss: 0.0064 - val_accuracy: 0.8430 - val_loss: 1.1698\n",
      "Epoch 91/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9989 - loss: 0.0047 - val_accuracy: 0.8343 - val_loss: 1.1722\n",
      "Epoch 92/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9967 - loss: 0.0055 - val_accuracy: 0.8430 - val_loss: 1.1967\n",
      "Epoch 93/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9970 - loss: 0.0059 - val_accuracy: 0.8488 - val_loss: 1.1876\n",
      "Epoch 94/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 0.8488 - val_loss: 1.2165\n",
      "Epoch 95/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0020 - val_accuracy: 0.8401 - val_loss: 1.1592\n",
      "Epoch 96/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0066 - val_accuracy: 0.8459 - val_loss: 1.2107\n",
      "Epoch 97/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9978 - loss: 0.0059 - val_accuracy: 0.8430 - val_loss: 1.1786\n",
      "Epoch 98/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9985 - loss: 0.0038 - val_accuracy: 0.8430 - val_loss: 1.2238\n",
      "Epoch 99/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9988 - loss: 0.0028 - val_accuracy: 0.8430 - val_loss: 1.2324\n",
      "Epoch 100/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0027 - val_accuracy: 0.8430 - val_loss: 1.2438\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1000us/step - accuracy: 0.8811 - loss: 0.9832\n",
      "Test accuracy: 0.8720930218696594\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(X_test_scaled, y_test)\n",
    "print(f\"Test accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model - deep neural net\n",
    "hidden_nodes_layer1 = 128\n",
    "hidden_nodes_layer2 = 64\n",
    "hidden_nodes_layer3 = 32\n",
    "hidden_nodes_layer4 = 16\n",
    "\n",
    "kernel_regularizer=regularizers.l2(0.01)\n",
    "\n",
    "nn = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Sequential.add() got an unexpected keyword argument 'input_shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# First hidden layer\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDense\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43munits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_nodes_layer1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrelu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Second hidden layer\u001b[39;00m\n\u001b[0;32m      6\u001b[0m nn\u001b[38;5;241m.\u001b[39madd(tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\n\u001b[0;32m      7\u001b[0m     units\u001b[38;5;241m=\u001b[39mhidden_nodes_layer2, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m\"\u001b[39m), kernel_regularizer),\n",
      "\u001b[1;31mTypeError\u001b[0m: Sequential.add() got an unexpected keyword argument 'input_shape'"
     ]
    }
   ],
   "source": [
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(\n",
    "    units=hidden_nodes_layer1, activation=\"relu\"), input_shape=(X_train.shape[1])),\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(\n",
    "    units=hidden_nodes_layer2, activation=\"relu\"), kernel_regularizer),\n",
    "\n",
    "# Third hidden layer\n",
    "nn.add(tf.keras.layers.Dense(\n",
    "    units=hidden_nodes_layer3, activation=\"relu\"), kernel_regularizer),\n",
    "\n",
    "# Fourth hidden layer\n",
    "nn.add(tf.keras.layers.Dense(\n",
    "    units=hidden_nodes_layer3, activation=\"relu\"), kernel_regularizer),\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"), kernel_regularizer)\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5604 - loss: 0.6750 - val_accuracy: 0.7326 - val_loss: 0.5351\n",
      "Epoch 2/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8213 - loss: 0.4505 - val_accuracy: 0.8023 - val_loss: 0.4190\n",
      "Epoch 3/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8584 - loss: 0.3480 - val_accuracy: 0.8023 - val_loss: 0.4282\n",
      "Epoch 4/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8757 - loss: 0.3250 - val_accuracy: 0.8314 - val_loss: 0.3930\n",
      "Epoch 5/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8566 - loss: 0.3265 - val_accuracy: 0.8372 - val_loss: 0.3811\n",
      "Epoch 6/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8967 - loss: 0.2817 - val_accuracy: 0.8023 - val_loss: 0.3978\n",
      "Epoch 7/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8881 - loss: 0.2853 - val_accuracy: 0.8169 - val_loss: 0.3899\n",
      "Epoch 8/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9132 - loss: 0.2434 - val_accuracy: 0.8517 - val_loss: 0.3690\n",
      "Epoch 9/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9066 - loss: 0.2588 - val_accuracy: 0.8576 - val_loss: 0.3693\n",
      "Epoch 10/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9265 - loss: 0.2298 - val_accuracy: 0.8488 - val_loss: 0.3655\n",
      "Epoch 11/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9168 - loss: 0.2191 - val_accuracy: 0.8517 - val_loss: 0.3658\n",
      "Epoch 12/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9305 - loss: 0.1959 - val_accuracy: 0.8517 - val_loss: 0.3773\n",
      "Epoch 13/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9237 - loss: 0.2088 - val_accuracy: 0.8605 - val_loss: 0.3635\n",
      "Epoch 14/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9298 - loss: 0.1890 - val_accuracy: 0.8517 - val_loss: 0.3652\n",
      "Epoch 15/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9349 - loss: 0.1763 - val_accuracy: 0.8576 - val_loss: 0.3751\n",
      "Epoch 16/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9483 - loss: 0.1643 - val_accuracy: 0.8634 - val_loss: 0.3745\n",
      "Epoch 17/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9320 - loss: 0.1972 - val_accuracy: 0.8517 - val_loss: 0.3827\n",
      "Epoch 18/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9472 - loss: 0.1556 - val_accuracy: 0.8576 - val_loss: 0.3772\n",
      "Epoch 19/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9507 - loss: 0.1485 - val_accuracy: 0.8576 - val_loss: 0.3926\n",
      "Epoch 20/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9500 - loss: 0.1565 - val_accuracy: 0.8605 - val_loss: 0.3886\n",
      "Epoch 21/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9647 - loss: 0.1271 - val_accuracy: 0.8663 - val_loss: 0.4060\n",
      "Epoch 22/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9681 - loss: 0.1183 - val_accuracy: 0.8605 - val_loss: 0.4041\n",
      "Epoch 23/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9672 - loss: 0.1172 - val_accuracy: 0.8605 - val_loss: 0.4093\n",
      "Epoch 24/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9720 - loss: 0.1040 - val_accuracy: 0.8459 - val_loss: 0.4162\n",
      "Epoch 25/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9673 - loss: 0.1196 - val_accuracy: 0.8459 - val_loss: 0.4197\n",
      "Epoch 26/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9600 - loss: 0.1064 - val_accuracy: 0.8517 - val_loss: 0.4330\n",
      "Epoch 27/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9645 - loss: 0.1107 - val_accuracy: 0.8547 - val_loss: 0.4419\n",
      "Epoch 28/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9642 - loss: 0.1162 - val_accuracy: 0.8576 - val_loss: 0.4656\n",
      "Epoch 29/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9770 - loss: 0.0844 - val_accuracy: 0.8343 - val_loss: 0.4995\n",
      "Epoch 30/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9731 - loss: 0.0813 - val_accuracy: 0.8517 - val_loss: 0.4649\n",
      "Epoch 31/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9804 - loss: 0.0684 - val_accuracy: 0.8430 - val_loss: 0.4871\n",
      "Epoch 32/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9763 - loss: 0.0729 - val_accuracy: 0.8605 - val_loss: 0.5073\n",
      "Epoch 33/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9744 - loss: 0.0793 - val_accuracy: 0.8314 - val_loss: 0.5734\n",
      "Epoch 34/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9826 - loss: 0.0605 - val_accuracy: 0.8488 - val_loss: 0.5059\n",
      "Epoch 35/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9776 - loss: 0.0709 - val_accuracy: 0.8401 - val_loss: 0.5918\n",
      "Epoch 36/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9861 - loss: 0.0540 - val_accuracy: 0.8343 - val_loss: 0.5623\n",
      "Epoch 37/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9800 - loss: 0.0641 - val_accuracy: 0.8517 - val_loss: 0.5607\n",
      "Epoch 38/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9868 - loss: 0.0493 - val_accuracy: 0.8372 - val_loss: 0.5765\n",
      "Epoch 39/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9894 - loss: 0.0501 - val_accuracy: 0.8430 - val_loss: 0.5738\n",
      "Epoch 40/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9917 - loss: 0.0364 - val_accuracy: 0.8343 - val_loss: 0.6097\n",
      "Epoch 41/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9853 - loss: 0.0474 - val_accuracy: 0.8372 - val_loss: 0.6111\n",
      "Epoch 42/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9907 - loss: 0.0333 - val_accuracy: 0.8343 - val_loss: 0.6413\n",
      "Epoch 43/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9924 - loss: 0.0290 - val_accuracy: 0.8488 - val_loss: 0.6368\n",
      "Epoch 44/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9928 - loss: 0.0287 - val_accuracy: 0.8459 - val_loss: 0.6373\n",
      "Epoch 45/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9869 - loss: 0.0336 - val_accuracy: 0.8459 - val_loss: 0.6805\n",
      "Epoch 46/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9928 - loss: 0.0265 - val_accuracy: 0.8459 - val_loss: 0.7022\n",
      "Epoch 47/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9906 - loss: 0.0270 - val_accuracy: 0.8372 - val_loss: 0.7045\n",
      "Epoch 48/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9924 - loss: 0.0278 - val_accuracy: 0.8343 - val_loss: 0.7011\n",
      "Epoch 49/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9941 - loss: 0.0229 - val_accuracy: 0.8430 - val_loss: 0.7095\n",
      "Epoch 50/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9983 - loss: 0.0145 - val_accuracy: 0.8314 - val_loss: 0.7526\n",
      "Epoch 51/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9951 - loss: 0.0196 - val_accuracy: 0.8401 - val_loss: 0.7401\n",
      "Epoch 52/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9960 - loss: 0.0161 - val_accuracy: 0.8372 - val_loss: 0.7537\n",
      "Epoch 53/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9941 - loss: 0.0135 - val_accuracy: 0.8343 - val_loss: 0.8399\n",
      "Epoch 54/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9969 - loss: 0.0117 - val_accuracy: 0.8343 - val_loss: 0.7933\n",
      "Epoch 55/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9993 - loss: 0.0107 - val_accuracy: 0.8256 - val_loss: 0.8396\n",
      "Epoch 56/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9955 - loss: 0.0124 - val_accuracy: 0.8343 - val_loss: 0.8497\n",
      "Epoch 57/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9974 - loss: 0.0107 - val_accuracy: 0.8314 - val_loss: 0.8584\n",
      "Epoch 58/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9978 - loss: 0.0078 - val_accuracy: 0.8285 - val_loss: 0.8951\n",
      "Epoch 59/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9980 - loss: 0.0116 - val_accuracy: 0.8285 - val_loss: 0.9211\n",
      "Epoch 60/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9966 - loss: 0.0113 - val_accuracy: 0.8256 - val_loss: 0.9486\n",
      "Epoch 61/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 0.0089 - val_accuracy: 0.8430 - val_loss: 0.8887\n",
      "Epoch 62/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9992 - loss: 0.0063 - val_accuracy: 0.8401 - val_loss: 0.9154\n",
      "Epoch 63/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9980 - loss: 0.0058 - val_accuracy: 0.8401 - val_loss: 0.9356\n",
      "Epoch 64/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9986 - loss: 0.0066 - val_accuracy: 0.8517 - val_loss: 0.9378\n",
      "Epoch 65/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 0.0043 - val_accuracy: 0.8488 - val_loss: 0.9546\n",
      "Epoch 66/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0055 - val_accuracy: 0.8547 - val_loss: 0.9680\n",
      "Epoch 67/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9989 - loss: 0.0058 - val_accuracy: 0.8343 - val_loss: 0.9800\n",
      "Epoch 68/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0062 - val_accuracy: 0.8488 - val_loss: 1.0029\n",
      "Epoch 69/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9956 - loss: 0.0215 - val_accuracy: 0.8547 - val_loss: 1.0154\n",
      "Epoch 70/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9677 - loss: 0.1100 - val_accuracy: 0.8140 - val_loss: 1.0672\n",
      "Epoch 71/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9507 - loss: 0.1367 - val_accuracy: 0.8430 - val_loss: 0.7194\n",
      "Epoch 72/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9783 - loss: 0.0657 - val_accuracy: 0.8343 - val_loss: 0.8724\n",
      "Epoch 73/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9853 - loss: 0.0475 - val_accuracy: 0.8227 - val_loss: 0.8290\n",
      "Epoch 74/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9936 - loss: 0.0261 - val_accuracy: 0.8372 - val_loss: 0.7999\n",
      "Epoch 75/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0127 - val_accuracy: 0.8343 - val_loss: 0.8339\n",
      "Epoch 76/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0085 - val_accuracy: 0.8372 - val_loss: 0.8425\n",
      "Epoch 77/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9999 - loss: 0.0059 - val_accuracy: 0.8401 - val_loss: 0.8689\n",
      "Epoch 78/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0045 - val_accuracy: 0.8430 - val_loss: 0.8833\n",
      "Epoch 79/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9999 - loss: 0.0046 - val_accuracy: 0.8343 - val_loss: 0.9192\n",
      "Epoch 80/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0038 - val_accuracy: 0.8401 - val_loss: 0.9153\n",
      "Epoch 81/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0042 - val_accuracy: 0.8401 - val_loss: 0.9347\n",
      "Epoch 82/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0047 - val_accuracy: 0.8401 - val_loss: 0.9547\n",
      "Epoch 83/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.8372 - val_loss: 0.9639\n",
      "Epoch 84/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 0.8314 - val_loss: 0.9768\n",
      "Epoch 85/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0032 - val_accuracy: 0.8430 - val_loss: 0.9841\n",
      "Epoch 86/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0031 - val_accuracy: 0.8343 - val_loss: 1.0152\n",
      "Epoch 87/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9988 - loss: 0.0059 - val_accuracy: 0.8372 - val_loss: 1.0102\n",
      "Epoch 88/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0032 - val_accuracy: 0.8372 - val_loss: 1.0173\n",
      "Epoch 89/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.8343 - val_loss: 1.0216\n",
      "Epoch 90/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.8372 - val_loss: 1.0364\n",
      "Epoch 91/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9997 - loss: 0.0036 - val_accuracy: 0.8459 - val_loss: 1.0464\n",
      "Epoch 92/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0037 - val_accuracy: 0.8343 - val_loss: 1.0735\n",
      "Epoch 93/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9988 - loss: 0.0041 - val_accuracy: 0.8314 - val_loss: 1.0585\n",
      "Epoch 94/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9998 - loss: 0.0031 - val_accuracy: 0.8343 - val_loss: 1.0731\n",
      "Epoch 95/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9992 - loss: 0.0026 - val_accuracy: 0.8459 - val_loss: 1.0551\n",
      "Epoch 96/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9992 - loss: 0.0045 - val_accuracy: 0.8343 - val_loss: 1.0865\n",
      "Epoch 97/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9999 - loss: 0.0018 - val_accuracy: 0.8372 - val_loss: 1.0854\n",
      "Epoch 98/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9988 - loss: 0.0039 - val_accuracy: 0.8343 - val_loss: 1.1059\n",
      "Epoch 99/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.8372 - val_loss: 1.0890\n",
      "Epoch 100/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.8343 - val_loss: 1.1034\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled, y_train, epochs=100, batch_size=58, validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 - 0s - 2ms/step - accuracy: 0.8814 - loss: 0.9931\n",
      "Loss: 0.9930531978607178, Accuracy: 0.8813953399658203\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "filename = 'alzheimer_ML.h5'\n",
    "nn.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot accuracy of the model\n",
    "plot_df = pd.DataFrame(fit_model.history, index =  range(1, len(fit_model.history[\"loss\"]) + 1))\n",
    "plot_df.plot(y = \"accuracy\", figsize = (8, 5))\n",
    "plt.title(\"Model Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.grid(True)\n",
    "plt.savefig(\"model_accuracy_opt.png\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inclassfeb2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
